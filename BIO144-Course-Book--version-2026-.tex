% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  letterpaper,
  8pt,
  a4paper]{book}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
\usepackage{colortbl}
\usepackage{array}
\usepackage{anyfontsize}
\usepackage{multirow}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={BIO144 Course Book (version 2026)},
  pdfauthor={Owen Petchey},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{BIO144 Course Book (version 2026)}
\author{Owen Petchey}
\date{2025-12-12}
\begin{document}
\frontmatter
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\setcounter{tocdepth}{1}
\tableofcontents
}

\mainmatter
\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-warning-color!10!white, leftrule=.75mm, colframe=quarto-callout-warning-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Warning}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Under construction}: This 2026 version of this book is currently
being prepared. Some chapters are not yet available, and some content
may change before the course starts in February 2026.*

\end{tcolorbox}

This book contains the content of the course BIO144 Data Analysis in
Biology at the University of Zurich. It is intended to be used as a
companion to the lectures and practical exercises of the course. All of
the required content of the course (i.e., what could be in the final
exam) is included in this book. Additional content is included for those
who want to learn more.

Beware that Owen sometimes makes updates to the book during the
semester, so if you have downloaded a copy or taken screenshots, your
copy may not exactly match the most current version. However, all of the
required content will be the same, and any changes will be correcting
typos or improving explanations. If content does change in a way that
would change the answer to a question in the final exam, Owen will
announce this in the lectures and on OLAT.

\section*{How to get a copy of this
book}\label{how-to-get-a-copy-of-this-book}
\addcontentsline{toc}{section}{How to get a copy of this book}

\markright{How to get a copy of this book}

If you'd like a copy of this book for yourself, there are a few ways.
But beware: if you take a local copy then it will not be updated when
Owen makes changes to the online version!

\begin{itemize}
\item
  You can download a PDF version of the entire book: ðŸ“„ Download PDF
\item
  You can download a complete local copy of the HTML version of the
  BIO144 course book from here:\\
  \url{https://github.com/opetchey/BIO144_Course_Book/tree/main}. The
  html files for the book are in the \texttt{\_book} folder, and this is
  the only folder you need for your offline html copy of the book. You
  can open the \texttt{index.html} file in your web browser to read the
  book offline.
\item
  You can get all of the source code for the book from the
  \href{https://github.com/opetchey/BIO144_Course_Book}{GitHub
  repository}. However, you may find it a little complicated to do
  anything useful with it!
\end{itemize}

\section*{If you think you found a mistake in this
book}\label{if-you-think-you-found-a-mistake-in-this-book}
\addcontentsline{toc}{section}{If you think you found a mistake in this
book}

\markright{If you think you found a mistake in this book}

If you think you have found a mistake in the book, please say. A really
nice way is to submit an issue on the GitHub repository for the book:
\href{https://github.com/opetchey/BIO144_Course_Book/issues}{GitHub
repository}. You will need a GitHub account to do this, but they are
free and easy to set up. Otherwise tell Owen in person sometime, or in
the OLAT Forum, or by email.

When reporting a mistake, please be as specific as possible about where
the mistake is. A screenshot works well. Or give the chapter and section
number, and copy a chunk of text, as well as a description of the issue
problem of course!

\section*{How this book was made}\label{how-this-book-was-made}
\addcontentsline{toc}{section}{How this book was made}

\markright{How this book was made}

The book was written using a type of RMarkdown. It allows a script with
a mix of normal text and R code to produce chapters and a book that has
a mixture of text, R code, and R output. Rmarkdown is very useful for
making reports, books, presentations, and even websites.

This book is a Quarto book. To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\section*{Acknowledgements}\label{acknowledgements}
\addcontentsline{toc}{section}{Acknowledgements}

\markright{Acknowledgements}

The content was based on lectures originally written by
\href{https://www.ntnu.edu/employees/stefanie.muff}{Dr Stefanie Muff}.

The content of the book was written with the assistance of
\href{https://copilot.github.com/}{Github Copilot}, an AI tool that
helps write code and text.

\bookmarksetup{startatroot}

\chapter*{Introduction (L1)}\label{introduction-l1}
\addcontentsline{toc}{chapter}{Introduction (L1)}

\markboth{Introduction (L1)}{Introduction (L1)}

The first lecture of the course introduces it, gives some important
information, and sets the stage for the rest of the course. Some of the
time in the lecture will be used to create a dataset for use during the
course. It also gives an opportunity to review some of the things about
R and statistics that it is very useful to already know.

The lecture includes:

\begin{itemize}
\tightlist
\item
  Goals of the course
\item
  Course organisation
\item
  AI and the course
\item
  Making a course dataset
\item
  Using RStudio
\item
  Reviewing what you should already know
\item
  Learning objectives
\end{itemize}

\section*{Notation and some
definitions}\label{notation-and-some-definitions}
\addcontentsline{toc}{section}{Notation and some definitions}

\markright{Notation and some definitions}

Throughout the course, we will use the following notation:

\begin{itemize}
\tightlist
\item
  \(x\) for a variable. Typically this variable contains a set of
  observations. These observations are said to represent a sample of all
  the possible observations that could be made of a \emph{population}.
\item
  \(x_1, x_2, \ldots\) for the values of a variable
\item
  \(x_i\) for the \(i\)th value of a scalar variable. This is often
  spoken as ``x sub i'' or the ``i-th value of x''.
\item
  \(x^{(1)}\) for variable 1, \(x^{(2)}\) for variable 2, etc.
\item
  The mean of the sample \(x\) is \(\bar{x}\). This is usually spoken as
  ``x-bar''.
\item
  The mean of \(x\) is calculated as
  \(\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i\).
\item
  \(n\) is the number of observations in a sample.
\item
  The summation symbol \(\sum\) is used to indicate that the values of
  \(x\) are summed over all values of \(i\) from 1 to \(n\).
\item
  The standard deviation of the sample is \(s\). The standard deviation
  of the population is \(\sigma\).
\item
  The variance is \(s^2\). The variance of the population is
  \(\sigma^2\).
\item
  The variance of the sample is calculated as
  \(s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2\).
\item
  The standard deviation of the sample is calculated as
  \(s = \sqrt{s^2}\).
\item
  \(y\) is usually used to represent a dependent / response variable.
\item
  \(x\) is usually used to represent an independent / predictor /
  explanatory variable.
\item
  \(\beta_0\) is usually used to denote the intercept of a linear model.
\item
  \(\beta_1\), \(\beta_2\), etc. are usually used to denote the
  coefficients of the independent variables in a linear model.
\item
  Estimates are denoted with a hat, so \(\hat{\beta}_0\) is the estimate
  of the intercept of a linear model.
\item
  Hence, the estimated value of \(y_i\) in a linear regression model is
  \(\hat{y_i} = \hat{\beta}_0 + \hat{\beta}_1 x_i^{(1)}\).
\item
  \(e_i\) is the residual for the \(i\)th observation in a linear model.
  The residual is the difference between the observed value of \(y_i\)
  and the predicted value of \(y_i\) (\(\hat{y_i}\)).
\item
  Often we assume errors are normally distributed with mean 0 and
  variance \(\sigma^2\). This is written as \(e_i \sim N(0, \sigma^2)\).
\item
  SST is the total sum of squares. It is the sum of the squared
  differences between the observed values of \(y\) and the mean of
  \(y\). It is calculated as \(\sum_{i=1}^n (y_i - \bar{y})^2\).
\item
  SSM is the model sum of squares. It is the sum of the squared
  differences between the predicted values of \(y\) and the mean of
  \(y\). It is calculated as \(\sum_{i=1}^n (\hat{y_i} - \bar{y})^2\).
\item
  SSE is the error sum of squares. It is the sum of the squared
  differences between the observed values of \(y\) and the predicted
  values of \(y\). It is calculated as
  \(\sum_{i=1}^n (y_i - \hat{y_i})^2\).
\item
  The variance of \(x\) can be written as \(Var(x)\). The covariance
  between \(x\) and \(y\) can be written as \(Cov(x, y)\).
\item
  Covariance is calculated as
  \(Cov(x, y) = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})\).
\item
  \(H_0\) is the null hypothesis.
\item
  \(\alpha\) is the significance level.
\item
  \emph{df} is the degrees of freedom.
\item
  \(p\) is the p-value.
\end{itemize}

\section*{Using Generative AI in R and Data Analysis: Guidance and Good
Practice}\label{using-generative-ai-in-r-and-data-analysis-guidance-and-good-practice}
\addcontentsline{toc}{section}{Using Generative AI in R and Data
Analysis: Guidance and Good Practice}

\markright{Using Generative AI in R and Data Analysis: Guidance and Good
Practice}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

For the final examination, you will use your own computer, but the test
will run inside the Safe Exam Browser, which will be configured to block
all access to generative AI tools, browser-based assistants, external
software, online services, and any AI code copilots inside RStudio or
other IDEs. This means \textbf{no form of generative AI will be
available during the exam}. Because of this, please avoid becoming
overly reliant on GenAI---such as ChatGPT, Claude, Gemini, Copilot, or
similar tools for answering quiz questions, explaining results, fixing
errors, guiding your analysis, or writing code. You must be able to
perform all tasks independently. We also strongly recommend that you do
not use RStudio with Copilot integration during the course, as it will
not function in the exam environment and may leave you under prepared.
Throughout the semester, be sure to practice writing your own R code,
interpreting outputs yourself, and applying statistical reasoning
without AI assistance, as your exam performance will depend entirely on
your own knowledge and skills.

\end{tcolorbox}

Generative AI (GenAI) tools can support learning, exploration, and
coding in R. They can be powerful assistants, but they must be used with
care. This section introduces the types of tools available, provides
guidelines for responsible use, highlights red flags for problematic
usage, and gives examples of good and poor practice.

Typical uses:

\begin{itemize}
\tightlist
\item
  asking conceptual questions\\
\item
  summarizing methods\\
\item
  generating example code\\
\item
  explaining error messages
\end{itemize}

Strengths:

\begin{itemize}
\tightlist
\item
  flexible and conversational\\
\item
  good for brainstorming\\
\item
  can generate starter code
\end{itemize}

Limitations:

\begin{itemize}
\tightlist
\item
  often wrong in subtle ways\\
\item
  may hallucinate functions\\
\item
  cannot see your working R session
\end{itemize}

\subsection*{Guidelines for Good Use of Generative
AI}\label{guidelines-for-good-use-of-generative-ai}
\addcontentsline{toc}{subsection}{Guidelines for Good Use of Generative
AI}

\subsubsection*{Use GenAI as a Helper, Not a Source of
Truth}\label{use-genai-as-a-helper-not-a-source-of-truth}
\addcontentsline{toc}{subsubsection}{Use GenAI as a Helper, Not a Source
of Truth}

Best uses:

\begin{itemize}
\tightlist
\item
  drafting\\
\item
  explanation\\
\item
  syntax reminders\\
\item
  scaffolding
\end{itemize}

Not reliable for:

\begin{itemize}
\tightlist
\item
  model choice\\
\item
  statistical inference\\
\item
  interpreting coefficients\\
\item
  designing analysis workflows\\
\item
  checking assumptions
\end{itemize}

\subsubsection*{Always Verify AI-Generated Code and
Explanations}\label{always-verify-ai-generated-code-and-explanations}
\addcontentsline{toc}{subsubsection}{Always Verify AI-Generated Code and
Explanations}

Check:

\begin{itemize}
\tightlist
\item
  does the code run?\\
\item
  do variable names match?\\
\item
  is the model appropriate?\\
\item
  are assumptions addressed?\\
\item
  is the explanation logically correct?
\end{itemize}

\subsubsection*{Keep Human Judgement
Central}\label{keep-human-judgement-central}
\addcontentsline{toc}{subsubsection}{Keep Human Judgement Central}

GenAI cannot:

\begin{itemize}
\tightlist
\item
  understand scientific questions\\
\item
  evaluate model assumptions\\
\item
  know ecological/biological reasoning\\
\item
  determine appropriate models
\end{itemize}

\subsubsection*{Provide Context
Carefully}\label{provide-context-carefully}
\addcontentsline{toc}{subsubsection}{Provide Context Carefully}

When asking GenAI:

\begin{itemize}
\tightlist
\item
  describe variables\\
\item
  provide example data\\
\item
  specify your goal\\
\item
  show your existing code
\end{itemize}

Better context = better answers.

\subsubsection*{Use GenAI to Improve Understanding, Not Bypass
It}\label{use-genai-to-improve-understanding-not-bypass-it}
\addcontentsline{toc}{subsubsection}{Use GenAI to Improve Understanding,
Not Bypass It}

Helpful:

\begin{itemize}
\tightlist
\item
  \emph{``Explain logistic regression.''}\\
\item
  \emph{``Why do residuals fan out?''}
\end{itemize}

Not helpful:

\begin{itemize}
\tightlist
\item
  \emph{``Do my assignment for me.''}
\end{itemize}

\subsection*{Indicators of Problematic
Usage}\label{indicators-of-problematic-usage}
\addcontentsline{toc}{subsection}{Indicators of Problematic Usage}

\subsubsection*{Code That Does Not Reflect
Ability}\label{code-that-does-not-reflect-ability}
\addcontentsline{toc}{subsubsection}{Code That Does Not Reflect Ability}

Signs:

\begin{itemize}
\tightlist
\item
  unfamiliar advanced syntax\\
\item
  unexplained packages\\
\item
  inconsistent style
\end{itemize}

\subsubsection*{Hallucinated Functions or Nonsensical
Code}\label{hallucinated-functions-or-nonsensical-code}
\addcontentsline{toc}{subsubsection}{Hallucinated Functions or
Nonsensical Code}

Examples:

\begin{itemize}
\tightlist
\item
  \texttt{slope(x)} in mixed models\\
\item
  missing arguments\\
\item
  fabricated packages
\end{itemize}

\subsubsection*{Statistical Errors Typical of
AI}\label{statistical-errors-typical-of-ai}
\addcontentsline{toc}{subsubsection}{Statistical Errors Typical of AI}

Common issues:

\begin{itemize}
\tightlist
\item
  wrong model family\\
\item
  wrong inference logic\\
\item
  invented assumptions\\
\item
  incorrect explanation of coefficients
\end{itemize}

\subsubsection*{Lack of Understanding}\label{lack-of-understanding}
\addcontentsline{toc}{subsubsection}{Lack of Understanding}

Indicators:

\begin{itemize}
\tightlist
\item
  cannot explain model\\
\item
  inconsistent interpretations\\
\item
  identical phrasing to AI output
\end{itemize}

\subsubsection*{Over-Reliance on AI}\label{over-reliance-on-ai}
\addcontentsline{toc}{subsubsection}{Over-Reliance on AI}

Signs:

\begin{itemize}
\tightlist
\item
  using AI for every step\\
\item
  no debugging effort\\
\item
  stagnation in skill development
\end{itemize}

\subsection*{Examples of Good and Problematic
Use}\label{examples-of-good-and-problematic-use}
\addcontentsline{toc}{subsection}{Examples of Good and Problematic Use}

\subsubsection*{Good Use Examples}\label{good-use-examples}
\addcontentsline{toc}{subsubsection}{Good Use Examples}

\textbf{A. Syntax help}\\
\emph{``How do I specify a random slope in \texttt{lme4}?''}

\textbf{B. Clarification}\\
\emph{``How does adding an interaction change interpretation?''}

\textbf{C. Debugging}\\
\emph{``What does `object not found' usually mean?''}

\textbf{D. Brainstorming}\\
\emph{``How can I visualise a logistic regression?''}

\subsubsection*{Problematic Use
Examples}\label{problematic-use-examples}
\addcontentsline{toc}{subsubsection}{Problematic Use Examples}

\textbf{A. Blindly copying model code}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{*}\NormalTok{ x3 }\SpecialCharTok{*}\NormalTok{ x1)}
\end{Highlighting}
\end{Shaded}

\textbf{B. Incorrect statistical logic}\\
AI code labelled as a bootstrap but is actually a permutation test.

\textbf{C. Misleading interpretation}\\
Claims that coefficients assume predictor independence.

\textbf{D. Presenting AI-generated plots without understanding}

\textbf{E. Outsourcing entire workflow}\\
\emph{``Write a script that loads data, cleans it, runs models,
interprets, and writes the report.''}

\subsubsection*{Summary}\label{summary}
\addcontentsline{toc}{subsubsection}{Summary}

Generative AI can:

\begin{itemize}
\tightlist
\item
  help learning\\
\item
  support debugging\\
\item
  provide code scaffolds\\
\item
  explain concepts
\end{itemize}

But it can also:

\begin{itemize}
\tightlist
\item
  hallucinate\\
\item
  produce incorrect models\\
\item
  misinterpret statistics
\end{itemize}

\textbf{Use GenAI as a supportive tool---never as an unquestioned
authority.}\\
Good use of GenAI \emph{supports} learning. Problematic use
\emph{replaces} it.

\subsection*{Common GenAI Errors in R and Statistical
Modelling}\label{common-genai-errors-in-r-and-statistical-modelling}
\addcontentsline{toc}{subsection}{Common GenAI Errors in R and
Statistical Modelling}

Generative AI tools can be helpful for writing R code, exploring ideas,
and learning syntax.\\
However, they sometimes produce \emph{plausible but incorrect} code or
explanations.\\
This section provides real examples of typical GenAI mistakes, with
correct solutions and teaching points.

\textbf{Why this matters:} GenAI is a \textbf{pattern-matching system},
not a statistical reasoning engine. It does not understand assumptions,
inference, or modelling logic.Therefore, students should \textbf{never
accept code or explanations without checking them}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{\texorpdfstring{Incorrect formula structure in
\texttt{lm()}}{Incorrect formula structure in lm()}}\label{incorrect-formula-structure-in-lm}
\addcontentsline{toc}{subsubsection}{Incorrect formula structure in
\texttt{lm()}}

\textbf{Prompt:} \emph{Fit a linear model with main effects and a
two-way interaction between \texttt{x2} and \texttt{x3}.}

\textbf{Incorrect GenAI output:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{*}\NormalTok{ x3 }\SpecialCharTok{*}\NormalTok{ x1, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

This includes an unintended \textbf{three-way interaction} and extra
terms.

\textbf{Correct:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{*}\NormalTok{ x3, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} Always check model formulas carefully. AI often
adds or removes interactions.

\subsubsection*{Confusing bootstrap and permutation
tests}\label{confusing-bootstrap-and-permutation-tests}
\addcontentsline{toc}{subsubsection}{Confusing bootstrap and permutation
tests}

\textbf{Documented case:} GenAI was asked for a \emph{bootstrap t-test}.

\textbf{Incorrect GenAI code (actually a permutation test):}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t\_stats }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{1000}\NormalTok{, \{}
\NormalTok{  perm }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{group)}
  \FunctionTok{t.test}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{value }\SpecialCharTok{\textasciitilde{}}\NormalTok{ perm)}\SpecialCharTok{$}\NormalTok{statistic}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\textbf{Correct bootstrap approach:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t\_stats }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{1000}\NormalTok{, \{}
\NormalTok{  sample\_df }\OtherTok{\textless{}{-}}\NormalTok{ df[}\FunctionTok{sample}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(df), }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{), ]}
  \FunctionTok{t.test}\NormalTok{(value }\SpecialCharTok{\textasciitilde{}}\NormalTok{ group, }\AttributeTok{data =}\NormalTok{ sample\_df)}\SpecialCharTok{$}\NormalTok{statistic}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} The logic of inference matters. Code that runs
is not necessarily correct.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Incorrect explanation of linear-model
coefficients}\label{incorrect-explanation-of-linear-model-coefficients}
\addcontentsline{toc}{subsubsection}{Incorrect explanation of
linear-model coefficients}

\textbf{Incorrect claim:} \emph{``Coefficients assume independence among
predictors.''}

This is false. Linear model coefficients describe \textbf{conditional
effects within the model}, regardless of collinearity.

\textbf{Teaching point:} Interpretations come from the model structure,
not from simplistic assumptions GenAI sometimes invents.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Hallucinated functions in mixed
models}\label{hallucinated-functions-in-mixed-models}
\addcontentsline{toc}{subsubsection}{Hallucinated functions in mixed
models}

\textbf{Incorrect GenAI output:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lmer}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ (}\FunctionTok{slope}\NormalTok{(x) }\SpecialCharTok{|}\NormalTok{ group), }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\texttt{slope()} does not exist.

\textbf{Correct random-slope specification:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lmer}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ (x }\SpecialCharTok{|}\NormalTok{ group), }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} Always verify syntax in package documentation.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Wrong variable names}\label{wrong-variable-names}
\addcontentsline{toc}{subsubsection}{Wrong variable names}

The dataset has variables \texttt{height} and \texttt{age}.

\textbf{Incorrect GenAI output:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(Height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Age, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Correct:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} GenAI often guesses variable names. Check
against your data.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Wrong model family for binary
data}\label{wrong-model-family-for-binary-data}
\addcontentsline{toc}{subsubsection}{Wrong model family for binary data}

\textbf{Incorrect GenAI output (linear regression):}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Correct logistic regression:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ df, }\AttributeTok{family =}\NormalTok{ binomial)}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} For binary response variables, specify the
model family explicitly.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Incorrect explanation of random
intercepts}\label{incorrect-explanation-of-random-intercepts}
\addcontentsline{toc}{subsubsection}{Incorrect explanation of random
intercepts}

\textbf{Incorrect claim:}\\
\emph{``Random intercepts eliminate correlation among repeated
measures.''}

Incorrect --- they \textbf{model} correlation, not eliminate it.

\textbf{Teaching point:} Random effects structure determines the implied
correlation. AI explanations are often vague or wrong here.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Omitting interaction terms in
ANOVA}\label{omitting-interaction-terms-in-anova}
\addcontentsline{toc}{subsubsection}{Omitting interaction terms in
ANOVA}

\textbf{Prompt:} \emph{Two-way ANOVA with interaction.}

\textbf{Incorrect:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{aov}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ factor1 }\SpecialCharTok{+}\NormalTok{ factor2, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Correct:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{aov}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ factor1 }\SpecialCharTok{*}\NormalTok{ factor2, }\AttributeTok{data =}\NormalTok{ df)}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} Confirm that the model matches the experimental
design.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{\texorpdfstring{Incorrect use of
\texttt{predict()}}{Incorrect use of predict()}}\label{incorrect-use-of-predict}
\addcontentsline{toc}{subsubsection}{Incorrect use of
\texttt{predict()}}

\textbf{Prompt:} \emph{Predict for new x values.}

\textbf{Incorrect GenAI output:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

This gives \textbf{in-sample fitted values}, not predictions for new
data.

\textbf{Correct:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(model, }\AttributeTok{newdata =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} Always specify \texttt{newdata} for
predictions.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Poor explanations of
multicollinearity}\label{poor-explanations-of-multicollinearity}
\addcontentsline{toc}{subsubsection}{Poor explanations of
multicollinearity}

\textbf{Incorrect GenAI claim:}\\
\emph{``Multicollinearity is indicated when the model p-value is low but
the individual predictor p-values are high.''}

This is an unreliable and incomplete diagnostic.

\textbf{Better diagnostics:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{car}\SpecialCharTok{::}\FunctionTok{vif}\NormalTok{(model)}
\FunctionTok{cor}\NormalTok{(df)}
\FunctionTok{model.matrix}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\textbf{Teaching point:} AI often repeats common internet tropes rather
than robust statistical principles.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection*{Summary}\label{summary-1}
\addcontentsline{toc}{subsubsection}{Summary}

GenAI can:

\begin{itemize}
\tightlist
\item
  write useful scaffolding code,\\
\item
  provide quick reminders,\\
\item
  help with simple tasks.
\end{itemize}

But it can also:

\begin{itemize}
\tightlist
\item
  hallucinate functions,\\
\item
  give subtly incorrect models,\\
\item
  invent statistical logic,\\
\item
  provide plausible but wrong explanations.
\end{itemize}

\textbf{Advice for students:}\\
Use GenAI as a starting point, not an authority.\\
Always check:

\begin{itemize}
\tightlist
\item
  function names,\\
\item
  model formulas,\\
\item
  assumptions,\\
\item
  interpretations,\\
\item
  and logic.
\end{itemize}

In statistics, clarity of reasoning matters more than code that merely
\emph{runs}.

\bookmarksetup{startatroot}

\chapter*{R and RStudio (L2)}\label{r-and-rstudio-l2}
\addcontentsline{toc}{chapter}{R and RStudio (L2)}

\markboth{R and RStudio (L2)}{R and RStudio (L2)}

\section*{Getting R and RStudio}\label{sec-using-r-and-rstudio}
\addcontentsline{toc}{section}{Getting R and RStudio}

\markright{Getting R and RStudio}

\textbf{\emph{R}} is a programming language and software environment for
statistical computing and graphics. RStudio is an integrated development
environment (IDE) for R. \textbf{\emph{RStudio}} provides a
user-friendly interface for working with R, including a console, a
script editor, and tools for managing packages and projects.

We highly recommend using \textbf{RStudio} to work with \textbf{R}.

There are two ways to use \textbf{RStudio}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{RStudio Desktop}: a standalone application that you can
  install on your computer. If you choose this option, you will need to
  install R first, and then install RStudio. This usually requires
  administrator privileges on your computer. If you have problems
  installing add-on packages, they will have to be fixed by you or with
  our help (rarely we cannot find a solution). Follow the instructions
  on this website about how to install R and RStudio:
  https://posit.co/download/rstudio-desktop/.
\item
  \textbf{Rstudio Cloud}: a web-based version of RStudio that you can
  use in your web browser. You don't need to install anything on your
  computer, and you can access your work from any computer with an
  internet connection. The Faculty of Science has a
  \href{https://rstudio2024.mnf.uzh.ch}{RStudio Cloud here} that you can
  use (and will have to use during the final exam).
\end{enumerate}

What do we recommend? Try the cloud first. If you like it then continue
to use it.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

Whether you use the RStudio application on your computer, or use RStudio
on the Cloud, you are responsible for the safety and persistence of your
files (data, code, etc.). Just because you're using RStudio on the Cloud
does not mean your files are automatically saved forever. Make sure to
download and back up your important files regularly!

\end{tcolorbox}

\section*{Getting to know the RStudio
IDE}\label{sec-getting-to-know-the-rstudio-ide}
\addcontentsline{toc}{section}{Getting to know the RStudio IDE}

\markright{Getting to know the RStudio IDE}

When you open RStudio, you will see a window with four main panes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Source pane}: where you can write and edit R scripts, R
  Markdown documents, and other files. This pane can have multiple tabs,
  so you can have several files open at the same time.
\item
  \textbf{Console pane}: where you can type and execute R commands
  directly. This pane has multiple tabs, including: \textbf{Console},
  \textbf{Terminal}, and \textbf{Jobs}. During this course we will
  mostly use the \textbf{Console} tab.
\item
  \textbf{Environment pane}: where you can see the objects (data frames,
  vectors, etc.) that are currently in your R session. This pane has
  multiple tabs, including: \textbf{Environment}, \textbf{History},
  \textbf{Connections}, and \textbf{Tutorial}. During this course we
  will mostly use the \textbf{Environment} tab.
\item
  \textbf{Files/Plots/Packages/Help pane}: where you can manage files,
  view plots, manage packages, and access help documentation. This pane
  has multiple tabs, including: \textbf{Files}, \textbf{Plots},
  \textbf{Packages}, \textbf{Help}, and \textbf{Viewer}. During this
  course we will mostly use the \textbf{Files}, \textbf{Plots},
  \textbf{Packages}, and \textbf{Help} tabs.
\end{enumerate}

Our \textbf{Scripts} are in the Source pane tabs. The code / script we
write in R is usually saved in a file with the extension \texttt{.R}.
This file can be opened and edited in the Source pane. Creating a new R
script: File \textgreater{} New File \textgreater{} R Script.

You can run code from the script by selecting the code and clicking the
``Run'' button, or by using the keyboard shortcut
\texttt{Ctrl\ +\ Enter} (Windows) or \texttt{Cmd\ +\ Enter} (Mac).

There is so much more to learn about the RStudio IDE, but we will cover
that as we go along in the course.

\section*{Getting to know R}\label{sec-getting-to-know-r}
\addcontentsline{toc}{section}{Getting to know R}

\markright{Getting to know R}

In our newly opened script file, type the following code:

Then type the following code:

\begin{verbatim}
[1] 2
\end{verbatim}

\begin{verbatim}
[1] 7.389056
\end{verbatim}

\begin{verbatim}
[1] 4
\end{verbatim}

Select all the code and run it (using the ``Run'' button or
\texttt{Ctrl\ +\ Enter} / \texttt{Cmd\ +\ Enter}). You should see the
results of the calculations in the Console pane.

Now try assigning values to named object:

And then print the value of \texttt{c}:

\begin{verbatim}
[1] 15
\end{verbatim}

You should see the value \texttt{15} printed in the Console pane.

We can also create vectors:

\begin{verbatim}
[1] 1 2 3 4 5
\end{verbatim}

And do maths on vectors:

\begin{verbatim}
[1]  2  4  6  8 10
\end{verbatim}

\begin{verbatim}
[1] 11 12 13 14 15
\end{verbatim}

\begin{verbatim}
[1]  1  4  9 16 25
\end{verbatim}

We can vectors of strings (text):

\begin{verbatim}
[1] "apple"  "banana" "cherry"
\end{verbatim}

And can perform operations on strings:

\begin{verbatim}
[1] "I like apple"  "I like banana" "I like cherry"
\end{verbatim}

\begin{verbatim}
[1] "APPLE"  "BANANA" "CHERRY"
\end{verbatim}

And we can create data frames, which are like tables of data

\begin{verbatim}
     Name Age Height
1   Alice  25    165
2     Bob  30    180
3 Charlie  35    175
\end{verbatim}

Above we have numerous examples of functions: \texttt{exp()},
\texttt{sqrt()}, \texttt{c()}, \texttt{paste()}, \texttt{toupper()}, and
\texttt{data.frame()}. Functions are a fundamental part of R
programming. They are used to perform specific tasks, such as
calculations, data manipulation, and data analysis. All functions have a
name and can take arguments (inputs) and return values (outputs). They
are called by writing the function name followed by parentheses, with
any arguments inside the parentheses.

You likely guessed that there is much much more to learn about R, but we
will cover that as we go along in the course.

\section*{Getting help}\label{sec-getting-help}
\addcontentsline{toc}{section}{Getting help}

\markright{Getting help}

R has a built-in help system that you can use to get information about
functions, packages, and other topics. To access the help system, you
can use the \texttt{?} operator followed by the name of the function or
topic you want to learn about. For example, to get help on the
\texttt{mean()} function, you would type:

This will open the help documentation for the \texttt{mean()} function
in the Help pane of RStudio. The documentation includes a description of
the function, its arguments, and examples of how to use it. Some of the
help documentation is very useful and accessible, other is less so. Over
time you will learn which functions and packages have good
documentation, and you will get better and better at understanding R
help files.

Of course you can use any other resources to get help with R, including
online forums, tutorials, and books. Some popular online resources for R
help include:

\begin{itemize}
\tightlist
\item
  \href{https://stackoverflow.com/questions/tagged/r}{Stack Overflow}
\item
  \href{https://community.rstudio.com/}{RStudio Community}
\item
  \href{https://www.r-bloggers.com/}{R-bloggers}
\item
  \href{https://www.r-graph-gallery.com/}{The R Graph Gallery}
\end{itemize}

You can also use search engines like Google to find answers to your R
questions. Just be sure to include ``R'' in your search query to get
relevant results.

AI assistants like ChatGPT can also be useful for getting help with R
programming. You can ask specific questions about R code, functions, and
packages, and get instant responses.

And of course there is always your course instructors and fellow
students to help you out when you get stuck.

\section*{Add-on packages}\label{sec-add-on-packages}
\addcontentsline{toc}{section}{Add-on packages}

\markright{Add-on packages}

R has a vast ecosystem of add-on packages that extend its functionality.
These packages are collections of functions, data, and documentation
that can be installed and loaded into your R session. There are
thousands of packages available on CRAN (the Comprehensive R Archive
Network) and other repositories like Bioconductor and GitHub.

We will be using several packages throughout this course. To install a
package, you can use the \texttt{install.packages()} function. For
example, to install the \texttt{ggplot2} package, you would type:

You can also use the RStudio interface to install packages. Go to the
``Packages'' tab in the bottom right pane, click on ``Install'', type
the name of the package you want to install, and click ``Install''.

You can see which packages are currently installed by looking in the
``Packages'' tab.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

You only need to install a package once. After it is installed, you can
load it into your R session using the \texttt{library()} function. Do
not install packages every time you want to use them; just load them
with \texttt{library()}.

\end{tcolorbox}

\section*{R Version and add-on package versions}\label{sec-r-versions}
\addcontentsline{toc}{section}{R Version and add-on package versions}

\markright{R Version and add-on package versions}

(This section concerns the Desktop version of R and RStudio, and not so
much the Cloud version, because version management is handled for you in
the Cloud.)

R and its add-on packages are constantly being updated and improved.
This can cause problems when trying to install or use packages that
depend on specific versions of R or other packages.

Imagine that the online version of a package has been updated and now
only works with the lastest version of R. If you are using an older
version of R, you may not be able to install or use that package.

Or if a package depends on another package that has been updated, you
may need to update that package as well to use the first package.

This sounds complicated, but there are some simple steps you can take to
reduce the chances of running into version-related problems:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Keep your R version up to date.} New versions of R are
  released every 6 months or so, and they often include important bug
  fixes and new features. You can check your current R version by typing
  \texttt{R.version.string} in the Console. To update R, you can
  download the latest version from the
  \href{https://cran.r-project.org/}{CRAN website}.
\item
  \textbf{Keep your add-on packages up to date.} You can update all your
  installed packages by using the \texttt{update.packages()} function.
  This will check for updates for all installed packages and install the
  latest versions. You can also use the RStudio interface to update
  packages by going to the ``Packages'' tab, clicking on ``Update'',
  selecting the packages you want to update, and clicking ``Install
  Updates''.
\item
  \textbf{Do this well before critical deadlines or important events
  (e.g., exams).} Updating R and packages can sometimes lead to
  unexpected issues, so it's best to do it well in advance of when you
  need everything to work perfectly.
\end{enumerate}

Nevertheless, even with these precautions, you may still encounter
version-related issues from time to time. When this happens, don't
panic!

A common problem you might see is an error message when trying to
install or load a package, indicating that the package requires a newer
version of R or another package. The error / warning message might look
like:

\texttt{warning:\ package\ \textquotesingle{}xyz\textquotesingle{}\ requires\ R\ version\ \textgreater{}=\ 4.2.0}

\texttt{Warning\ in\ install.packages:\ package\ â€˜XYZâ€™\ is\ not\ available\ (for\ R\ version\ 4.2.0)}

These messages indicate that the package you are trying to install or
load requires a newer version of R than the one you currently have. To
fix this, you will need to update your R installation to the required
version or higher. Then its also a good idea to update your packages as
well.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

RStudio is also regularly updated, with new version released every
several months or so. Your version of RStudio is independent of your
version of R, so you can update RStudio without changing your R version.
Note that usually your version of RStudio is not as important as your
version of R and the packages you are using. So updating RStudio is
usually not a high priority and doesn't often help solve problems
related to add on package versions.

\end{tcolorbox}

\section*{R Projects}\label{sec-r-projects}
\addcontentsline{toc}{section}{R Projects}

\markright{R Projects}

I always work within R Projects. R Projects help you to organise your
work and keep all files related to a project in one place. They also
make importing data a breeze.

But what is an R Project? An R Project is a directory (folder) that
contains all the files related to a specific project. When you open an R
Project, RStudio automatically sets the working directory to the project
directory, so you don't have to worry about setting the working
directory manually.

To see if you're working within an R Project, look at the top right of
the RStudio window. If you see the name of your project there, you're
good to go. If you see ``Project: (None)'', then you're not working
within an R Project.

If you click on the project name, a dropdown menu will appear. From
there, you can create a new project, open an existing project, or switch
between projects.

\textbf{Create a new R Project:} File \textgreater{} New Project
\textgreater{} New Directory or Existing Directory \textgreater{} New
Project \textgreater{} Choose a name and location for your project
\textgreater{} Create Project.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Get organised!} Put all files for a project in one folder. For
example, I made a folder called \texttt{BIO144\_2026} and put all files
related to this course in that folder. Within that folder, I have
subfolders for \texttt{data}, \texttt{scripts}, and \texttt{results}. I
then create an R Project in the \texttt{BIO144\_2026} folder. This way,
all files related to the course are in one place, and I can easily find
them later.

\end{tcolorbox}

Now, always open and ensure you're working within the R Project for your
project. As mentioned, you can see the project name at the top right of
the RStudio window. And if its not the correct project, click on the
name to get the drop-down list of available projects from which you can
switch to the correct one.

\section*{Importing data}\label{sec-importing-data}
\addcontentsline{toc}{section}{Importing data}

\markright{Importing data}

First, get some data sets for us to work with. \textbf{XYZ} You can
download them from the course website or use your own data sets. Save
the data files in a folder called \texttt{data} within your R Project
directory.

We will use the \texttt{readr} package to import data into R. The
\texttt{readr} package provides functions to read data from various file
formats, including CSV (comma-separated values) files, tab-separated
values files, and others.

To read a CSV file, we can use the \texttt{read\_csv()} function from
the \texttt{readr} package. For example, to read a CSV file called
\texttt{data.csv}, we can use the following code:

This code will read the \texttt{data.csv} file from the \texttt{data}
folder within the current working directory (which should be the R
Project directory) and store it in a data frame called \texttt{data}.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Easily getting the file path} In RStudio, you can easily get the
file path by putting the cursor in the parentheses of the
\texttt{read\_csv()} function, the press the tab key. A drop-down menu
will appear with options to navigate to the file. This way, you don't
have to type the file path manually.

\end{tcolorbox}

\section*{Viewing the data}\label{sec-viewing-data}
\addcontentsline{toc}{section}{Viewing the data}

\markright{Viewing the data}

Once you've imported your data, you can view it in several ways:

\begin{itemize}
\tightlist
\item
  Click on the data frame in the Environment tab in RStudio to open it
  in a new tab.
\item
  Use the \texttt{View()} function to open the data frame in a new tab
  in RStudio.
\item
  Use the \texttt{head()} function to view the first few rows of the
  data frame.
\item
  Use the \texttt{str()} function to view the structure of the data
  frame, including the variable names and types.
\item
  Use the \texttt{summary()} function to get a summary of the data
  frame, including basic statistics for each variable.
\end{itemize}

Another useful function is \texttt{glimpse()} from the \texttt{dplyr}
package, which provides a quick overview of the data frame.

There are many checks you can do to ensure your data was imported
correctly. For example checking if there are duplicated values in a
variable when there shouldn't be:

\begin{verbatim}
[1] FALSE
\end{verbatim}

The function \texttt{any()} will return \texttt{TRUE} if there are any
duplicated values in the \texttt{Name} variable, and \texttt{FALSE}
otherwise. The function \texttt{duplicated()} returns a logical vector
indicating which values are duplicates. We use the dollar sign
\texttt{\$} to access a specific variable (column) in the data frame. A
logical vector is a vector that contains only \texttt{TRUE} or
\texttt{FALSE} values:

\begin{verbatim}
[1] FALSE FALSE FALSE
\end{verbatim}

All three logicals are \texttt{FALSE}, meaning none of the three are
duplicates. If there were duplicates, the corresponding positions in the
logical vector would be \texttt{TRUE}. For example:

What do you expect the output of \texttt{duplicated(example\_vector)} to
be?

A final check (though not the final one we could do--there are many
others). Let us check for missing values and get a count of how many
there are in each variable. We can do this with the following
\emph{tidyverse} code:

\begin{verbatim}
  Name Age Height
1    0   0      0
\end{verbatim}

Looks complicated eh! Well, that's because it is, for sure. But let's
break it down:

\begin{itemize}
\tightlist
\item
  \texttt{summarise()} creates a new data frame with summary statistics.
\item
  \texttt{across(everything(),\ \textasciitilde{}\ sum(is.na(.)))}
  applies the function \texttt{sum(is.na(.))} to every variable in the
  data frame.
\item
  The \texttt{is.na()} function returns a logical vector indicating
  which values are missing (\texttt{NA}), and the \texttt{sum()}
  function counts the number of \texttt{TRUE} values in that vector
  (i.e., the number of missing values).
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Let's assume your data was imported incorrectly.} This means you
have to inspect it carefully. Check that the variable names are correct,
that the data types are correct (e.g., numeric, character, factor), that
there are the correct number of rows and columns. If you find any
issues, you need to find out what caused them, fix them, and re-import
the data (see below).

\end{tcolorbox}

Common data import problems:

\begin{itemize}
\tightlist
\item
  Incorrect delimiter: If your data file uses a different delimiter
  (e.g., tab, semicolon), you need to specify it in the
  \texttt{read\_csv()} function using the \texttt{delim} argument (e.g.,
  \texttt{read\_delim("data.csv",\ delim\ =\ "\textbackslash{}t")} for
  tab-delimited files).
\item
  Missing values: If your data file uses a specific value to represent
  missing data (e.g., ``NA'', ``-999''), you need to specify it in the
  \texttt{read\_csv()} function using the \texttt{na} argument (e.g.,
  \texttt{read\_csv("data.csv",\ na\ =\ c("NA",\ "-999"))}).
\item
  Only one column: If your data file has only one column, it may be
  because the delimiter is incorrect. Check the delimiter and re-import
  the data with the correct delimiter.
\item
  You opened the downloaded file in Excel and then saved it: Excel may
  have changed the format of the file when you opened and saved it.
  Always work with the original downloaded file.
\item
  Wrong path or file name: Make sure the file path and name are correct.
  Remember, when you work in an R Project, you can place the cursor in
  the parentheses of the \texttt{read\_csv()} function and press the tab
  key to navigate to the file.
\end{itemize}

\section*{Data wrangling}\label{sec-data-wrangling}
\addcontentsline{toc}{section}{Data wrangling}

\markright{Data wrangling}

Now we have our data imported and checked, and we're ready to start
working with it. This process is called data wrangling, and it involves
cleaning, transforming, and reshaping the data to make it suitable for
visualisation and analysis.

\subsection*{Clean the variable names}\label{clean-the-variable-names}
\addcontentsline{toc}{subsection}{Clean the variable names}

The first thing I like to do is standardise and clean up the variable
names. I like to use the \texttt{janitor} package for this:

\begin{verbatim}

Attaching package: 'janitor'
\end{verbatim}

\begin{verbatim}
The following objects are masked from 'package:stats':

    chisq.test, fisher.test
\end{verbatim}

The \texttt{clean\_names()} function from the \texttt{janitor} package
will convert variable names to a consistent format (lowercase, spaces
replaced by underscores, no special characters).

\subsection*{Manipulate the data frame}\label{manipulate-the-data-frame}
\addcontentsline{toc}{subsection}{Manipulate the data frame}

Functions in the \texttt{dplyr} package are used to manipulate data
frames:

\begin{itemize}
\tightlist
\item
  \texttt{select()}: select columns by position, or by name, or by other
  methods
\item
  \texttt{filter()}: select rows that meet a logical condition
\item
  \texttt{slice()}: select rows by position
\item
  \texttt{arrange()}: reorder rows
\item
  \texttt{mutate()}: add new variables
\end{itemize}

The \texttt{dplyr} package also provides functions to group data frames
and to summarize data:

\begin{itemize}
\tightlist
\item
  \texttt{group\_by()}: add to a data frame a grouping structure
\item
  \texttt{summarize()}: summarize data, respecting any grouping
  structure specified by \texttt{group\_by()}
\end{itemize}

The pipe operator \texttt{\textbar{}\textgreater{}} is used to chain
together multiple operations on a data frame.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

Note that you will often see another pipe operator
\texttt{\%\textgreater{}\%} used in examples. The pipe operator
\texttt{\textbar{}\textgreater{}} is a newer version of
\texttt{\%\textgreater{}\%} that is more efficient and easier to use.
The pipe operator \texttt{\textbar{}\textgreater{}} is available in R
version 4.1.0 and later.

\end{tcolorbox}

Lets work through some examples with a sample data frame:

Here is the same dataset with 100 rows:

\subsection*{Select columns
{[}\#select-columns{]}}\label{select-columns-select-columns}
\addcontentsline{toc}{subsection}{Select columns {[}\#select-columns{]}}

We can select columns by name

\begin{verbatim}
# A tibble: 100 x 2
   name       score
   <chr>      <dbl>
 1 Person_001  91.9
 2 Person_002  87.3
 3 Person_003  77.8
 4 Person_004  64.5
 5 Person_005  69.8
 6 Person_006  91.2
 7 Person_007  64.3
 8 Person_008  91.9
 9 Person_009  72.6
10 Person_010  70.3
# i 90 more rows
\end{verbatim}

We can select columns by position

\begin{verbatim}
# A tibble: 100 x 2
   name       score
   <chr>      <dbl>
 1 Person_001  91.9
 2 Person_002  87.3
 3 Person_003  77.8
 4 Person_004  64.5
 5 Person_005  69.8
 6 Person_006  91.2
 7 Person_007  64.3
 8 Person_008  91.9
 9 Person_009  72.6
10 Person_010  70.3
# i 90 more rows
\end{verbatim}

We can select columns by a condition, for example select only the
numeric columns:

\begin{verbatim}
# A tibble: 100 x 2
     age score
   <int> <dbl>
 1    50  91.9
 2    34  87.3
 3    38  77.8
 4    33  64.5
 5    22  69.8
 6    29  91.2
 7    37  64.3
 8    41  91.9
 9    30  72.6
10    24  70.3
# i 90 more rows
\end{verbatim}

We can select a column by pattern matching, using helper functions, for
example select columns that contain the letter ``a'':

\begin{verbatim}
# A tibble: 100 x 2
   name         age
   <chr>      <int>
 1 Person_001    50
 2 Person_002    34
 3 Person_003    38
 4 Person_004    33
 5 Person_005    22
 6 Person_006    29
 7 Person_007    37
 8 Person_008    41
 9 Person_009    30
10 Person_010    24
# i 90 more rows
\end{verbatim}

Other helpers include \texttt{starts\_with()}, \texttt{ends\_with()},
\texttt{matches()}, and \texttt{everything()}.

\subsection*{Filter: Getting particular rows of data
{[}\#filter-rows{]}}\label{filter-getting-particular-rows-of-data-filter-rows}
\addcontentsline{toc}{subsection}{Filter: Getting particular rows of
data {[}\#filter-rows{]}}

To get particular rows of data, we can use the \texttt{filter()}
function. This function takes a \emph{logical condition} as an argument
and returns only the rows that meet that condition. For example, to get
all rows where the Age is greater than 30:

\begin{verbatim}
# A tibble: 66 x 3
   name         age score
   <chr>      <int> <dbl>
 1 Person_001    50  91.9
 2 Person_002    34  87.3
 3 Person_003    38  77.8
 4 Person_004    33  64.5
 5 Person_007    37  64.3
 6 Person_008    41  91.9
 7 Person_011    39  67.3
 8 Person_012    33  96.5
 9 Person_013    41  61.7
10 Person_014    44  80.0
# i 56 more rows
\end{verbatim}

Here, the logical condition is \texttt{age\ \textgreater{}\ 30}.

We can combine multiple conditions using the logical operators
\texttt{\&} (and), \texttt{\textbar{}} (or), and \texttt{!} (not). For
example, to get all rows where the Age is greater than 30 and the Score
is less than 90:

\begin{verbatim}
# A tibble: 60 x 3
   name         age score
   <chr>      <int> <dbl>
 1 Person_002    34  87.3
 2 Person_003    38  77.8
 3 Person_004    33  64.5
 4 Person_007    37  64.3
 5 Person_011    39  67.3
 6 Person_013    41  61.7
 7 Person_014    44  80.0
 8 Person_015    45  87.3
 9 Person_016    46  81.3
10 Person_018    38  82.9
# i 50 more rows
\end{verbatim}

Other logical operators include \texttt{==} (equal to), \texttt{!=} (not
equal to), \texttt{\textless{}=} (less than or equal to), and
\texttt{\textgreater{}=} (greater than or equal to).

\subsection*{Slice: Getting rows by position
{[}\#slice-rows{]}}\label{slice-getting-rows-by-position-slice-rows}
\addcontentsline{toc}{subsection}{Slice: Getting rows by position
{[}\#slice-rows{]}}

The \texttt{slice()} function allows us to get rows by their position in
the data frame. For example, to get the first two rows:

\begin{verbatim}
# A tibble: 2 x 3
  name         age score
  <chr>      <int> <dbl>
1 Person_001    50  91.9
2 Person_002    34  87.3
\end{verbatim}

I very rarely use this function, as I prefer to use \texttt{filter()}
with logical conditions. I can't think of a good use case for this
function right now! Perhaps you can?

\subsection*{Arrange: Reordering rows
{[}\#arrange-rows{]}}\label{arrange-reordering-rows-arrange-rows}
\addcontentsline{toc}{subsection}{Arrange: Reordering rows
{[}\#arrange-rows{]}}

The \texttt{arrange()} function allows us to reorder the rows of a data
frame based on the values in one or more columns. For example, to
reorder the rows by Age in ascending order:

\begin{verbatim}
# A tibble: 100 x 3
   name         age score
   <chr>      <int> <dbl>
 1 Person_064    20  88.8
 2 Person_056    21  79.5
 3 Person_091    21  67.4
 4 Person_005    22  69.8
 5 Person_025    22  74.9
 6 Person_033    23  67.3
 7 Person_092    23  72.4
 8 Person_010    24  70.3
 9 Person_017    24  79.1
10 Person_058    24  72.7
# i 90 more rows
\end{verbatim}

I f we want to reorder the rows by Age in descending order, we can use
the \texttt{desc()} function:

\begin{verbatim}
# A tibble: 100 x 3
   name         age score
   <chr>      <int> <dbl>
 1 Person_001    50  91.9
 2 Person_061    50  79.9
 3 Person_075    50  67.3
 4 Person_085    50  50.1
 5 Person_096    50  86.8
 6 Person_031    49  71.8
 7 Person_078    49  72.6
 8 Person_024    48  81.2
 9 Person_057    48  80.3
10 Person_021    47  66.0
# i 90 more rows
\end{verbatim}

It's unusual to need the rows of a dataset to be arranged in a specific
order, but it can be useful when looking at the data directly.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

Note that when you view the data in RStudio, it will always be arranged
by the row number. In the viewer you can sort by clicking on the column
headers.

\end{tcolorbox}

\subsection*{Mutate: Adding new variables
{[}\#mutate-variables{]}}\label{mutate-adding-new-variables-mutate-variables}
\addcontentsline{toc}{subsection}{Mutate: Adding new variables
{[}\#mutate-variables{]}}

The \texttt{mutate()} function allows us to add new variables to a data
frame. For example, to add a new variable called
\texttt{Age\_in\_5\_years} that is the Age plus 5:

\begin{verbatim}
# A tibble: 100 x 4
   name         age score age_in_5_years
   <chr>      <int> <dbl>          <dbl>
 1 Person_001    50  91.9             55
 2 Person_002    34  87.3             39
 3 Person_003    38  77.8             43
 4 Person_004    33  64.5             38
 5 Person_005    22  69.8             27
 6 Person_006    29  91.2             34
 7 Person_007    37  64.3             42
 8 Person_008    41  91.9             46
 9 Person_009    30  72.6             35
10 Person_010    24  70.3             29
# i 90 more rows
\end{verbatim}

We can add multiple new variables at once:

\begin{verbatim}
# A tibble: 100 x 5
   name         age score age_in_5_years percentage_score
   <chr>      <int> <dbl>          <dbl>            <dbl>
 1 Person_001    50  91.9             55            0.919
 2 Person_002    34  87.3             39            0.873
 3 Person_003    38  77.8             43            0.778
 4 Person_004    33  64.5             38            0.645
 5 Person_005    22  69.8             27            0.698
 6 Person_006    29  91.2             34            0.912
 7 Person_007    37  64.3             42            0.643
 8 Person_008    41  91.9             46            0.919
 9 Person_009    30  72.6             35            0.726
10 Person_010    24  70.3             29            0.703
# i 90 more rows
\end{verbatim}

\subsection*{Working with categorical variables
{[}\#sec-categorical-variables{]}}\label{working-with-categorical-variables-sec-categorical-variables}
\addcontentsline{toc}{subsection}{Working with categorical variables
{[}\#sec-categorical-variables{]}}

Variables in a data frame in R have a \emph{type}. The most common types
of variables are numeric and categorical. Numeric variables are
variables that take on numerical values, such as age or score.
Categorical variables are variables that take on a limited number of
values, often representing categories or groups. In R, categorical
variables are typically have \emph{type}
\texttt{\textless{}chr\textgreater{}} which is \texttt{character}. Or
they can be of type \texttt{\textless{}fct\textgreater{}} which is
\texttt{factor}.

When we import data categorical variable is usually imported as a
\texttt{character} variable. For example, the variable \texttt{name} in
our example dataset is a categorical variable of type
\texttt{character}. Look at the first few rows of the dataset again, and
see that below the variable name it says
\texttt{\textless{}chr\textgreater{}} for the \texttt{name} variable:

\begin{verbatim}
# A tibble: 100 x 3
   name         age score
   <chr>      <int> <dbl>
 1 Person_001    50  91.9
 2 Person_002    34  87.3
 3 Person_003    38  77.8
 4 Person_004    33  64.5
 5 Person_005    22  69.8
 6 Person_006    29  91.2
 7 Person_007    37  64.3
 8 Person_008    41  91.9
 9 Person_009    30  72.6
10 Person_010    24  70.3
# i 90 more rows
\end{verbatim}

This is all totally fine. There are, however, use cases where we might
want to convert a \texttt{character} variable to a \texttt{factor}
variable. Factors are useful when we have a categorical variable with a
fixed number of levels, and we want to specify the order of those
levels. For example, if we had a variable called
\texttt{education\_level} with the values ``High School'',
``Bachelor's'', ``Master's'', and ``PhD'', we might want to convert this
variable to a factor and specify the order of the levels.

Let's make a new dataset to illustrate this:

Look at the structure of this new dataset:

\begin{verbatim}
# A tibble: 5 x 3
  name    education_level   age
  <chr>   <chr>           <dbl>
1 Alice   Bachelor's         19
2 Bob     Master's           23
3 Charlie PhD                25
4 David   High School        16
5 Eve     Bachelor's         20
\end{verbatim}

We can see that the \texttt{education\_level} variable is of type
\texttt{\textless{}chr\textgreater{}}, which is \texttt{character}.

We can convert the \texttt{education\_level} variable to a factor:

\begin{verbatim}
# A tibble: 5 x 3
  name    education_level   age
  <chr>   <fct>           <dbl>
1 Alice   Bachelor's         19
2 Bob     Master's           23
3 Charlie PhD                25
4 David   High School        16
5 Eve     Bachelor's         20
\end{verbatim}

Now, the \texttt{education\_level} variable is of type
\texttt{\textless{}fct\textgreater{}}, which is \texttt{factor}.

Here is a graph of age by education level:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-37-1.pdf}}

We have a problem here: the education levels are not in a sensible
order. The first level is ``Bachelor's'', followed by ``High School'',
``Master's'', and ``PhD''.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

Why do you think the levels are in this order? We didn't tell R to order
them like this! The answer is that R orders factor levels alphabetically
by default. So when we convert a character variable to a factor without
specifying the order of the levels, R will order them alphabetically.

\end{tcolorbox}

It would be much better to have the levels ordered as ``High School'',
``Bachelor's'', ``Master's'', and ``PhD''.

We can fix this by specifying the order of the levels when we convert
the variable to a factor:

Now when we plot the data again, the education levels are in the correct
order:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-39-1.pdf}}

Another use case is when we are making a linear model and want to
specify the reference level for a categorical variable. We will look at
this when we get to linear models. If you want to skip ahead, you can
see how this works in a section at the end of this chapter (Section
\textbf{?@sec-ref-level}).

\section*{Visualisation}\label{sec-visualisation}
\addcontentsline{toc}{section}{Visualisation}

\markright{Visualisation}

There are many many many types of data visualisation. We will not
explore them all in this course! In fact, we will use only a few basic
types of visualisation, but we will use them well and critically. The
three types of visualisation we will focus on are scatter plots,
histograms, and box and whisker plots.

\subsection*{Three basic types of visualisation
{[}\#three-basic-visualisations{]}}\label{three-basic-types-of-visualisation-three-basic-visualisations}
\addcontentsline{toc}{subsection}{Three basic types of visualisation
{[}\#three-basic-visualisations{]}}

\emph{Scatterplots} are used to visualise the relationship between two
continuous variables. Here is an example of a scatterplot:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-40-1.pdf}}

\emph{Histograms} are used to visualise the distribution of a single
continuous variable. The axiss are different to scatterplots: the x-axis
is the variable being measured, and the y-axis is the count (or
frequency) of observations in each bin. A bin is a range of values. Here
is an esample of a histogram:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-41-1.pdf}}

\emph{Box and whisker plots} are used to visualise the distribution of a
continuous variable across different categories. Here is an example of a
box and whisker plot. First we add a new variable that is age group:

The new variable \texttt{age\_group} is a categorical variable with
three levels: ``20-29'', ``30-39'', and ``40-49''. We make this using
the \texttt{case\_when()} function. This function works by checking each
condition (which are given as the arguments to the function) in turn,
and assigning the corresponding value when the condition is true. Now we
can make the box and whisker plot:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-43-1.pdf}}

\subsection*{Understanding ggplot2 syntax
{[}\#understanding-ggplot2{]}}\label{understanding-ggplot2-syntax-understanding-ggplot2}
\addcontentsline{toc}{subsection}{Understanding ggplot2 syntax
{[}\#understanding-ggplot2{]}}

We have used the \texttt{ggplot2} package to create visualisations. The
\texttt{ggplot2} package is based on the grammar of graphics, which
provides a consistent way to create visualisations. It is amazing, and
when it was created it revolutionised data visualisation in R.

You can see that for each of the three visualisations, we use the
\texttt{ggplot()} function to create the base plot, and then we add
layers to the plot using the \texttt{+} operator.

The first argument to the \texttt{ggplot()} function is the data frame
that we want to visualise. The layers that we add to the plot each have
two main components. The first component is the \emph{aesthetic
mappings}, which specify how the variables in the data frame are mapped
to the visual properties of the plot (e.g., x-axis, y-axis, color,
size). The second component is the \emph{geometric object}, which
defines how the data is represented in the plot (e.g., points, lines,
bars).

The \emph{aesthetic mappings} are specified using the \texttt{aes()}
function, which takes arguments that define the mappings. Inside the
\texttt{aes()} function, we specify the variables from the data frame
that we want to map to the visual properties of the plot. For example,
in the scatterplot, we map the \texttt{age} variable to the x-axis and
the \texttt{score} variable to the y-axis using
\texttt{aes(x\ =\ age,\ y\ =\ score)}.

The \emph{geometric object} is specified using functions that start with
\texttt{geom\_}, such as \texttt{geom\_point()},
\texttt{geom\_histogram()}, and \texttt{geom\_boxplot()}.

You will notice that for the scatterplot and the box and whisker plot,
we specify both an x- and a y-variable, but for the histogram we only
specify an x-variable. This is because histograms only have one
variable, which is the variable being measured. The y-axis is
automatically calculated as the count (or frequency) of observations in
each bin.

We can customise many features of the graph using additional arguments
to the \texttt{ggplot()} function and the \texttt{geom\_} functions. For
example, we can add titles and labels to the axes using the
\texttt{labs()} function:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-44-1.pdf}}

We can also change the theme of the plot using the \texttt{theme\_}
functions. For example, to use a minimal theme, and add it the
customisations we already made:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-45-1.pdf}}

There are a million and one ways to customise visualisations in
\texttt{ggplot2}. We will explore many of them during the course in a
rather ad-hoc way. In this course we do not \emph{assess} your skill and
competence in making clear and beautiful visualisations. We will,
however, be very happy to help you make beautiful and effective
visualisations for your assignments and projects. And please be sure
that making beautiful and effective visualisations is a skill that is
very highly valued in the workplace.

\subsection*{Saving ggplot visualisations
{[}\#saving-ggplot{]}}\label{saving-ggplot-visualisations-saving-ggplot}
\addcontentsline{toc}{subsection}{Saving ggplot visualisations
{[}\#saving-ggplot{]}}

Another feature that is very useful is to save ggplot visualisations to
objects and then save to a file (for example a pdf). First, here is how
we save a ggplot to an object:

Now we can save the plot to a file using the \texttt{ggsave()} function:

Note two things about the \texttt{ggsave()} function. First, the first
argument is the file name (including the file extension). The file
extension determines the file type (e.g., pdf, png, jpeg). Second, we
can specify the width and height of the plot in inches.

Also note that the file is saved to the current working directory. When
you're working in an R project, this is usually the base directory of
the project. If you want to save your plots in a folder named
\texttt{plots} you would first need to create the folder (if it doesn't
already exist) and then specify the path in the file name:

\begin{verbatim}
Warning in dir.create("plots"): 'plots' already exists
\end{verbatim}

\section*{Extras}\label{extras}
\addcontentsline{toc}{section}{Extras}

\markright{Extras}

\subsection*{Making reports directly using Quarto
{[}\#quarto-reports{]}}\label{making-reports-directly-using-quarto-quarto-reports}
\addcontentsline{toc}{subsection}{Making reports directly using Quarto
{[}\#quarto-reports{]}}

We don't explicitly ask you to make reports using Quarto in this course,
but it is a very useful skill to have, and I highly recommend you
explore it further in your own time. Here are a few basics to get you
started.

One of the great features of R and RStudio is the ability to create
reports that combine text, code, and visualisations. One of the most
popular tools for this is Quarto (https://quarto.org/), which allows you
to create documents in various formats (HTML, PDF, Word, etc.) using a
combination of \emph{Markdown} and R code.

**Why is this so great???* If you want to show someone your analysis and
visualisation, say a team member or supervisor, it is often good to
prepare a report that explains what you did, perhaps shows the code you
used, and presents the results (including visualisations). One way to go
about this is to prepare a powerpoint presentation or a word document,
and then copy and paste code and visualisations into the document. Its
what I used to do. It works. But it is tedious, error prone, and when
you change something in your code or data, you have to remember to go
back and update the powerpoint or word document.

With Quarto, you can create a report that automatically includes the
code and visualisations directly from your R script. This way, if you
change the code or data, you can simply re-render the report and
everything is automatically updated. It takes away a lot of the
tediousness and potential for errors. And it makes updating reports much
easier.

If you'd like to get started with Quarto, check out the Quarto website
(https://quarto.org/) and the RStudio Quarto documentation
(https://quarto.org/docs/get-started/). There are also many tutorials
and resources available online to help you learn how to use Quarto
effectively.

If you have questions about Quarto, feel free to ask me or TAs during
the practicals, though note that any particular TAs may or may not be
experienced with Quarto themselves.

\subsection*{Combining ggplots with patchwork
{[}\#combining-ggplots{]}}\label{combining-ggplots-with-patchwork-combining-ggplots}
\addcontentsline{toc}{subsection}{Combining ggplots with patchwork
{[}\#combining-ggplots{]}}

We often make multiple ggplots in our analyses. Sometimes it is useful
to combine multiple plots into a single figure for easier comparison or
presentation. We can do with ggplots and the lovely add-on package
called \texttt{patchwork}. The \texttt{patchwork} package allows us to
combine multiple ggplots into a single plot layout. Here is an example
of how to use \texttt{patchwork} to combine the three plots we made
earlier (scatterplot, histogram, and boxplot):

First, load the \texttt{patchwork} package:

Next make the first plot and assign it to an object:

Now make the second plot and assign it to an object:

Now make the third plot and assign it to an object:

Now we can combine the three plots into a single layout using the
\texttt{patchwork} syntax. Here, we arrange \texttt{plot1} on the top
row, and \texttt{plot2} and \texttt{plot3} side by side on the bottom
row:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-53-1.pdf}}

Amazing eh! OK, lets leave it there for now. We'll use ggplot2
throughout the course, and explore more features as we go along.

\subsection*{Setting a reference level in a linear
model}\label{sec-ref-level}
\addcontentsline{toc}{subsection}{Setting a reference level in a linear
model}

Sometimes when fitting linear models with categorical explanatory
(independent) variables, it is useful to set a specific reference level
for the categorical variable. This can help in interpreting the model
coefficients. In R, we can set the reference level using the
\texttt{relevel()} function or by using the \texttt{factor()} function
with the \texttt{levels} argument.

First, let's create a simple dataset:

By default, R will set the first level of the factor (in alphabetical
order) as the reference level. In this case, ``Aspirin'' would be the
reference level. Therefore when we visualise the data:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-55-1.pdf}}

It would be nicer to have the ``Control'' group as the first level on
the left of the x-axis.

Likewise, when we make a linear model:

\begin{verbatim}

Call:
lm(formula = response ~ treatment, data = my_data)

Residuals:
   1    2    3    4    5    6 
 0.5 -0.5 -0.5 -0.5  0.5  0.5 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)          7.5000     0.5000  15.000 0.000643 ***
treatmentControl    -3.0000     0.7071  -4.243 0.023981 *  
treatmentIbuprofen  -1.0000     0.7071  -1.414 0.252215    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7071 on 3 degrees of freedom
Multiple R-squared:  0.8615,    Adjusted R-squared:  0.7692 
F-statistic: 9.333 on 2 and 3 DF,  p-value: 0.05152
\end{verbatim}

The (Intercept) term corresponds to the ``Aspirin'' group, and the
coefficients for ``Control'' and ``Ibuprofen'' are relative to
``Aspirin''. \emph{R} has done this because in the factor levels,
``Aspirin'' comes first alphabetically and was therefore set as the
reference level when the factor variable was created.

If we want to set ``Control'' as the reference level, we can do so using
\texttt{relevel()}:

Now when we visualise the data again:

\pandocbounded{\includegraphics[keepaspectratio]{2.1-R-and-RStudio_files/figure-pdf/unnamed-chunk-58-1.pdf}}

Magic! The ``Control'' group is now the first level on the left of the
x-axis.

And when we fit the linear model again:

\begin{verbatim}

Call:
lm(formula = response ~ treatment, data = my_data)

Residuals:
   1    2    3    4    5    6 
 0.5 -0.5 -0.5 -0.5  0.5  0.5 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)   
(Intercept)          4.5000     0.5000   9.000   0.0029 **
treatmentAspirin     3.0000     0.7071   4.243   0.0240 * 
treatmentIbuprofen   2.0000     0.7071   2.828   0.0663 . 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7071 on 3 degrees of freedom
Multiple R-squared:  0.8615,    Adjusted R-squared:  0.7692 
F-statistic: 9.333 on 2 and 3 DF,  p-value: 0.05152
\end{verbatim}

The (Intercept) term now corresponds to the ``Control'' group, and the
coefficients for ``Aspirin'' and ``Ibuprofen'' are relative to
``Control''. This makes interpretation of the model coefficients more
intuitive.

\bookmarksetup{startatroot}

\chapter*{Regression Part 1 (L3)}\label{regression-part-1-l3}
\addcontentsline{toc}{chapter}{Regression Part 1 (L3)}

\markboth{Regression Part 1 (L3)}{Regression Part 1 (L3)}

\textbf{How Owen will structure the lecture time}

\textbf{The chapter content below is the reference for what students are
expected to know.} During the lecture time Owen will talk through and
explain hopefully most of the content of this chapter. He will write on
a tablet, show figures and other content of this chapter, and may
live-code in RStudio. He will also present questions and ask students to
\emph{Think, Pair, Share}. The \emph{Share} part will sometime be via
clicker, sometimes by telling the class. The same will happen in lecture
3-6.

\section*{Introduction}\label{introduction}
\addcontentsline{toc}{section}{Introduction}

\markright{Introduction}

Linear regression is a common statistical method that models the
relationship between a dependent (response) variable and one or more
independent (explanatory) variables. The relationship is modeled with
the equation for a straight line (\(y = a + bx\)).

With linear regression we can answer questions such as:

\begin{itemize}
\tightlist
\item
  How does the dependent (response) variable change with respect to the
  independent (explanatory) variable?
\item
  What amount of variation in the dependent variable can be explained by
  the independent variable?
\item
  Is there a statistically significant relationship between the
  dependent variable and the independent variable?
\item
  Does the linear model fit the data well?
\end{itemize}

In this chapter / lesson we will explore what is linear regression and
how to use it to answer these questions. We'll cover the following
topics:

\begin{itemize}
\tightlist
\item
  Why use linear regression?
\item
  What is the linear regression model?
\item
  Fitting the regression model (= finding the intercept and the slope).
\item
  Is linear regression a good enough model to use?
\item
  What do we do when things go wrong?
\item
  Transformation of variables/the response.
\item
  Identifying and handling odd data points (aka outliers).
\end{itemize}

In this chapter / lesson we will not discuss the statistical
significance of the model. We will cover this topic in the next chapter
/ lesson.

\subsection*{Why use linear
regression?}\label{why-use-linear-regression}
\addcontentsline{toc}{subsection}{Why use linear regression?}

\begin{itemize}
\tightlist
\item
  It's a good starting point because it is a relatively simple model.
\item
  Relationships are sometimes close enough to linear.
\item
  It's easy to interpret.
\item
  It's easy to use.
\item
  It's actually quite flexible (e.g.~can be used for non-linear
  relationships, e.g., a quadratic model is still a linear model!!! See
  \textbf{?@sec-kind-of-magic}.).
\end{itemize}

\subsection*{An example - blood pressure and
age}\label{an-example---blood-pressure-and-age}
\addcontentsline{toc}{subsection}{An example - blood pressure and age}

There are lots of situations in which linear regression can be useful.
For example, consider hypertension. Hypertension is a condition in which
the blood pressure in the arteries is persistently elevated.
Hypertension is a major risk factor for heart disease, stroke, and
kidney disease. It is estimated that hypertension affects about 1
billion people worldwide. Hypertension is a complex condition that is
influenced by many factors, including age. In fact, it is well known
that blood pressure increases with age. But how much does blood pressure
increase with age? This is a question that can be answered using linear
regression.

Here is an example of a study that used linear regression to answer this
question:
https://journals.lww.com/jhypertension/fulltext/2021/06000/association\_of\_age\_and\_blood\_pressure\_among\_3\_3.15.aspx

In this study, the authors used linear regression to model the
relationship between age and blood pressure. They found that systolic
blood pressure increased by 0.28--0.85 mmHg/year. This is a small
increase, but it is statistically significant. This means that the
observed relationship between age and blood pressure is unlikely to be
due to chance.

Lets look at some simulated example data:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-2-1.pdf}}

Well, that is pretty conclusive. We hardly need statistics. There is a
clear positive relationship between age and systolic blood pressure. But
how can we quantify this relationship? And in less clear-cut cases what
is the strength of evidence for a relationship? This is where linear
regression comes in. Linear regression models the relationship between
age and systolic blood pressure. With linear regression we can answer
the following questions:

\begin{itemize}
\tightlist
\item
  What is the value of the intercept and slope of the relationship?
\item
  Is the relationship different from what we would expect if there were
  no relationship?
\item
  How well does the mathematical representation match the observed
  values?
\item
  How much uncertainty is there in predictions?
\end{itemize}

Lets try to figure some of these out from the visualisation.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#guess-params)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\begin{itemize}
\tightlist
\item
  Make a guess of the slope.
\item
  Make a guess of the intercept (hint be careful, lots of people get
  this wrong).
\end{itemize}

\end{tcolorbox}

\section*{Calculating the intercept and
slope}\label{calculating-the-intercept-and-slope}
\addcontentsline{toc}{section}{Calculating the intercept and slope}

\markright{Calculating the intercept and slope}

\subsection*{Regression from a mathematical
perspective}\label{regression-from-a-mathematical-perspective}
\addcontentsline{toc}{subsection}{Regression from a mathematical
perspective}

Given an \textbf{independent/explanatory variable} (\(X\)) and a
\textbf{dependent/response variable} (\(Y\)) all points \((x_i,y_i)\),
\(i= 1,\ldots, n\), on a straight line follow the equation

\[y_i = \beta_0 + \beta_1 x_i\ .\]

\begin{itemize}
\tightlist
\item
  \(\beta_0\) is the \textbf{intercept} - the value of \(Y\) when
  \(x_i = 0\)
\item
  \(\beta_1\) the \textbf{slope} of the line, also known as the
  regression coefficient of \(X\).
\item
  If \(\beta_0=0\) the line goes through the origin \((x,y)=(0,0)\).
\item
  \textbf{Interpretation} of linear dependency: proportional increase in
  \(y\) with increase (decrease) in \(x\).
\end{itemize}

\subsection*{Finding the intercept and the
slope}\label{finding-the-intercept-and-the-slope}
\addcontentsline{toc}{subsection}{Finding the intercept and the slope}

In a regression analysis, one task is to estimate the intercept and the
slope. These are known as the \textbf{regression coefficients}
\(\beta_0\), \(\beta_1\).

\begin{itemize}
\item
  \textbf{Problem}: For more than two points \((x_i,y_i)\),
  \(i=1,\ldots, n\), there is generally no perfectly fitting line.
\item
  \textbf{Aim:} We want to estimate the parameters \((\beta_0,\beta_1)\)
  of the \textbf{best fitting} line \(Y = \beta_0 + \beta_1 x\).
\item
  \textbf{Idea:} Find the \textbf{best fitting line} by minimizing the
  deviations between the data points \((x_i,y_i)\) and the regression
  line. I.e., minimising the residuals.
\end{itemize}

But which deviations?

These ones?

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-3-1.pdf}}

Or these?

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-4-1.pdf}}

Or maybe even these?

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-5-1.pdf}}

Well, actually its none of these!!!

\subsection*{Least squares}\label{least-squares}
\addcontentsline{toc}{subsection}{Least squares}

For multiple reasons (theoretical aspects and mathematical convenience),
the intercept and slope are estimated using the \textbf{least squares}
approach. In this, yet something else is minimized:

The parameters \(\beta_0\) and \(\beta_1\) are estimated such that the
\textbf{sum of squared vertical distances} (sum of squared residuals /
errors) is minimised.

\textbf{SSE} means \textbf{S}um of \textbf{S}quared \textbf{E}rrors:

\[SSE = \sum_{i=1}^n e_i^2 \]

where,

\[e_i = y_i - \underbrace{(\beta_0 + \beta_1 x_i)}_{=\hat{y}_i} \]
\textbf{Note:} \(\hat y_i = \beta_0 + \beta_1 x_i\) are the
\emph{predicted values}.

In the graph just below, one of these squares is shown in red.

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-6-1.pdf}}

\subsection*{Least squares estimates}\label{least-squares-estimates}
\addcontentsline{toc}{subsection}{Least squares estimates}

With a linear model, we can calculate the least squares estimates of the
parameters \(\beta_0\) and \(\beta_1\) directly using the following
formulas.

For a given sample of data \((x_i,y_i), i=1,..,n\), with mean values
\(\overline{x}\) and \(\overline{y}\), the least squares estimates
\(\hat\beta_0\) and \(\hat\beta_1\) are computed as

\[ \hat\beta_1 = \frac{\sum_{i=1}^n  (y_i - \overline{y}) (x_i - \overline{x})}{ \sum_{i=1}^n (x_i - \overline{x})^2 } = \frac{cov(x,y)}{var(x)}\]

\[\hat\beta_0 = \overline{y} - \hat\beta_1 \overline{x}  \]

Moreover,

\[ \hat\sigma^2 = \frac{1}{n-2}\sum_{i=1}^n e_i^2 \quad \text{with residuals  } e_i = y_i - (\hat\beta_0 + \hat\beta_1 x_i) \]

is an unbiased estimate of the residual variance \(\sigma^2\).

(Derivations of the equations above are in the Stahel script 2.A b.
Hint: differentiate, set to zero, solve.)

\subsection*{\texorpdfstring{Why division by \(n-2\) ensures an unbiased
estimator}{Why division by n-2 ensures an unbiased estimator}}\label{why-division-by-n-2-ensures-an-unbiased-estimator}
\addcontentsline{toc}{subsection}{Why division by \(n-2\) ensures an
unbiased estimator}

When estimating parameters (\(\beta_0\) and \(\beta_1\)), the square of
the residuals is minimised. This fitting process inherently \emph{uses
up} two \emph{degrees of freedom}, as the model forces the residuals to
sum to zero and aligns the slope to best fit the data. I.e., one degree
of freedom is lost due to the estimation of the intercept, and another
due to the estimation of the slope.

The adjustment (division by \(n-2\) instead of \(n\)) compensates for
the loss of variability due to parameter estimation, ensuring the
estimator of the residual variance is unbiased. Mathematically, dividing
by n - 2 adjusts for this loss and gives an accurate estimate of the
population variance when working with sample data.

We'll look at degrees of freedom in more detail later, so don't worry if
this is a bit confusing right now.

\subsection*{Let's do it in R}\label{lets-do-it-in-r}
\addcontentsline{toc}{subsection}{Let's do it in R}

First we read in the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bp\_age\_data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/Simulated\_Blood\_Pressure\_and\_Age\_Data.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The we make a graph of the data:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-8-1.pdf}}

Then we make the linear model, using the \texttt{lm()} function:

Then we can look at the summary of the model. It contains a lot of
information, so can be a bit confusing at first.

\begin{verbatim}

Call:
lm(formula = Systolic_BP ~ Age, data = bp_age_data)

Residuals:
     Min       1Q   Median       3Q      Max 
-13.2195  -3.4434  -0.0808   3.1383  12.6025 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 98.96874    1.46102   67.74   <2e-16 ***
Age          0.82407    0.02771   29.74   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 4.971 on 98 degrees of freedom
Multiple R-squared:  0.9002,    Adjusted R-squared:  0.8992 
F-statistic: 884.4 on 1 and 98 DF,  p-value: < 2.2e-16
\end{verbatim}

How do our guesses of the intercept and slope compare to the guesses we
made earlier?

Recal that the units of the \emph{Age} coefficient are in mmHg per year.
This means that for each additional year of age, the systolic blood
pressure increases by Â´r round(coef(bp\_age\_model){[}2{]},2)Â´ mmHg.

\section*{Dealing with the error}\label{dealing-with-the-error}
\addcontentsline{toc}{section}{Dealing with the error}

\markright{Dealing with the error}

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-11-1.pdf}}

The line is not a perfect fit to the data. There is scatter around the
line.

Some of this scatter could be caused by other factors that influence
blood pressure, such as diet, exercise, and genetics. Also, the there
could be differences due to the measurement instrument (i.e., some
measurement error).

These other factors are not included in the model (only age is in the
model), so they create variation that can only appear in error term.

In the linear regression model the dependent variable \(Y\) is related
to the independent variable \(x\) as

\[Y = \beta_0 + \beta_1 x + \epsilon \ \] where

\begin{itemize}
\tightlist
\item
  \(\epsilon\) is the error term
\item
  \(\beta_0\) is the intercept
\item
  \(\beta_1\) is the slope
\item
  \(\epsilon\) is the error term.
\end{itemize}

The error term captures the difference between the observed value of the
dependent variable and the value predicted by the model. The error term
includes the effects of other factors that influence the dependent
variable, as well as measurement error.

\[Y \quad= \quad \underbrace{\text{expected value}}_{E(Y) = \beta_0 + \beta_1 x} \quad + \quad \underbrace{\text{random error}}_{\epsilon}  \ .\]

Graphically the error term is the vertical distance between the observed
value of the dependent variable and the value predicted by the model.

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-12-1.pdf}}

The error term is also known as the residual. It is the variation that
\emph{resides} (is left over / is left unexplained) after accounting for
the relationship between the dependent and independent variables.

\subsection*{Example in R}\label{example-in-r}
\addcontentsline{toc}{subsection}{Example in R}

Let's look at observed values, expected (predicted) values, and
residuals (error) in R.

The observed values of the response (dependent) variable are already in
the dataset:

\begin{verbatim}
[1] 150.3277 170.0801 139.7174 135.4089 151.9041 122.0296
\end{verbatim}

To get the expected values, we need to find the intercept and slope of
the linear model. We can do this using the \texttt{lm()} function in R.

And we can get the intercept and slope using the \texttt{coef()}
function:

\begin{verbatim}
(Intercept)         Age 
 98.9687381   0.8240678 
\end{verbatim}

We can then use the mutate function from the dplyr package to add the
expected values to the dataset:

And we can get the residuals by subtracting the expected values from the
observed values:

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

We can also get the expected values and residuals directly from the
\texttt{lm} object using the \texttt{fitted()} (or \texttt{predicted()})
and \texttt{residuals()} functions:

\end{tcolorbox}

Now we have a model that gives the expected values (on the regression
line) and that gives us a residual. Because the expected value plus the
residual equals the observed value, if we use each of the residuals as
the error for each respective data point, we end up with a perfect fit
to the data. All we are doing is describing the observed data in a
different way. This is known as over-fitting. In fact, we have gained
very little by fitting the model. We have simply memorized / copied the
data!!!

In order to avoid this, we need to assume something about the residuals
-- we need to \emph{model} the residuals. The most common model for the
residuals is a normal distribution with mean 0 and constant variance.

\[\epsilon \sim N(0,\sigma^2)\]

\textbf{This is known as the normality assumption.} The normality
assumption is important because it allows us to make inferences about
the \emph{population parameters} based on the \emph{sample data}.

The linear regression model then becomes:

\[Y = \beta_0 + \beta_1 x + N(0,\sigma^2) \ \]

where \(\sigma^2\) is the variance of the error term. The variance of
the error term is the amount of variation in the dependent variable that
is not explained by the independent variable. The variance of the error
term is also known as the residual variance.

An alternate and equivalent formulation is that \(Y\) is a random
variable that follows a normal distribution with mean
\(\beta_0 + \beta_1 x\) and variance \(\sigma^2\).

\[Y \sim N(\beta_0 + \beta_1 x, \sigma^2)\]

So, the answer to the question ``how do we deal with the error term'' is
that we model the error term as normally distributed with mean 0 and
constant variance. Put another way, the error term is assumed to be
normally distributed with mean 0 and constant variance.

\subsection*{Back to blood pressure and
age}\label{back-to-blood-pressure-and-age}
\addcontentsline{toc}{subsection}{Back to blood pressure and age}

The mathematical model in this case is:

\[SystolicBP = \beta_0 + \beta_1 \times Age + \epsilon\]

where: \emph{SystolicBP} is the dependent (response) variable,
\(\beta_0\) is the intercept, \(\beta_1\) is the coefficient of Age,
\emph{Age} is the independent (explanatory) variable, \(\epsilon\) is
the error term.

Let's ensure we understand this, by thinking about the units of the
variables in this model. This can be very useful because it can help us
to understand the model better and to check that the model makes sense.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, pair, share (\#what-units)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\begin{itemize}
\tightlist
\item
  What are the units of blood pressure?
\item
  What are the units of age?
\item
  What are the units of the intercept?
\item
  What are the units of the coefficient of Age?
\item
  What are the units of the error term?
\end{itemize}

\end{tcolorbox}

\section*{Is the model good enough to
use?}\label{is-the-model-good-enough-to-use}
\addcontentsline{toc}{section}{Is the model good enough to use?}

\markright{Is the model good enough to use?}

\begin{itemize}
\tightlist
\item
  All models are wrong, but is ours good enough to be useful?
\item
  Are the assumption of the model justified?
\item
  It would be very unwise to use the model before we know if it is good
  enough to use.
\item
  \emph{Don't jump out of an aeroplane until you know your parachute is
  good enough!}
\end{itemize}

\subsection*{What assumptions do we
make?}\label{what-assumptions-do-we-make}
\addcontentsline{toc}{subsection}{What assumptions do we make?}

We already heard about one. We assume that the residuals follow a
\(N(0,\sigma^2)\) distribution (that is, a Gaussian / Normal distrution
with mean of zero and variance of \(\sigma^2\)). We make this assumption
because it is often well enough met, and it gives great mathematical
tractability.

This assumption implies that:

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  The \(\epsilon_i\) are normally distributed.
\item
  \(\epsilon_i\) has constant variance: \(Var(\epsilon_i)=\sigma^2\).
\item
  The \(\epsilon_i\) are independent of each other.
\end{enumerate}

Furthermore:

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  we assumed a linear relationship.
\item
  implies there are no outliers (implied by (a) above)
\end{enumerate}

Lets go through each five assumptions.

\subsection*{(a) Normally distributed
residuals}\label{a-normally-distributed-residuals}
\addcontentsline{toc}{subsection}{(a) Normally distributed residuals}

Recall that we make the assumption that the residuals are normally
distributed with mean 0 and constant variance:

\[\epsilon \sim N(0,\sigma^2)\]

Here we are concerned with the first part of this assumption, that the
residuals are normally distributed.

What does this mean? How can we check it?

A normal distribution is symmetric and bell-shaped\ldots{}

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-19-1.pdf}}

Lets look at the frequency distribution of the residuals of the linear
regression of blood pressure and age:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-20-1.pdf}}

The normal distribution assumption (a) seems ok as well.

\subsection*{(a) Normally distributed residuals: The
QQ-plot}\label{a-normally-distributed-residuals-the-qq-plot}
\addcontentsline{toc}{subsection}{(a) Normally distributed residuals:
The QQ-plot}

Usually, not the histogram of the residuals is plotted, but the
so-called \textbf{quantile-quantile} (QQ) plot. The quantiles of the
observed distribution are plotted against the quantiles of the
respective theoretical (normal) distribution:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-21-1.pdf}}

If the points lie approximately on a straight line, the data is fairly
normally distributed.

This is often ``tested'' by eye, and needs some experience.

\emph{But what on earth is a quantile???}

Imagine we make 21 measures of something, say 21 blood pressures:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-22-1.pdf}}

The median of these is 127.8. The median is the 50\% or 0.5 quantile,
because half the data points are above it, and half below.

\begin{verbatim}
  50% 
127.8 
\end{verbatim}

The \emph{theoretical quantiles} come from the normal distribution. The
\emph{sample quantiles} come from the distribution of our residuals.

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-24-1.pdf}}

\subsubsection*{How do I know if a QQ-plot looks
``good''?}\label{how-do-i-know-if-a-qq-plot-looks-good}
\addcontentsline{toc}{subsubsection}{How do I know if a QQ-plot looks
``good''?}

There is \textbf{no quantitative rule} to answer this question. Instead
experience is needed. You can gain this experience from simulations. To
this end, we can generate the same number of data points of a normally
distributed variable and compare this simulated qqplot to our observed
one.

Example: Generate 100 points \(\epsilon_i \sim N(0,1)\) each time:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-25-1.pdf}}

Each of the graphs above has data points that are randomly generated
from a normal distribution. In all cases the data points are close to
the line. This is what we would expect if the data were normally
distributed. The amount of deviation from the line is what we would
expect from random variation, and so seeing this amount of variation in
a QQ-plot of your model should not be cause for concern.

\subsection*{(b) Constant error variance
(homoscedasticity)}\label{b-constant-error-variance-homoscedasticity}
\addcontentsline{toc}{subsection}{(b) Constant error variance
(homoscedasticity)}

Recall that we assume the errors are normally distributed with constant
variance \(\sigma^2\):

\[\epsilon_i \sim N(0, \sigma^2)\]

Here we're concerned with the second part of this assumption, that the
variance is constant.That is, variance of the residuals is a constant:
\(\text{Var}(\epsilon_i) = \sigma^2\). And not, for example
\(\text{Var}(\epsilon_i) = \sigma^2 \cdot x_i\).

Put another way, we're interested if the size of the residuals tends to
show a pattern with the fitted values. By \emph{size} of the residuals
we mean the \emph{absolute value} of the residuals. In fact, we often
look at the square root of the absolute value of the standardized
residuals:

\[R_i = \frac{\epsilon_i}{\hat{\sigma}}\] Where \(\hat{\sigma}\) is the
estimated standard deviation of the residuals:

\[\hat{\sigma} = \sqrt{\frac{1}{n-2} \sum_{i=1}^n \epsilon_i^2}\]

So that the full equation of the square root of the standardised
residuals is:

\[\sqrt{|R_i|} = \sqrt{\left|\frac{\epsilon_i}{\hat{\sigma}}\right|}\]

To look to see if the variance of the residuals is constant, we need to
see if there is any relationship between the size of the residuals and
the fitted values. A commonly used visualistion for this is a plot of
the size of the residuals against the fitted values.

Lets first calculated the \(\sqrt{|R_i|}\) values for our blood pressure
model:

And now visualise the relationship between the fitted values and the
size of the residuals:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-27-1.pdf}}

This graph is known as the scale-location plot. It is particularly
suited to check the assumption of equal variances
(\textbf{homoscedasticity / HomoskedastizitÃ¤t}). There should be
\textbf{no trend} or pattern.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

We can also use the built-in plot function for linear models to create
this plot. It is the third plot in the set of diagnostic plots.

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-28-1.pdf}}

\end{tcolorbox}

\subsubsection*{How it looks with the variance increasing with the
fitted
values}\label{how-it-looks-with-the-variance-increasing-with-the-fitted-values}
\addcontentsline{toc}{subsubsection}{How it looks with the variance
increasing with the fitted values}

Here's a graphical example of how it would look if the variance of the
residuals increases with the fitted values.

First here is a graph of the relationship:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-29-1.pdf}}

And here the scale-location plot for a linear model of that data:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-30-1.pdf}}

\subsection*{(c) Independence (residuals are independent of each
other)}\label{c-independence-residuals-are-independent-of-each-other}
\addcontentsline{toc}{subsection}{(c) Independence (residuals are
independent of each other)}

We assume that the residuals (\(\epsilon_i\)) are independent of each
other. This means that the value of one residual is not somehow related
to the value of another.

The dataset about blood pressure we looked at contained 100
observations, each one made from a different person. In such a study
design, we could be safe in the assumption that the people are
independent, and therefore the assumption that the residuals are
independent.

Imagine, however, if we had 100 observations of blood pressure collected
from 50 people, because we measured the blood pressure of each person
twice. In this case, the residuals would not be independent, because two
measures of the blood pressure of the same person are likely to be
similar. A person is likely to have a high blood pressure in both
measurements, or a low blood pressure in both measurements. This would
mean they have a high residual in both measurements, or a low residual
in both measurements.

In this case, we would need to account for the fact that the residuals
are not independent. We would need to use a more complex model, such as
a mixed effects model, to account for the fact that the residuals are
not independent. We will talk about this again in the last week of this
course.

In general, you should always think about the study design when you are
analysing data. You should always think about whether the residuals are
likely to be independent of each other. If they are not, you should
think about how you can account for this in your analysis.

A good way to assess if there could be dependencies in the residuals is
to be critical about what is the unit of observation in the data. In the
blood pressure example, the unit of observation is the person. Count the
number of persons in the study. If there are fewer persons than
observations, then at least some people must have been measured at least
twice. Repeating measures on the same person is a common way to get
dependent residuals.

So, to check the assumption of independence, you should:

\begin{itemize}
\tightlist
\item
  Think carefully about the study design.
\item
  Think carefully about the unit of observation in the data.
\item
  Compare the number of observations to the number of units of
  observation.
\end{itemize}

\subsection*{(d) Linearity assumption}\label{d-linearity-assumption}
\addcontentsline{toc}{subsection}{(d) Linearity assumption}

The linearity assumption states that the relationship between the
independent variable and the dependent variable is linear. This means
that the dependent variable changes by a constant amount for a one-unit
change in the independent variable. And that this slope is does not
change with the value of the independent variable.

The blood pressure data seems to be linear:

\begin{verbatim}
Warning: `fortify(<lm>)` was deprecated in ggplot2 3.6.0.
i Please use `broom::augment(<lm>)` instead.
i The deprecated feature was likely used in the ggplot2 package.
  Please report the issue at <https://github.com/tidyverse/ggplot2/issues>.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-31-1.pdf}}

In contrast, look at this linear regression through data that appears
non-linear:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-32-1.pdf}}

And with the residuals shown as red lines:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-33-1.pdf}}

At low values of \(y\), the residuals are positive, at intermediate
values of \(y\) the residuals are negative, and at high values of \(y\)
the residuals are positive. This pattern in the residuals is a sign that
the relationship between \(x\) and \(y\) is not linear.

We can plot the value of the residuals against the \(y\) value directly,
instead of looking at the pattern in the graph above. This is called a
\textbf{Tukey-Anscombe plot}. It is a graph of the residuals versus the
fitted \(y\) values:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-34-1.pdf}}

We can very clearly see pattern in the residuals in this Tukey-Anscombe
plot. The residuals are positive, then negative, then positive, as the
fitted \(y\) value gets larger.

We can also make this Tukey-Anscombe plot using the built-in plot
function for linear models in R:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-35-1.pdf}}

The red line in the Tukey-Anscombe plot is a loess smooth. It is
automatically added to the plot. It is a way of estimating the pattern
in the residuals. If the red line is not flat, then there is a pattern
in the residuals. However, the loess smooth is not always reliable. It
is a good idea to look at the residuals directly, without this smooth.

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-36-1.pdf}}

The data here is simulated to show a very clear pattern in the
residuals. In real data, the pattern might not be so clear. But if you
suspect you see a pattern in the residuals, it could be a sign that the
relationship between the independent and dependent variable is not
linear.

Here is the Tukey-Anscombe plot for the blood pressure data:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-37-1.pdf}}

There is very little evidence of any pattern in the residuals. This data
is simulated with a truly linear relationship, so we would not expect to
see any pattern in the residuals.

\subsection*{(e) No outliers}\label{e-no-outliers}
\addcontentsline{toc}{subsection}{(e) No outliers}

An outlier is a data point that is very different from the other data
points. Outliers can have a big effect on the results of a regression
analysis. They can pull the line of best fit towards them, and make the
line of best fit a poor representation of the data.

Lets again look at the blood pressure versus age data:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-38-1.pdf}}

There are no obvious outliers in this data. The data points are all
close to the line of best fit. This is a good sign that the line of best
fit is a good representation of the data.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#odd-data)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

Where on this graph would you expect to see particularly influential
outliers? Influential in the sense that they would have a large effect
on the slope of the line of best fit.

\end{tcolorbox}

Data points that are far from the mean of the independent variable have
a large effect on the value of the slope. These data points have a large
leverage. They are data points that are far from the other data points
in the \(x\) direction.

We can think of this with the analogy of a seesaw. The slope of the line
of best fit is like the pivot point of a seesaw. Data points that are
far from the pivot point have a large effect on the slope. Data points
that are close to the pivot point have a small effect on the slope.

A measure of distance from the pivot point is called the \(leverage\) of
a data point. In simple regression, the leverage of individual \(i\) is
defined as

\(h_{i} = (1/n) + (x_i-\overline{x})^2 / SSX\).

where \(SSX = \sum_{i=1}^n (x_i - \overline{x})^2\). (\textbf{S}um of
\textbf{S}quares of \textbf{\(X\)})

So, the leverage of a data point is inversely related to \(n\) (the
number of data points). The leverage of a data point is also inversely
related to the sum of the squares of the \(x\) values. The leverage of a
data point is directly related to the square of the distance of the
\(x\) value from the mean of the \(x\) values.

More intuitively perhaps, the leverage of a data point will be greater
when the are fewer other data points. It will also be greater when the
distance from the mean value of \(x\) is greater.

Going back to the analogy of a seesaw, with data points as children on
the seesaw, the leverage of a data point is like the distance from the
pivot a child sits. But we also have children of different weights. A
lighter child will have less effect on the tilt of the seesaw. A heavier
one will have a greater effect on the tilt. A heavier child sitting far
from the pivot will have a very large effect.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#like-weight)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

What quantity that we already experienced is like the weight of the
child?

\end{tcolorbox}

The size of the residuals are like the weight of the child. Data points
with large residuals have a large effect on the slope of the line of
best fit. Data points with small residuals have a small effect on the
slope of the line of best fit.

So the overall effect of a data point on the slope of the line of best
fit is a combination of the leverage and the residual. This quantity is
called the \(influence\) of a data point.

Let's add a rather extreme data point to the blood pressure versus age
data:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-39-1.pdf}}

This is a bit ridiculous, but it is a good example of an outlier. The
data point is far from the other data points. It has a large residual.
And it is a long way from the pivot (the middle of the \(x\) data) so
has large leverage.

We can make a histogram of the residuals and see that the outlier has a
large residual:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-40-1.pdf}}

And we can see that the leverage is large.

There is a graph that we can look at to see the influence of a data
point. This is called a \(Cook's\) \(distance\) plot. The Cook's
distance of a data point is a measure of how much the slope of the line
of best fit changes when that data point is removed. The Cook's distance
of a data point is defined as

\(D_i = \sum_{j=1}^n (\hat{y}_j - \hat{y}_{j(i)})^2 / (p \times MSE)\).

where \(\hat{y}_j\) is the predicted value of the dependent variable for
data point \(j\), \(\hat{y}_{j(i)}\) is the predicted value of the
dependent variable for data point \(j\) when data point \(i\) is
removed, \(p\) is the number of parameters in the model (2 in this
case), \(MSE\) is the mean squared error of the model.

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-41-1.pdf}}

But does it have a large influence on the value of the slope? In the
next graph we show the line of best fit with the outlier (blue line) and
without the outlier (red line).

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-42-1.pdf}}

No, the outlier doesn't have much influence on the slope. The outlier
has a large leverage. It is far from the pivot. But it does not have
such a large effect (influence) on the slope. This is in large part
because there are a lot data points (100) that are quite tightly
arranged around the regression line.

\subsubsection*{Graphical illustration of the leverage
effect}\label{graphical-illustration-of-the-leverage-effect}
\addcontentsline{toc}{subsubsection}{Graphical illustration of the
leverage effect}

Data points with \(x_i\) values far from the mean have a stronger
leverage effect than when \(x_i\approx \overline{x}\):

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-43-1.pdf}}

The outlier (red circle) in the middle plot ``pulls'' the regression
line in its direction and has large influence on the slope. THe outlier
(red circle) in the right plot has less influence on the slope because
it is closer to the mean of \(x\).

\subsubsection*{Leverage plot
(Hebelarm-Diagramm)}\label{leverage-plot-hebelarm-diagramm}
\addcontentsline{toc}{subsubsection}{Leverage plot (Hebelarm-Diagramm)}

In the leverage plot, (standardized) residuals \(\tilde{R_i}\) are
plotted against the leverage \(H_{ii}\) :

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-44-1.pdf}}

Critical ranges are the top and bottom right corners!!

Here, observations 71, 85, and 87 are labelled as potential outliers.

Some texts will give a rule of thumb that points with Cook's distances
greater than 1 should be considered influential, while others claim a
reasonable rule of thumb is \(4 / ( n - p - 1 )\) where \(n\) is the
sample size, and \(p\) is the number of \(beta\) parameters.

\section*{What can go ``wrong'' during the modeling
process?}\label{what-can-go-wrong-during-the-modeling-process}
\addcontentsline{toc}{section}{What can go ``wrong'' during the modeling
process?}

\markright{What can go ``wrong'' during the modeling process?}

Answer: a lot of things!

\begin{itemize}
\tightlist
\item
  Non-linearity. We assumed a linear relationship between the response
  and the explanatory variables. But this is not always the case in
  practice. We might find that the relationship is curved and not well
  represtented by a straight line.
\item
  Non-normal distribution of residuals. The QQ-plot data might deviate
  from the straight line so much that we get worried!
\item
  Heteroscadisticity (non-constant variance). We assumed
  homoscadisticity, but the residuals might show a pattern.
\item
  Data point with high influence. We might have a data point that has a
  large influence on the slope of the line of best fit.
\end{itemize}

\subsection*{What to do when things ``go
wrong''?}\label{what-to-do-when-things-go-wrong}
\addcontentsline{toc}{subsection}{What to do when things ``go wrong''?}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Now: Transform the response and/or explanatory variables.
\item
  Now: Take care of outliers.
\item
  Later in the course: Improve the model, e.g., by adding additional
  terms or interactions.
\item
  Later in the course: Use another model family (generalized or
  nonlinear regression model).
\end{enumerate}

\subsection*{Dealing with
non-linearity}\label{dealing-with-non-linearity}
\addcontentsline{toc}{subsection}{Dealing with non-linearity}

Here's another example of \(y\) and \(x\) that are not linearly related:

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-45-1.pdf}}

One way to deal with this is to transform the response variable \(Y\).
Here we try two different transformations: \(\log_{10}(Y)\) and
\(\sqrt{Y}\).

Square root transform of the response variable \(Y\):

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-46-1.pdf}}

Not great.

Log transformation of the response variable \(Y\):

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-47-1.pdf}}

Nope. Still some evidence of non-linearity.

What about transforming the explanatory variable \(X\) as well?

\pandocbounded{\includegraphics[keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-48-1.pdf}}

Let's look at the four diagnostic plots for the log-log-transformed
data:

\begin{center}
\includegraphics[width=7cm,height=\textheight,keepaspectratio]{4.1-regression-part1_files/figure-pdf/unnamed-chunk-49-1.pdf}
\end{center}

All looks pretty good except for the scale-location plot, which shows a
bit of a pattern. But overall, this looks much better than our original
model.

But\ldots{} how to know which transformation to use\ldots? It's a bit of
trial and error. But we can use the diagnostic plots to help us.

\textbf{Very very important} is that we do this trial and error before
we start using the model. E.g., we don't want to jump from the aeroplane
and then find out that our parachute is not working properly! And then
try to fix the parachute while we are falling\ldots.

Likewise, we must not start using the model and then try to fix it. We
need to make sure our model is in good working order before we start
using it.

One of the traps we could fall into is called ``p-hacking''. This is
when we try different transformation until we find one that gives us the
\textbf{result we want}, for example significant relationship. This is a
big no-no in statistics. We need to decide on the model (including any
transformations) before we start using it.

\subsection*{Common transformations}\label{common-transformations}
\addcontentsline{toc}{subsection}{Common transformations}

Which transformations could be considered? There is no simple answer.
But some guidelines. E.g. if we see non-linearity and increasing
variance with increasing fitted values, then a log transform may improve
matter.

Some common and useful transformations are:

\begin{itemize}
\tightlist
\item
  The log transformation for concentrations and absolute values.
\item
  The square-root transformation for count data.
\item
  The arcsin square-root \(\arcsin(\sqrt{\cdot})\) transformation for
  proportions/percentages.
\end{itemize}

Transformations can also be applied on explanatory variables, as we saw
in the example above.

\subsection*{Outliers}\label{outliers}
\addcontentsline{toc}{subsection}{Outliers}

What do we do when we identify the presence of one or more outliers?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start by checking the ``correctness'' of the data. Is there a typo or
  a decimal point that was shifted by mistake? Check both the response
  and explanatory variables.
\item
  If not, ask whether the model could be improved. Do reasonable
  transformations of the response and/or explanatory variables eliminate
  the outlier? Do the residuals have a distribution with a long tail
  (which makes it more likely that extreme observations occur)?
\item
  Sometimes, an outlier may be the most interesting observation in a
  dataset! Was the outlier created by some interesting but different
  process from the other data points?
\item
  Consider that outliers can also occur just by chance!
\item
  Only if you decide to report the results of both scenario can you
  check if inclusion/exclusion changes the qualitative conclusion, and
  by how much it changes the quantitative conclusion.
\end{enumerate}

\subsection*{Removing outliers}\label{removing-outliers}
\addcontentsline{toc}{subsection}{Removing outliers}

It might seem tempting to remove observations that apparently don't fit
into the picture. However:

\begin{itemize}
\tightlist
\item
  Do this \textbf{only with greatest care} e.g., if an observation has
  extremely implausible values!\\
\item
  Before deleting outliers, check points 1-5 above.
\item
  When removing outliers, \textbf{you must mention this in your report}.
\end{itemize}

During the course we'll see many more examples of things going at least
a bit wrong. And we'll do our best to improve the model, so we can be
confident in it, and start to use it. Which we will start to do in the
next lesson. But before we wrap up, some good news\ldots{}

\section*{Its a kind of magic\ldots{}}\label{sec-kind-of-magic}
\addcontentsline{toc}{section}{Its a kind of magic\ldots{}}

\markright{Its a kind of magic\ldots{}}

Above, we learned about linear regression, the equation for it, how to
estimate the coefficients, and how to check the assumptions. There was a
lot of information, and it might seem a bit overwhelming.

You might also be aware that there are quite a few other types of
statistical model, such as multiple regression, t-test, ANOVA, two-way
ANOVA, and ANCOVA. It could be worrying to think that you need to learn
so much new information for each of these types of tests.

But this is where the kind-of-magic happens. The good news is that the
linear regression model is a special case of what is called a
\emph{general linear model}, or just \emph{linear model} for short. And
that all the tests mentioned above are also types of \emph{linear
model}. So, once you have learned about linear regression, you have
learned a lot about linear models, and therefore also a lot about all of
these other tests as well.

Moreover, the same function in R `lm' is used to make all those
statistical models Awesome.

\subsection*{So what is a linear
model?}\label{so-what-is-a-linear-model}
\addcontentsline{toc}{subsection}{So what is a linear model?}

A linear model is a model where the relationship between the dependent
variable and the independent variables is linear. That is, the dependent
variable can be expressed as a linear combination of the independent
variables. An example of a linear model is:

\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p + \epsilon\]

where: \(y\) is the dependent variable, \(\beta_0\) is the intercept,
\(\beta_1, \beta_2, \ldots, \beta_p\) are the coefficients of the
independent variables, \(x_1, x_2, \ldots, x_p\) are the independent
variables, \(\epsilon\) is the error term.

In contrast, a non-linear model is a model where the relationship
between the dependent variable and the independent variables is
non-linear. An example of a non-linear model is the exponential growth
model:

\[y = \beta_0 + \beta_1 e^{\beta_2 x} + \epsilon\]

where: y is the dependent variable, \(\beta_0\) is the intercept,
\(\beta_1, \beta_2\) are the coefficients of the independent variables,
\(x\) is the independent variable, \(\epsilon\) is the error term.

Keep in mind that a model with a quadratic term is still a linear model.
For example:

\[y = \beta_0 + \beta_1 x_1 + \beta_2 x^2 + \epsilon\]

is still a linear model. We can see this if we substitute \(x^2\) with a
new variable \(x_2\), where \(x_2 = x^2\). The model then becomes:

\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\]

This is clearly a linear model.

\bookmarksetup{startatroot}

\chapter*{Regression Part 2 (L4)}\label{regression-part-2-l4}
\addcontentsline{toc}{chapter}{Regression Part 2 (L4)}

\markboth{Regression Part 2 (L4)}{Regression Part 2 (L4)}

\textbf{How Owen will structure the lecture time}

\textbf{The chapter content below is the reference for what students are
expected to know.} During the lecture time Owen will talk through and
explain hopefully most of the content of this chapter. He will write on
a tablet, show figures and other content of this chapter, and may
live-code in RStudio. He will also present questions and ask students to
\emph{Think, Pair, Share}. The \emph{Share} part will sometime be via
clicker, sometimes by telling the class. The same will happen in lecture
3-6.

\section*{Introduction}\label{introduction-1}
\addcontentsline{toc}{section}{Introduction}

\markright{Introduction}

Now that we have a satisfactory model, we can start to use it. In the
following material, you will learn:

\begin{itemize}
\tightlist
\item
  How to measure how good is the regression (correlation and \(R^2\)).
\item
  How to test if the parameter estimates are compatible with some
  specific value (\(t\)-test).
\item
  How to find the range of parameters values are compatible with the
  data (confidence intervals).
\item
  How to find the regression lines compatible with the data (confidence
  band).
\item
  How to calculate plausible values of newly collected data (prediction
  band).
\end{itemize}

\subsection*{Accompanying reading
material}\label{accompanying-reading-material}
\addcontentsline{toc}{subsection}{Accompanying reading material}

\section*{How good is the regression
model?}\label{how-good-is-the-regression-model}
\addcontentsline{toc}{section}{How good is the regression model?}

\markright{How good is the regression model?}

What would a good regression model look like? What would a bad one look
like? One could say that a good regression model is one that explains
the dependent variable well. But what could we mean by ``explains the
data well''?

Take these two examples.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-2-1.pdf}}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#better-model)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

In which of these two would you say the model is better, and in which is
it worse?

\end{tcolorbox}

The first model seems to fit the data well, while the second one does
not. But how can we quantify this?

Let's say that we will measure the goodness of the model by the amount
of variability of the dependent variable that is explained by the
independent variable. To do this we need to do the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Measure the total variability of the dependent variable (total sum of
  squares, \(SST\)).
\item
  Measure the amount of variability of the dependent variable that is
  explained by the independent variable (model sum of squares, \(SSM\)).
\item
  Measure the variability of the dependent variable that is not
  explained by the independent variable (error sum of squares, \(SSE\)).
\item
  Calculate the proportion of variability of the dependent variable that
  is explained by the independent variable (\(R^2\), pronounced as
  ``r-squared'') (also known as the coefficient of determination)
  (\(R^2\) = \(SSM/SST\)).
\end{enumerate}

\textbf{Importantly, note that we will calculate \(SSM\) and \(SSE\) so
that they sum up to \(SST\). I.e., \(SST = SSM + SSE\). That is, the
total variability is the sum of what is explained by the model and what
remains unexplained.}

Let's take each in turn:

\subsection*{\texorpdfstring{\(SST\)}{SST}}\label{sst}
\addcontentsline{toc}{subsection}{\(SST\)}

\textbf{1. The total variability of the dependent variable is the sum of
the squared differences between the dependent variable and its mean.
This is called the total sum of squares (\(SST\)).}

\[SST = \sum_{i=1}^{n} (y_i - \bar{y})^2\]

where: \(y_i\) is the dependent variable, \(\bar{y}\) is the mean of the
dependent variable, \(n\) is the number of observations.

\textbf{Note that sometimes \(SST\) is referred to as \(SSY\) (sum of
squares of \(y\)).}

Graphically, this is the sum of the square of the blue residuals as
shown in the following graph, where the horizontal dashed line is at the
value of the mean of the dependent variable.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-3-1.pdf}}

We can calculate this in R as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SST }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y1 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y1))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection*{SSM and SSE}\label{ssm-and-sse}
\addcontentsline{toc}{subsection}{SSM and SSE}

Now the next two steps, that is getting the model sum of squares (SSM)
and the error sum of squares (SSE) are a bit more complicated. To do
this we need to fit a regression model to the data. Let's see this
graphically, and divide the data into the explained and unexplained
parts.

Make a graph with vertical lines connecting the data to the mean of the
data, but with each line two parts, one from the mean to the data, and
one from the data to the predicted value.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-5-1.pdf}}

In this graph, the square of the length of the green lines is the model
sum of squares (\(SST\)). The square of the length of the red lines is
the error sum of squares (\(SSE\)).

In a better model the length of the green lines will be \textbf{longer}
(the square of these gives the \(SMM\), the variability explained by the
model). And the length of the red lines will be \textbf{shorter} (the
square of these gives the \(SSE\), the variability not explained by the
model).

\subsection*{\texorpdfstring{\(SSM\)}{SSM}}\label{ssm}
\addcontentsline{toc}{subsection}{\(SSM\)}

Next we will do the second step, that is calculate the model sum of
squares (\(SSM\)).

\textbf{2. The amount of variability of the dependent variable that is
explained by the independent variable is called the model sum of squares
(\(SSM\)).}

This is the difference between the predicted value of the dependent
variable and the mean of the dependent variable, squared and summed:

\[SSE = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2\]

where: \(\hat{y}_i\) is the predicted value of the dependent variable,

In R, we calculate this as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\NormalTok{y1\_predicted }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(m1)}
\NormalTok{SSM }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y1\_predicted }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y1))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{SSM}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 339.7423
\end{verbatim}

\subsection*{\texorpdfstring{\(SSE\)}{SSE}}\label{sse}
\addcontentsline{toc}{subsection}{\(SSE\)}

Third, we calculate the error sum of squares (\(SSE\)) with either of
two methods. We could calculate it as the sum of the squared residuals,
or as the difference between the total sum of squares and the model sum
of squares:

\[SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = SST - SSM\] Let's calculate
this in R uses both approaches:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSE }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y1 }\SpecialCharTok{{-}}\NormalTok{ y1\_predicted)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{SSE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 13.62997
\end{verbatim}

Or\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSE }\OtherTok{\textless{}{-}}\NormalTok{ SST }\SpecialCharTok{{-}}\NormalTok{ SSM}
\NormalTok{SSE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 13.62997
\end{verbatim}

\subsection*{\texorpdfstring{\(R^2\)}{R\^{}2}}\label{r2}
\addcontentsline{toc}{subsection}{\(R^2\)}

Finally, we calculate the proportion of variability of the dependent
variable that is explained by the independent variable (\(R^2\)):

\[R^2 = \frac{SSM}{SST}\]

\begin{verbatim}
[1] 0.9614289
\end{verbatim}

\subsection*{Is my R squared good?}\label{is-my-r-squared-good}
\addcontentsline{toc}{subsection}{Is my R squared good?}

What value of \(R^2\) is considered good? In ecological research,
\(R^2\) values are often low (less than 0.3), because ecological systems
are complex and many factors influence the dependent variable. However,
in other fields, such as physiology, \(R^2\) values are often higher.
Therefore, the answer of what values of \(R^2\) are good depends on the
field of research.

Here are the four examples and their r-squared.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-10-1.pdf}}

\subsection*{Questions}\label{questions}
\addcontentsline{toc}{subsection}{Questions}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#what-minimised)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

What is minimised when we fit a regression model? And therefore what is
maximised?

\end{tcolorbox}

\section*{How unlikey is the observed data given the null
hypothesis?}\label{how-unlikey-is-the-observed-data-given-the-null-hypothesis}
\addcontentsline{toc}{section}{How unlikey is the observed data given
the null hypothesis?}

\markright{How unlikey is the observed data given the null hypothesis?}

We often hear this expressed as ``is the relationship significant?'' And
maybe we heard that the relationship is significant if the p-value is
less than 0.05. But what does all this actually mean? In this section
we'll figure all this out. The first step to is to formulate a null
hypothesis.

What is a meaningful null hypothesis for a regression model?

As mentioned, often we're interested in whether there is a relationship
between the dependent (response) and independent (explanatory) variable.
Therefore, the null hypothesis is that there is no relationship between
the dependent and independent variable. This means that the null
hypothesis is that the slope of the regression line is zero.

Recall the regression model: \[y = \beta_0 + \beta_1 x + \epsilon\]

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#null-hypothesis)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

Write down the null hypothesis of no relationship between \(x\) and
\(y\) in terms of a \(\beta\) parameter.

\end{tcolorbox}

The null hypothesis is that the slope of the regression line is zero:
\[H_0: \beta_1 = 0\]

What is the alternative hypothesis?

\[H_1: \beta_1 \neq 0\]

So, how do we test the null hypothesis? More precisely, we are going to
calculate the probability of observing the data we have, given that the
null hypothesis is true. If this probability is very low, then we can
reject the null hypothesis.

Does that make sense? Does it seem a bit convoluted? It is a bit!!!

But this is how hypothesis testing works. We never prove the null
hypothesis is true. Instead, we calculate the probability of observing
our data given that the null hypothesis is true. If this probability is
very low, we reject the null hypothesis.

To make the calculation we can use the fact that the slope of the
regression line is an estimate of the true slope. This estimate has
uncertainty associated with it. We can use this uncertainty to calculate
the probability of observing the data we have, given the null hypothesis
is true.

We can see that the slope estimate (the \(x\) row) has uncertainty by
looking at the regression output:

\begin{verbatim}
              Estimate Std. Error
(Intercept) -0.7638353  0.6652233
x            2.1161160  0.1072104
\end{verbatim}

The estimate is the mean of the distribution of the parameter (slope)
and the standard error is a measure of the uncertainty of the estimate.

The standard error is calculated as:

\[\sigma^{(\beta_1)} = \sqrt{ \frac{\hat\sigma^2}{\sum_{i=1}^n (x_i - \bar x)^2}}\]

Where \(\hat\sigma^2\) is the expected residual variance of the model.
This is calculated as:

\[\hat\sigma^2 = \frac{\sum_{i=1}^n (y_i - \hat y_i)^2}{n-2}\]

Where \(\hat y_i\) is the predicted value of \(y_i\) from the regression
model.

OK, let's take a look at this intuitively. We have the estimate of the
slope and the standard error of the estimate.

Here is a graph of the value of the slope estimate versus the standard
error of the estimate:

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-12-1.pdf}}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Think, Pair, Share (\#chance-area)}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

In what areas of the graph is the slope estimate more likely to have
been observed by chance? And what regions is it less likely to have been
observed by chance?

Think about this before you look at the end of this chapter for an
answer (Section \textbf{?@sec-visual-p-values-regress}).

\end{tcolorbox}

When the slope estimate is larger, it is less likely to have been
observed by chance. And when the standard error is larger, it is more
likely to have been observed by chance. How can we put these together
into a single measure?

If we divide the slope estimate by the standard error, we get a measure
of how many standard errors the slope estimate is from the null
hypothesis slope of zero. This is the \(t\)-statistic:

\[t = \frac{\hat\beta_1 - \beta_{1,H_0}}{\sigma^{(\beta_1)}}\]

Where \(\beta_{1,H_0}\) is the null hypothesis value of the slope,
usually zero, so that

\[t = \frac{\hat\beta_1}{\sigma^{(\beta_1)}}\]

\textbf{The \(t\)-statistic is a measure of how many standard errors the
slope estimate is from the null hypothesis value of the slope. The
larger the \(t\)-statistic, the less likely the slope estimate was
observed by chance.}

How can we transform the value of a \(t\)-statistic into a p-value? We
can use the \textbf{\(t\)-distribution}, which quantifies the
probability of observing a value of the \(t\)-statistic under the null
hypothesis.

But what is the \(t\)-distribution? It is a distribution of the
\(t\)-statistic under the null hypothesis. It is a bell-shaped
distribution that is centered on zero. The shape of the distribution is
determined by the degrees of freedom, which is \(n-2\) for a simple
linear regression model.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-13-1.pdf}}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

By the way, it is named the \(t\)-distribution by it's developer,
William Sealy Gosset, who worked for the Guinness brewery in Dublin,
Ireland. In his 1908 paper, Gosset introduced the \(t\)-distribution but
he didn't explicitly explain his choice of the letter \(t\). The choice
of the letter \(t\) could be to indicate ``Test'', as the
\(t\)-distribution was developed specifically for hypothesis testing.

\end{tcolorbox}

Now, recall that the p-value is the probability of observing the value
of the test statistic (so here the \(t\)-statistic) at least as extreme
as the one we have, given the null hypothesis is true. We can calculate
this probability by integrating the \(t\)-distribution from the observed
\(t\)-statistic to the tails of the distribution.

Here is a graph of the \(t\)-distribution with 100 degrees of freedom
with the tails of the distribution shaded so that the area of the shaded
region is 0.05 (i.e., 5\% of the total area).

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-14-1.pdf}}

And here's a graph of the \(t\)-distribution with 1000 degrees of
freedom (blue line) and the normal distribution (green dashed line):

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-15-1.pdf}}

So, with a large number of observations, the \(t\)-distribution
approaches the normal distribution. For the normal distribution, the
95\% area is between -1.96 and 1.96.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# x value for 95\% area of normal distribution}
\NormalTok{x\_value }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}
\NormalTok{x\_value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.959964
\end{verbatim}

\texttt{qnorm} is a function that calculates the \(x\) value for a given
quantile (probability) of the normal distribution. In simpler terms, it
finds the value \(x\) at which the area under the normal curve (up to
\(x\)) equals the given probability \(p\) (0.975 in the example
immediately above here).

Let's go back to the age - blood pressure data and calculate the p-value
for the slope estimate.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-18-1.pdf}}

Here's the model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Systolic\_BP }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Age, }\AttributeTok{data =}\NormalTok{ bp\_data)}
\end{Highlighting}
\end{Shaded}

Here we calculate the \(t\)-statistic for the slope estimate:

And here we calculate the one-tailed and two-tailed \(p\)-values:

\begin{verbatim}
         Age 
3.746958e-51 
\end{verbatim}

\begin{verbatim}
         Age 
7.493917e-51 
\end{verbatim}

We can get the \(p\)-value directly from the \texttt{summary} function:

\begin{verbatim}
    Estimate   Std. Error      t value     Pr(>|t|) 
8.240678e-01 2.770955e-02 2.973948e+01 7.493917e-51 
\end{verbatim}

Conclusion: there is \textbf{very strong evidence} that the blood
pressure is associated with age, because the \(p\)-value is extremely
small (thus it is very unlikely that the observed slope value or a large
one would be seen if there was really no association). Thus, we can
reject the null hypothesis that the slope is zero.

This basically answers question 1: ``Are the parameters compatible with
some specific value?''

\subsection*{\texorpdfstring{Recap: Formal definition of the
\(p\)-value}{Recap: Formal definition of the p-value}}\label{recap-formal-definition-of-the-p-value}
\addcontentsline{toc}{subsection}{Recap: Formal definition of the
\(p\)-value}

\textbf{The formal definition of \(p\)-value is the probability to
observe a data summary (e.g., an average or a slope) that is at least as
extreme as the one observed, given that the null hypothesis is correct.}

Example (normal distribution): Assume that we calculated that
\(t\)-value = -1.96

\(\Rightarrow\) \(Pr(|t|\geq 1.96)=0.05\) (two-tailed) and
\(Pr(t\leq-1.96)=0.025\) (one-tailed).

And here is a graph showing this:

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-23-1.pdf}}

\subsection*{\texorpdfstring{A cautionary note on the use of
\(p\)-values}{A cautionary note on the use of p-values}}\label{a-cautionary-note-on-the-use-of-p-values}
\addcontentsline{toc}{subsection}{A cautionary note on the use of
\(p\)-values}

Maybe you have seen that in statistical testing, often the criterion
\(p\leq 0.05\) is used to test whether \(H_0\) should be rejected. This
is often done in a black-or-white manner. However, we will put a lot of
attention to a more reasonable and cautionary interpretation of
\(p\)-values in this course!

\section*{How strong is the
relationship?}\label{how-strong-is-the-relationship}
\addcontentsline{toc}{section}{How strong is the relationship?}

\markright{How strong is the relationship?}

The actual value of the slope has practical meaning. The slope of the
regression line tells us how much the dependent variable changes when
the independent variable changes by one unit. The slope is one measure
of the strength of the relationship between the two variables.

We can ask what values of a parameter estimate are compatible with the
data (confidence intervals)? To answer this question, we can determine
the confidence intervals of the regression parameters.

The confidence interval of a parameter estimate is defined as the
interval that contains the true parameter value with a certain
probability. So the 95\% confidence interval of the slope is the
interval that contains the true slope with a probability of 95\%.

We can then imagine two cases. The 95\% confidence interval of the slope
includes 0:

\begin{verbatim}
Warning: `geom_errobarh()` was deprecated in ggplot2 4.0.0.
i Please use the `orientation` argument of `geom_errorbar()` instead.
\end{verbatim}

\begin{verbatim}
`height` was translated to `width`.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-24-1.pdf}}

Or where the confidence interval does not include zero:

\begin{verbatim}
`height` was translated to `width`.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-25-1.pdf}}

How do we calculate the lower and upper limits of the 95\% confidence
interval of the slope?

Recall that the \(t\)-value for a null hypothesis of slope of zero is
defined as:

\[t = \frac{\hat\beta_1}{\hat\sigma^{(\beta_1)}}\]

The first step is to calculate the \(t\)-value that corresponds to a
p-value of 0.05. This is the \(t\)-value that corresponds to the 97.5\%
quantile of the \(t\)-distribution with \(n-2\) degrees of freedom.

\(t_{0.975} = t_{0.025} = 1.96\), for large \(n\).

The 95\% confidence interval of the slope is then given by:

\[\hat\beta_1 \pm t_{0.975} \cdot \hat\sigma^{(\beta_1)}\]

In our blood pressure example the estimated slope is 0.8240678 and the
standard error of the slope is 0.0277096. We can calculate the 95\%
confidence interval of the slope in \emph{R} as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{t\_0975 }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, }\AttributeTok{df =}\NormalTok{ n }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}
\NormalTok{half\_interval }\OtherTok{\textless{}{-}}\NormalTok{ t\_0975 }\SpecialCharTok{*} \FunctionTok{summary}\NormalTok{(mod1)}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}
\NormalTok{lower\_limit }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(mod1)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ half\_interval}
\NormalTok{upper\_limit }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(mod1)[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ half\_interval}
\NormalTok{ci\_slope }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(lower\_limit, upper\_limit)}
\NormalTok{slope }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(mod1)[}\DecValTok{2}\NormalTok{]}
\NormalTok{slope}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      Age 
0.8240678 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ci\_slope}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      Age       Age 
0.7690791 0.8790565 
\end{verbatim}

Or, using the \texttt{confint} function:

\begin{verbatim}
    2.5 %    97.5 % 
0.7690791 0.8790565 
\end{verbatim}

Or we can do it using values from the coefficients table:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coefs }\OtherTok{\textless{}{-}} \FunctionTok{summary}\NormalTok{(mod1)}\SpecialCharTok{$}\NormalTok{coef}
\NormalTok{beta }\OtherTok{\textless{}{-}}\NormalTok{ coefs[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{]}
\NormalTok{sdbeta }\OtherTok{\textless{}{-}}\NormalTok{ coefs[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{] }
\NormalTok{beta }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{,}\DecValTok{241}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sdbeta }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7694840 0.8786516
\end{verbatim}

\emph{Interpretation}: for an increase in the age by one year, roughly
0.82 mmHg increase in blood pressure is expected, and all true values
for \(\beta_1\) between 0.77 and 0.88 are compatible with the observed
data.

\section*{Confidence and Prediction
Bands}\label{confidence-and-prediction-bands}
\addcontentsline{toc}{section}{Confidence and Prediction Bands}

\markright{Confidence and Prediction Bands}

\begin{itemize}
\item
  Remember: If another sample from the same population was taken, the
  regression line would look slightly different.
\item
  There are two questions to be asked:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which other regression lines are compatible with the observed data?
  This leads to the \emph{confidence band}.
\item
  Where do future observations (\(y\)) with a given \(x\) coordinate
  lie? This leads to the \emph{prediction band}.
\end{enumerate}

Note: The prediction band is much broader than the confidence band.

\section*{Calculation of the confidence
band}\label{calculation-of-the-confidence-band}
\addcontentsline{toc}{section}{Calculation of the confidence band}

\markright{Calculation of the confidence band}

Given a fixed value of \(x\), say \(x_0\). The question is:

Where does \(\hat y_0 = \hat\beta_0 + \hat\beta_1 x_0\) lie with a
certain confidence (i.e., 95\%)?

This question is not trivial, because both \(\hat\beta_0\) and
\(\hat\beta_1\) are estimates from the data and contain uncertainty.

The details of the calculation are given in Stahel 2.4b.

Plotting the confidence interval around all \(\hat y_0\) values one
obtains the \emph{confidence band} or \emph{confidence band for the
expected values} of \(y\).

Note: For the confidence band, only the uncertainty in the estimates
\(\hat\beta_0\) and \(\hat\beta_1\) matters.

Here is the confidence band for the blood pressure data:

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-29-1.pdf}}

Very narrow confidence bands indicate that the estimates are very
precise. In this case the estimated intercept and slope are precise
because the sample size is large and the data points are close to the
regression line.

\section*{Calculations of the prediction
band}\label{calculations-of-the-prediction-band}
\addcontentsline{toc}{section}{Calculations of the prediction band}

\markright{Calculations of the prediction band}

We can easily predicted an expected value of \(y\) for a given \(x\)
value. But we can also ask w where does a \emph{future observation} lie
with a certain confidence (i.e., 95\%)?

To answer this question, we have to \emph{consider not only the
uncertainty in the predicted value caused by uncertainty in the
parameter estimates} \(\hat y_0 =  \hat\beta_0 + \hat\beta_1 x_0\), but
also the \emph{error term} \(\epsilon_i \sim N(0,\sigma^2)\)\}.

This is the reason why the \textbf{prediction band} is wider than the
confidence band.

Here's a graph showing the prediction band for the blood pressure data:

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-31-1.pdf}}

Another way to think of the 95\% confidence band is that it is where we
would expect 95\% of the regression lines to lie if we were to collect
many samples from the same population. The 95\% prediction band is where
we would expect 95\% of the future observations to lie.

\section*{That is regression done (at least for our current
purposes)}\label{that-is-regression-done-at-least-for-our-current-purposes}
\addcontentsline{toc}{section}{That is regression done (at least for our
current purposes)}

\markright{That is regression done (at least for our current purposes)}

\begin{itemize}
\tightlist
\item
  Why use (linear) regression?
\item
  Fitting the line (= parameter estimation)
\item
  Is linear regression good enough model to use?
\item
  What to do when things go wrong?
\item
  Transformation of variables/the response.
\item
  Handling of outliers.
\item
  Goodness of the model: Correlation and \(R^2\)
\item
  Tests and confidence intervals
\item
  Confidence and prediction bands
\end{itemize}

\section*{Additional reading
material}\label{additional-reading-material}
\addcontentsline{toc}{section}{Additional reading material}

\markright{Additional reading material}

If you'd like another perspective and a deeper delve into some of the
mathematical details, please look at Chapter 2 of \emph{Lineare
Regression}, p.7-20 (Stahel script), Chapters 3.1, 3.2a-q of
\emph{Lineare Regression}, and Chapters 4.1 4.2f, 4.3a-e of
\emph{Lineare Regression}

\section*{Extras}\label{extras-1}
\addcontentsline{toc}{section}{Extras}

\markright{Extras}

\subsection*{Randomisation test for the slope of a regression
line}\label{randomisation-test-for-the-slope-of-a-regression-line}
\addcontentsline{toc}{subsection}{Randomisation test for the slope of a
regression line}

Let's use randomisation as another method to understand how likely we
are to observe the data we have, given the null hypothesis is true.

If the null hypothesis is true, we expect no relationship between \(x\)
and \(y\). Therefore, we can shuffle the \(y\) values and fit a
regression model to the shuffled data. We can repeat this many times and
calculate the slope of the regression line each time. This will give us
a distribution of slopes we would expect to observe if the null
hypothesis is true.

First, we'll make some data and get the slope of the regression line.
Here is the observed slope and relationship:

\begin{verbatim}
        x 
0.1251108 
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-33-1.pdf}}

Now we'll use randomisation to test the null hypothesis. We can create
lots of examples where the relationship is expected to have a slope of
zero by shuffling randomly the \(y\) values. Here are 20:

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-34-1.pdf}}

Now let's create 19 and put the real one in there somewhere random.
Here's a case where the real data has a quite strong relationship:

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-35-1.pdf}}

We can confidently find the real data amount the shuffled data. But what
if the relationship is weaker?

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-36-1.pdf}}

Now its less clear which is the real data. We can use this idea to test
the null hypothesis.

We do the same procedure of but instead of just looking at the graphs,
we calculate the slope of the regression line each time. This gives us a
distribution of slopes we would expect to observe if the null hypothesis
is true. We can then see where the observed slope lies in this
distribution of null hypothesis slopes.

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-37-1.pdf}}

We can now calculate the probability of observing the data we have,
given the null hypothesis is true.

\begin{verbatim}
[1] 0.0172
\end{verbatim}

\subsection*{Visualising p-values for regression
slopes}\label{sec-visual-p-values-regress}
\addcontentsline{toc}{subsection}{Visualising p-values for regression
slopes}

\pandocbounded{\includegraphics[keepaspectratio]{5.1-regression-part2_files/figure-pdf/unnamed-chunk-39-1.pdf}}

\bookmarksetup{startatroot}

\chapter*{Analysis of variance (ANOVA)
(L5)}\label{analysis-of-variance-anova-l5}
\addcontentsline{toc}{chapter}{Analysis of variance (ANOVA) (L5)}

\markboth{Analysis of variance (ANOVA) (L5)}{Analysis of variance
(ANOVA) (L5)}

\begin{itemize}
\tightlist
\item
  One-way ANOVA
\item
  Post-hoc tests and contrasts
\item
  Two-way ANOVA
\end{itemize}

ANOVA = ANalysis Of VAriance (Varianzanalyse)

\section*{Introduction}\label{introduction-2}
\addcontentsline{toc}{section}{Introduction}

\markright{Introduction}

The previous two chapters were about linear regression. \emph{Linear
regression} is a type of \emph{linear model} -- recall that in \emph{R}
we used the function \texttt{lm()} to make the regression model. In this
chapter we will look at a different type of linear model: analysis of
variance (ANOVA).

Recall that linear regression is a linear model with one continuous
explanatory (independent) variable. A continuous explanatory variable is
a variable in which values can take any value within a range (e.g.,
height, weight, temperature).

In contrast, analysis of variance (ANOVA) is a linear model with one or
more categorical explanatory variables. We will first look at a one-way
ANOVA, which has one categorical explanatory variable. Later (in a
following chapter) we will look at two-way ANOVA, which has two
categorical explanatory variables.

What is a categorical variable? A categorical explanatory variable is a
variable that contains values that fall into distinct groups or
categories. For example, habitat type (e.g., forest, grassland,
wetland), treatment group (e.g., control, low dose, high dose), or diet
type (e.g., vegetarian, vegan, omnivore).

This means that each observation belongs to one of a limited number of
categories or groups. For example, in a study of how blood pressure
varies with diet type, diet type is a categorical variable with several
levels (e.g., vegetarian, vegan, omnivore). A person can only belong to
one diet type category.

Here are the first several rows of a dataset that contains blood
pressure measurements for individuals following different diet types:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bp\_data\_diet }\OtherTok{\textless{}{-}} \FunctionTok{select}\NormalTok{(bp\_data\_diet, bp, diet, person\_ID)}
\NormalTok{bp\_data\_diet}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 50 x 3
      bp diet          person_ID
   <dbl> <chr>         <chr>    
 1   120 meat heavy    person_1 
 2    89 vegan         person_2 
 3    86 vegetarian    person_3 
 4   116 meat heavy    person_4 
 5   115 Mediterranean person_5 
 6   134 meat heavy    person_6 
 7    99 vegetarian    person_7 
 8   104 vegetarian    person_8 
 9   110 Mediterranean person_9 
10    97 Mediterranean person_10
# i 40 more rows
\end{verbatim}

There are three variables: - \texttt{bp}: blood pressure (continuous
response variable) - \texttt{diet}: diet type (categorical explanatory
variable) - \texttt{person\_ID}: unique identifier for each individual
(not used in the analysis)

Note that the \texttt{diet} variable is of type
\texttt{\textless{}chr\textgreater{}} which is short for
\texttt{character}. In \emph{R}, categorical variables are often
represented as factors.

As usual, its a really good idea to visualise the data in as close to
``raw'' form as possible before doing any analysis. We'll make a
scatterplot of blood pressure versus diet type.

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-4-1.pdf}}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

We just used \texttt{geom\_jitter()} instead of \texttt{geom\_point()}
to make a scatterplot. This is because \texttt{geom\_jitter()} adds a
small amount of random noise to the points, which helps to prevent
overplotting when multiple points have the same value (which is common
when the x-axis is categorical).

When we use \texttt{geom\_jitter()}, we can specify the amount of noise
to add in the x and y directions using the \texttt{width} and
\texttt{height} arguments, respectively. We must be very careful to not
add noise to the y direction if we care about the actual y values (e.g.,
blood pressure). In this case, we only added noise in the x direction by
setting \texttt{height\ =\ 0} to separate the points just enough, but
not so much that we could get confused about which of the diets they
belong to.

\end{tcolorbox}

Looking at this graph it certainly looks like diet type has an effect on
blood pressure. But is this effect statistically significant? In other
words, are the differences in mean blood pressure between diet types
larger than we would expect due to random variation alone?

Analysis of variance (ANOVA) is a statistical method that can help us
answer this question, and also others.

\section*{How does it look like in R?}\label{how-does-it-look-like-in-r}
\addcontentsline{toc}{section}{How does it look like in R?}

\markright{How does it look like in R?}

We can fit a one-way ANOVA model in \emph{R} using the same
\texttt{lm()} function that we used for linear regression. The only
difference is that the explanatory variable is categorical.

Then instead of using \texttt{summary()} to look at the results, we use
the \texttt{anova()} function.

\begin{verbatim}
Analysis of Variance Table

Response: bp
          Df Sum Sq Mean Sq F value    Pr(>F)    
diet       3 5274.2 1758.08  20.728 1.214e-08 ***
Residuals 46 3901.5   84.82                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

This is an ANOVA table. It shows us the sources of variation in the
data, along with their associated degrees of freedom (Df), sum of
squares (Sum Sq), mean square (Mean Sq), F value, and p-value
(Pr(\textgreater F)) associate with a getting a F value the same as or
greater than the observed F value if the null hypothesis were true.

The challenge now is to understand what all of these values mean! Let's
take it step by step.

\section*{What is ANOVA?}\label{what-is-anova}
\addcontentsline{toc}{section}{What is ANOVA?}

\markright{What is ANOVA?}

Analysis of variance is a method to compare whether the observations
(e.g., of blood pressure) differ according to some grouping (e.g., diet)
that the subjects (e.g., people) belong to.

We already know a lot about analysing variance: we compared the total
sum of squares (SST), model sum of squares (SSM) and the residual sum of
squares (SSE) in the context of linear regression. We used these to
calculated the \(R^2\) value. The \(R^2\) value tells us how much of the
total variance in the response variable (e.g., blood pressure) is
explained by the explanatory variable (e.g., diet).

The same applies to analysis of variance (ANOVA) (as well as regression)
because ANOVA is a special case of a linear model, just like regression
is also a special case of a linear model.

The defining characteristic of ANOVA is that we are comparing the means
of groups by analysing variances. Put another way, we will have a single
categorical explanatory variable with two or more levels. We will test
whether the means of the response variable are the same across all
levels of the explanatory variable, and we test this by analysing the
variances.

When we have only one categorical explanatory variable, we use a
\emph{one-way} ANOVA. When we have two categorical explanatory
variables, we will use a \emph{two-way} ANOVA (we'll look at this in a
subsequent chapter).

\section*{ANOVA as a linear model}\label{anova-as-a-linear-model}
\addcontentsline{toc}{section}{ANOVA as a linear model}

\markright{ANOVA as a linear model}

Just like linear regression, ANOVA can be expressed as a linear model.
The key difference is that in ANOVA, the explanatory variable is
categorical rather than continuous.We formulate the linear model as
follows:

\[y_{ij} = \mu_j + \epsilon_{i}\]

where:

\begin{itemize}
\tightlist
\item
  \(y_{ij}\) = Blood pressure of individual \(i\) with diet \(j\)
\item
  \(\mu_i\) = Mean blood pressure of an individual with diet \(j\)
\item
  \(\epsilon_{i}\sim N(0,\sigma^2)\) is an independent error term.
\end{itemize}

Graphically, with the blood pressure and diet data, this looks like:

\begin{verbatim}
`summarise()` has grouped output by 'diet'. You can override using the
`.groups` argument.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-9-1.pdf}}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

There is lots of hidden code used to create the data used in the graph
above, and to make the graph itself. You can see the code by going to
the \href{https://github.com/opetchey/BIO144_Course_Book}{Github
repository for this book}.

\end{tcolorbox}

\subsection*{Rewrite the model}\label{rewrite-the-model}
\addcontentsline{toc}{subsection}{Rewrite the model}

We usually use a different formulation of the linear model for ANOVA.
This is because we usually prefer to express the estimated parameters in
terms of \emph{differences between means} (rather than the means
themselves). The reason for this is that then the null hypothesis can be
that the differences are zero.

To proceed with this formulation, we define one of the groups as the
reference group, and make the mean of that equal to the intercept of the
model. For example, if we choose the ``meat heavy'' diet as the
reference group, we can write:

\[\mu_{meat} = \beta_0\]

And then to express the other group means as deviations from the
reference group mean:

\[\mu_{Med} = \beta_0 + \beta_1\] \[\mu_{vegan} = \beta_0 + \beta_2\]
\[\mu_{veggi} = \beta_0 + \beta_3\]

When we write out the entire model, we get:

\[y_i = \beta_0 + \beta_1 x_i^{1} + \beta_2 x_i^{2} + \beta_3 x_i^{3} + \epsilon_i\]
where: \(y_i\) is the blood pressure of individual \(i\). \(x_i^{1}\) is
a binary variable indicating whether individual \(i\) is on the
Mediterranean diet. \(x_i^{2}\) is a binary variable indicating whether
individual \(i\) is on the vegan diet. \(x_i^{3}\) is a binary variable
indicating whether individual \(i\) is on the vegetarian diet.

Graphically, the model now looks like this:

\begin{verbatim}
`summarise()` has grouped output by 'diet'. You can override using the
`.groups` argument.
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-10-1.pdf}}

Here is something to warp you mind\ldots{} we described one-way ANOVA as
a linear model with one categorical explanatory variable. But as you can
see above, we can also describe it as a linear model with multiple
binary explanatory variables (one for each group except the reference
group). And when we make a linear model in R it really does create
multiple binary explanatory variables behind the scenes. So one-way
ANOVA and multiple linear regression with multiple binary explanatory
variables are really the same thing! And, even more mind-warping,
one-way ANOVA and multiple regression (regression with multiple
continuous explanatory variables) are also the same thing! So when we
look at multiple regression later in the course, you can think of it as
just an extension of one-way ANOVA.

\subsection*{\texorpdfstring{The ANOVA test: The
\(F\)-test}{The ANOVA test: The F-test}}\label{the-anova-test-the-f-test}
\addcontentsline{toc}{subsection}{The ANOVA test: The \(F\)-test}

\textbf{Aim of ANOVA}: to test \emph{globally} if the groups differ.
That is we want to test the null hypothesis that all of the group means
are equal:

\[H_0: \mu_1=\mu_2=\ldots = \mu_g\] This is equivalent to testing if all
\(\beta\)s that belong to a categorical variable are = 0.

\[H_0: \beta_1 = \ldots = \beta_{g-1} = 0\] The alternate hypothesis is
that \({H_1}\): The group means are not all the same.

A key point is that we are testing a null hypothesis that concerns all
the groups. We are not testing if one group is different from another
group (which we could do with a \(t\)-test on one of the non-intercept
\(\beta\)s).

Because we are testing a null hypothesis that concerns all the groups,
we need to use an \(F\)-test. It asks if the model with the group means
is better than a model with just the overall mean.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

The \(F\)-test is called the ``\(F\)-test'' because it is based on the
\(F\)-distribution, which was named after the statistician
\href{https://en.wikipedia.org/wiki/Ronald_Fisher}{Sir Ronald A.
Fisher}. Fisher developed this statistical method as part of his
pioneering work in analysis of variance (ANOVA) and other fields of
experimental design and statistical inference.

\end{tcolorbox}

Actually, the \(F\)-test does not directly test the null hypothesis that
all the group means are equal. Instead, it tests whether the model that
includes the \emph{group means} explains significantly more variance in
the data than a model that only includes the overall mean (i.e., without
considering group differences).

The \(F\)-test does this by comparing two variance estimates: the
variance explained by the group means (between-group variance) and the
variance that remains unexplained within each group (within-group
variance).

\subsection*{\texorpdfstring{Interpretation of the \(F\)
statistic}{Interpretation of the F statistic}}\label{interpretation-of-the-f-statistic}
\addcontentsline{toc}{subsection}{Interpretation of the \(F\) statistic}

The \(F\)-test involves calculating from the observed data the value of
the \(F\) statistic, and then computing if that value is large enough to
reject the null hypothesis.

The \(F\) statistic is a ratio of two variances: the variance
\textbf{between} groups, and the variance \textbf{within} groups.

Here is an example with very low within group variability, and high
between group variability:

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-11-1.pdf}}

And here's an example with very high within group variability, and low
between group variability:

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-12-1.pdf}}

So, when the ratio of between group variance to within group variance is
large, the group means are very different compared to the variability
within groups. This suggests that the groups are different.

When the ratio is small, the group means are similar compared to the
variability within groups. This suggests that the groups are not
different.

\begin{itemize}
\tightlist
\item
  \textbf{\(F\) increases}

  \begin{itemize}
  \tightlist
  \item
    when the group means become more different, or
  \item
    when the variability within groups decreases.
  \end{itemize}
\item
  \textbf{\(F\) decreases}

  \begin{itemize}
  \tightlist
  \item
    when the group means become more similar, or
  \item
    when the variability within groups increases.
  \end{itemize}
\end{itemize}

\(\rightarrow\) The larger \(F\), the less likely are the data seen
under \(H_0\).

\subsection*{\texorpdfstring{Calculating the \(F\)
statistic}{Calculating the F statistic}}\label{calculating-the-f-statistic}
\addcontentsline{toc}{subsection}{Calculating the \(F\) statistic}

Recall that the \(F\) statistic is a ratio of two variances.
Specifically, it is the ratio of two mean squares (MS):

\begin{itemize}
\tightlist
\item
  \(MS_{model}\): the variability \textbf{between} groups.
\item
  \(MS_{residual}\): the variability \textbf{within} groups.
\end{itemize}

\(MS\) stands for Mean Square, and is a variance estimate.

The \(F\) statistic is calculated as:

\[F = \frac{MS_{model}}{MS_{residual}}\]

To find the mean squares, we need to calculate the within and the
between group sums of squares, and the corresponding degrees of freedom.
Let's go though this step by step.

\subsection*{Calculating the sums of
squares}\label{calculating-the-sums-of-squares}
\addcontentsline{toc}{subsection}{Calculating the sums of squares}

First we get the total sum of squares (SST), which quantifies the total
variability in the data. This is then split into the explained
variability (SSM), and the residual variability (SSE).

\textbf{Total variability:} SST =
\(\sum_{i=1}^k \sum_{j=1}^{n_i} (y_{ij}-\overline{y})^2\)

where:

\begin{itemize}
\tightlist
\item
  \(y_{ij}\) is the blood pressure of individual \(j\) in group \(i\)
\item
  \(\overline{y}\) is the overall mean blood pressure
\item
  \(n_i\) is the number of individuals in group \(i\)
\item
  \(k\) is the number of groups
\end{itemize}

\textbf{Explained variability (between group variability)}: == SSM =
\(\sum_{i=1}^k n_i (\overline{y}_{i} - \overline{y})^2\)

where:

\begin{itemize}
\tightlist
\item
  \(\overline{y}_{i}\) is the mean blood pressure of group \(i\)
\end{itemize}

\textbf{Residual variability (within group variability)}: = SSE =
\(\sum_{i=1}^k \sum_{j=1}^{n_i}  (y_{ij} - \overline{y}_{i} )^2\)

\subsection*{Calculating the degrees of
freedom}\label{calculating-the-degrees-of-freedom}
\addcontentsline{toc}{subsection}{Calculating the degrees of freedom}

And now we need the degrees of freedom for each sum of squares:

\textbf{SST degrees of freedom}: \(n - 1\) (total degrees of freedom is
number of observations \(n\) minus 1)

\textbf{SSM degrees of freedom}: \(k - 1\) (model degrees of freedom is
number of groups \(k\) minus 1)

\textbf{SSE degrees of freedom}: \(n - k\) (residual degrees of freedom
is total degrees of freedom \(n - 1\) minus model degrees of freedom
\(k - 1\))

\subsubsection*{Total degrees of
freedom}\label{total-degrees-of-freedom}
\addcontentsline{toc}{subsubsection}{Total degrees of freedom}

The total degrees of freedom are the degrees of freedom associated with
the total sum of squares (\(SST\)).

In order to calculate the \(SST\), we need to calculate the mean of the
response variable. This implies that we estimate one parameter (the mean
of the response variable). As a consequence, we lose one degree of
freedom and so there remain \(n-1\) degrees of freedom associated with
the total sum of squares (where \(n\) is the number of observations).

What do we mean by ``lose one degree of freedom''? Imagine we have ten
observations. We can calculate the mean of these ten observations. But
if we know the mean and nine of the observations, we can calculate the
tenth observation. So, in a sense, once we calculate the mean, the value
of one of the ten observations is fixed. This is what we mean by
``losing one degree of freedom''. When we calculate and use the mean,
one of the observations ``loses its freedom''.

For example, take the numbers 1, 3, 5, 7, 9. The mean is 5. The sum of
the squared differences between the observations and the mean is
\((1-5)^2 + (3-5)^2 + (5-5)^2 + (7-5)^2 + (9-5)^2 = 20\). This is the
total sum of squares. The degrees of freedom are \(5-1 = 4\).

The total degrees of freedom are the total number of observations minus
one. That is, the total sum of squares is associated with \(n-1\)
degrees of freedom.

Another perspective in which to think about the total sum of squares and
total degrees of freedom is to consider the intercept only model. The
intercept only model is a model that only includes the intercept term.
The equation of this model would be:

\[y_i = \beta_0 + \epsilon_i\] The sum of the square of the residuals
for this model is minimised when the predicted value of the response
variable is the mean of the response variable. That is, the least
squares estimate of \(\beta_0\) is the mean of the response variable:

\[\hat{\beta}_0 = \bar{y}\]

Hence, the predicted value of the response variable is the mean of the
response variable. The equation is:

\[\hat{y}_i = \bar{y} + \epsilon_i\]

The error term is therefore:

\[\epsilon_i = y_i - \bar{y}\] And the total sum of squares is:

\[SST = \sum_{i=1}^n (y_i - \bar{y})^2\]

where \(\hat{y}_i\) is the predicted value of the response variable for
the \(i\)th observation, \(\bar{y}\) is the mean of the response
variable, and \(\epsilon_i\) is the residual for the \(i\)th
observation.

The intercept only model involves estimating only one parameter, so the
total degrees of freedom are the total number of observations minus one
\(n - 1\).

Therefore, the total degrees of freedom are the total number of
observations minus one.

Bottom line: \(SST\) is the residual sum of squares when we fit the
intercept only model. The total degrees of freedom are the total number
of observations minus one.

\subsubsection*{Model degrees of
freedom}\label{model-degrees-of-freedom}
\addcontentsline{toc}{subsubsection}{Model degrees of freedom}

The model degrees of freedom are the degrees of freedom associated with
the model sum of squares (\(SSM\)).

In the case of the intercept only model, we estimated one parameter, the
mean of the response variable.

In the case of a categorical variable with \(k\) groups, we need \(k-1\)
parameters (non intercept \(\beta\) parameters), so we lose \(k-1\)
degrees of freedom. Put another way, when we fit a model with a
categorical explanatory variable with \(k\) groups, we estimate \(k-1\)
parameters in addition to the intercept. That is, we estimate the
difference between each group and the reference group.

Each time we estimate a new parameter, we lose a degree of freedom.

\subsubsection*{Residual degrees of
freedom}\label{residual-degrees-of-freedom}
\addcontentsline{toc}{subsubsection}{Residual degrees of freedom}

The residual degrees of freedom are the total degrees of freedom
(\(n-1\)) minus the model degrees of freedom (\(k-1\)).

Therefore, the residual degrees of freedom are the degrees of freedom
remaining after we estimate the intercept and the other \(\beta\)
parameters. There is one intercept and \(k-1\) other \(\beta\)
parameters, so the residual degrees of freedom are
\(n-1- ( k-1) = n - k\).

\subsection*{\texorpdfstring{Calculating the mean square and \(F\)
statistic}{Calculating the mean square and F statistic}}\label{calculating-the-mean-square-and-f-statistic}
\addcontentsline{toc}{subsection}{Calculating the mean square and \(F\)
statistic}

From these sums of squares and degrees of freedom we can calculate the
mean squares and \(F\)-statistic:

\[MS_{model} = \frac{SS_{\text{between}}}{k-1} = \frac{SSM}{k-1}\]

\[MS_{residual} = \frac{SS_{\text{within}}}{n-k} = \frac{SSE}{n-k}\]

\[F = \frac{MS_{model}}{MS_{residual}}\]

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Why divide by the degrees of freedom?} The more observations we
have, the greater will be the total sum of squares. The more
observations we have, the greater will be the residual sum of squares.
So it is not very informative to compare totals. Rather, we need to
compare the mean of the sums of squares. Except we don't calculate the
mean by dividing by the number of observations. Rather we divide by the
degrees of freedom. The total mean square is an estimate of the variance
of the response variable. And the residual mean square is an estimate of
the variance of the residuals.

\end{tcolorbox}

\subsection*{\texorpdfstring{\(SST\), \(SSM\), \(SSE\), and degrees of
freedom}{SST, SSM, SSE, and degrees of freedom}}\label{sst-ssm-sse-and-degrees-of-freedom}
\addcontentsline{toc}{subsection}{\(SST\), \(SSM\), \(SSE\), and degrees
of freedom}

Just a reminder and a summary of some of the material above:

\begin{itemize}
\tightlist
\item
  \(SST\): degrees of freedom = \(n-1\)
\item
  \(SSM\): degrees of freedom = \(k-1\)
\item
  \(SSE\): degrees of freedom = \(n-k\)
\end{itemize}

The sum of squares add up:

\[SST = SSM + SSE\]

and the degrees of freedom add up

\[(n-1) = (k-1) + (n - k)\]

\subsection*{Source of variance table}\label{source-of-variance-table}
\addcontentsline{toc}{subsection}{Source of variance table}

Now we have nearly everything we need. We often express all of this (and
a few more quantities) in a convenient table called the \textbf{sources
of variance table} (or ANOVA table).

The \textbf{sources of variance table} is a table that conveniently and
clearly gives all of the quantities mentioned above. It breaks down the
total sum of squares into the sum of squares explained by the model and
the sum of squares due to error. The source of variance table is used to
calculate the \(F\)-statistic.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0702}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1404}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1754}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3070}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3070}}@{}}
\caption{Sources of variance table}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Degrees of freedom
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mean square
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
F-statistic
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sum of squares
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Degrees of freedom
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Mean square
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
F-statistic
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Model & \(SSM\) & \(k-1\) & \(MSE_{model} = SSM / k-1\) &
\(\frac{MSE_{model}}{MSE_{error}}\) \\
Error & \(SSE\) & \(n - 1 - (k-1)\) &
\(MSE_{error} = SSE / (n - 1 - (k-1))\) & \\
Total & \(SST\) & \(n - 1\) & & \\
\end{longtable}

\subsection*{\texorpdfstring{Is my \(F\)-statistic large or
small?}{Is my F-statistic large or small?}}\label{is-my-f-statistic-large-or-small}
\addcontentsline{toc}{subsection}{Is my \(F\)-statistic large or small?}

OK, so we have calculated the \(F\) statistic. But how do we use it to
test our hypothesis?

We can use the \(F\) statistic to calculate a \(p\)-value, which tells
us how likely our data is under the null hypothesis.

Some key points:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(F\)-Distribution: The test statistic of the \(F\)-test (that is, the
  \(F\)-statistic) follows the \(F\)-distribution under the null
  hypothesis. This distribution arises when comparing the ratio of two
  independent sample variances (or mean squares).
\item
  Ronald Fisher's Contribution: Fisher introduced the \(F\)-distribution
  in the early 20th century as a way to test hypotheses about the
  equality of variances and to analyze variance in regression and
  experimental designs. The ``\(F\)'' in \(F\)-distribution honours him.
\item
  Variance Ratio: The test statistic for the \(F\)-test is the ratio of
  two variances (termed mean squares in this case), making the
  \(F\)-distribution the natural choice for modeling this ratio when the
  null hypothesis is true.
\end{enumerate}

The \(F\)-test is widely used, including when comparing variances,
assessing the significance of multiple regression models (see later
chapter), conducting ANOVA to test for differences among group means,
and for comparing different models.

Recall that ``The \(F\)-statistic is calculated as the ratio of the mean
square error of the model to the mean square error of the residuals.''
And that a large \(F\)-statistic is evidence against the null hypothesis
that the slopes of the explanatory variables are zero. And that a small
\(F\)-statistic is evidence to not reject the null hypothesis that the
slopes of the explanatory variables are zero.

But how big does the F-statistic need to be in order to confidently
reject the null hypothesis?

The null hypothesis that the explained variance of the model is no
greater than would be expected by chance. Here, ``by chance'' means that
the slopes of the explanatory variables are zero.

\[H_0: \beta_1 = \beta_2 = \ldots = \beta_p = 0\]

The alternative hypothesis is that the explained variance of the model
is greater than would be expected by chance. This would occur if the
slopes of some or all of the explanatory variables are not zero.

\[H_1: \beta_1 \neq 0 \text{ or } \beta_2 \neq 0 \text{ or } \ldots \text{ or } \beta_p \neq 0\]

To test this hypothesis we are going to, as usual, calculate a
\(p\)-value. The \(p\)-value is the probability of observing a test
statistic as or more extreme as the one we observed, assuming the null
hypothesis is true. To do this, we need to know the distribution of the
test statistic under the null hypothesis. The distribution of the test
statistic under the null hypothesis is known as the \(F\)-distribution.

The \(F\)-distribution has two degrees of freedom values associated with
it: the degrees of freedom of the model and the degrees of freedom of
the residuals. The degrees of freedom of the model are the number of
parameters estimated by the model corresponding to the null hypothesis.
The degrees of freedom of the residuals are the total degrees of freedom
minus the degrees of freedom of the model.

Here is the \(F\)-distribution with 2 and 99 degrees of freedom:

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-13-1.pdf}}

The F-distribution is skewed to the right and has a long tail. The area
to the right of 3.89 is shaded in red. This area represents the
probability of observing an F-statistic as or more extreme as 3.89,
assuming the null hypothesis is true. This probability is the
\(p\)-value of the hypothesis test.

The \(F\)-statistic and \(F\)-test is briefly recaptured in 3.1.f) of
the Stahel script, but see also Mat183 chapter 6.2.5. It uses the fact
that

\[\frac{MSE_{model}}{MSE_{residual}} =  \frac{SSM/p}{SSE/(n-1-p)} \sim F_{p,n-1-p}\]

follows an \(F\)-distribution with \(p\) and \((n-1-p)\) degrees of
freedom, where \(p\) are the number of continuous variables, \(n\) the
number of data points.

\begin{itemize}
\tightlist
\item
  \(SSE=\sum_{i=1} ^n(y_i-\hat{y}_i)^2\) is the residual sum of squares
\item
  \(SSM = SST - SSE\) is the sum of squares of the model
\item
  \(SST=\sum_{i=1}^n(y_i-\overline{y})^2\) is the total sum of squares
\item
  \(n\) is the number of data points
\item
  \(p\) is the number of explanatory variables in the regression model
\end{itemize}

Well, that is ANOVA conceptually. But how does it actually look like in
R?

\section*{Doing ANOVA in R}\label{doing-anova-in-r}
\addcontentsline{toc}{section}{Doing ANOVA in R}

\markright{Doing ANOVA in R}

Let's go back again the question of how diet effects blood pressure.
Here is the data:

\begin{verbatim}
# A tibble: 6 x 3
     bp diet          person_ID
  <dbl> <chr>         <chr>    
1   120 meat heavy    person_1 
2    89 vegan         person_2 
3    86 vegetarian    person_3 
4   116 meat heavy    person_4 
5   115 Mediterranean person_5 
6   134 meat heavy    person_6 
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-15-1.pdf}}

And here is how we fit a linear model to this data:

\textbf{IMPORTANT}: Since ANOVA is a linear model, it is important to
check the assumptions of linear models before interpreting the results.
These are some of the same assumptions we checked for simple linear
regression, including: independence of errors, normality of residuals,
and homoscedasticity (constant variance of residuals).

As with linear regression, we check the assumptions are not too badly
broken by looking at diagnostic plots:

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-17-1.pdf}}

Nothing looks too bad.

** Think-pair-share**: Which of the four plots above would you use to
check each of the three assumptions listed above?

** Think-pair-share**: Before we look at the ANOVA table, lets figure
out the total degrees of freedom, the degrees of freedom for the model,
and the degrees of freedom for the residuals. Have a think-pair-share
about each of these. Write you ideas down. Chat with you neighbour. Then
share with the class.

Now we can look at the ANOVA table:

\begin{verbatim}
Analysis of Variance Table

Response: bp
          Df Sum Sq Mean Sq F value    Pr(>F)    
diet       3 5274.2 1758.08  20.728 1.214e-08 ***
Residuals 46 3901.5   84.82                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The ANOVA table shows the sum of squares, degrees of freedom, mean
square, F value, and p-value for the model and residuals. As we know,
the \(F\) value (\(F\) statistics) is calculated as the mean square of
the model divided by the mean square of the residuals. The p-value is
calculated based on the F-distribution with the appropriate degrees of
freedom.

A suitable sentence to report our findings would be: ``Diet has a
significant effect on blood pressure
(\(F(2, 27) = 20.7, p < 0.0001\))''. This means that the probability of
observing such a large \(F\) value under the null hypothesis is less
than 0.01\%.

\emph{Think-pair-share}: You know that the \(R^2\) value is a measure of
how much variance in the response variable is explained by the model.
How would you calculate the \(R^2\) value from the ANOVA table above?

\section*{Difference between pairs of
groups}\label{difference-between-pairs-of-groups}
\addcontentsline{toc}{section}{Difference between pairs of groups}

\markright{Difference between pairs of groups}

Recall that the \(F\) test is a global test. It tests the null
hypothesis that all group means are equal. It does not tell us which
groups are different from each other. It just tells us that at least one
group mean is different. Sometimes researchers are interested in more
specific questions such as:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  finding the actual group(s) that deviate(s) from the others.
\item
  in estimates of the pairwise differences.
\end{enumerate}

The summary table in R provides some of these comparison, specifically
it contains the estimates for \(\beta_1\), \(\beta_2\), \(\beta_3\)
(while the reference was set to \(\beta_0 = 0\)).

For example, here is the summary table for our diet data:

\begin{verbatim}

Call:
lm(formula = bp ~ diet, data = bp_data_diet)

Residuals:
     Min       1Q   Median       3Q      Max 
-17.9375  -5.9174  -0.4286   5.2969  22.3750 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)        122.625      2.302  53.260  < 2e-16 ***
dietMediterranean  -12.688      3.256  -3.897 0.000314 ***
dietvegan          -26.768      4.173  -6.414 6.92e-08 ***
dietvegetarian     -23.625      3.607  -6.549 4.33e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 9.21 on 46 degrees of freedom
Multiple R-squared:  0.5748,    Adjusted R-squared:  0.5471 
F-statistic: 20.73 on 3 and 46 DF,  p-value: 1.214e-08
\end{verbatim}

In this table we have the intercept (\(\beta_0\)) and the three
\(\beta\) values for the diet groups: ``dietMeat'', ``dietVegetarian'',
and ``dietVegan''. The Estimate column shows the estimated coefficients
for each group. The intercept (\(\beta_0\)) represents the mean blood
pressure for the reference group (in this case, the ``meat'' diet
group). The other three coefficients represent \emph{the difference} in
mean blood pressure between each diet group and the reference group.

All well and good up to a point. But there are two issues with using the
results from this table:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The greater the number of individual tests, the more likely one will
  be significant just by chance. This is called the problem of multiple
  comparisons. Many test can result in a type-I error: rejecting the
  null hypothesis when it is actually true. The more tests one does, the
  more likely one is to make a type-I error.
\end{enumerate}

** Think-pair-share**: Imagine that when our threshold p-value each
individual test is 0.05 (5\%) so that if it is less than 0.05 we call it
``significant'' and if it is greater than 0.05 we call it ``not
significant'' (this is the standard practice in many fields). When we
make 20 hypothesis tests, how many would we expect to be ``significant''
just by chance (i.e., when we assume that all null hypotheses is true.)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The summary table does not provide all the possible pairwise
  comparisons. It does not, for example, provide the comparison between
  the ``vegan'' and the ``vegetarian'' group.
\end{enumerate}

Several methods to circumvent the problem of too many ``significant''
test results (type-I error) have been proposed. The most prominent ones
are:

\begin{itemize}
\tightlist
\item
  Bonferroni correction
\item
  Tukey \textbf{H}onest \textbf{S}ignificant \textbf{D}ifferences (HSD)
  approach
\item
  Fisher \textbf{L}east \textbf{S}ignificant \textbf{D}ifferences (LSD)
  approach
\end{itemize}

The second two when implemented in R also provide all possible pairwise
comparisons.

\subsection*{Bonferroni correction}\label{bonferroni-correction}
\addcontentsline{toc}{subsection}{Bonferroni correction}

\textbf{Idea:} If a total of \(m\) tests are carried out, simply divide
the type-I error level \(\alpha_0\) (often 5\%) such that

\[\alpha = \alpha_0 / m \ .\]

But this still leaves the problem of how to efficiently get all of the
possible pairwise comparisons. We can do this using the
\texttt{pairwise.t.test} function in R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairwise.t.test}\NormalTok{(bp\_data\_diet}\SpecialCharTok{$}\NormalTok{bp,}
\NormalTok{                bp\_data\_diet}\SpecialCharTok{$}\NormalTok{diet,}
                \AttributeTok{p.adjust.method =} \StringTok{"bonferroni"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Pairwise comparisons using t tests with pooled SD 

data:  bp_data_diet$bp and bp_data_diet$diet 

              meat heavy Mediterranean vegan 
Mediterranean 0.0019     -             -     
vegan         4.2e-07    0.0091        -     
vegetarian    2.6e-07    0.0239        1.0000

P value adjustment method: bonferroni 
\end{verbatim}

Here we can see that all pairwise comparisons have a p-value less than
0.05, except for the comparison of vegan versus vegetarian, which has a
p-value that rounds to 1.0000.

We also see in the output the note that ``P value adjustment method:
bonferroni'', indicating that the Bonferroni correction has been applied
to the p-values.

\subsection*{Tukey HSD approach}\label{tukey-hsd-approach}
\addcontentsline{toc}{subsection}{Tukey HSD approach}

\textbf{Idea:} Take into account the distribution of \emph{ranges}
(max-min) and design a new test.

In R we can use the \texttt{multcomp} package to do Tukey HSD tests:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bp\_data\_diet }\OtherTok{\textless{}{-}}\NormalTok{ bp\_data\_diet }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{diet =} \FunctionTok{as.factor}\NormalTok{(diet))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(bp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ diet, }\AttributeTok{data =}\NormalTok{ bp\_data\_diet)}
\FunctionTok{library}\NormalTok{(multcomp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading required package: mvtnorm
\end{verbatim}

\begin{verbatim}
Loading required package: survival
\end{verbatim}

\begin{verbatim}
Loading required package: TH.data
\end{verbatim}

\begin{verbatim}
Loading required package: MASS
\end{verbatim}

\begin{verbatim}

Attaching package: 'MASS'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:patchwork':

    area
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:dplyr':

    select
\end{verbatim}

\begin{verbatim}

Attaching package: 'TH.data'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:MASS':

    geyser
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tukey\_test }\OtherTok{\textless{}{-}} \FunctionTok{glht}\NormalTok{(fit, }\AttributeTok{linfct =} \FunctionTok{mcp}\NormalTok{(}\AttributeTok{diet =} \StringTok{"Tukey"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(tukey\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

     Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lm(formula = bp ~ diet, data = bp_data_diet)

Linear Hypotheses:
                                Estimate Std. Error t value Pr(>|t|)    
Mediterranean - meat heavy == 0  -12.688      3.256  -3.897  0.00168 ** 
vegan - meat heavy == 0          -26.768      4.173  -6.414  < 0.001 ***
vegetarian - meat heavy == 0     -23.625      3.607  -6.549  < 0.001 ***
vegan - Mediterranean == 0       -14.080      4.173  -3.374  0.00759 ** 
vegetarian - Mediterranean == 0  -10.938      3.607  -3.032  0.01951 *  
vegetarian - vegan == 0            3.143      4.453   0.706  0.89305    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)
\end{verbatim}

We get all the pairwise comparisons, along with their estimates,
standard errors, t-values, and p-values. We also get a note
\texttt{Adjusted\ p\ values\ reported\ -\/-\ single-step\ method},
indicating that the Tukey HSD adjustment has been applied to the
p-values.

Again, all pairwise comparisons have a p-value less than 0.05, except
for the comparison of vegan versus vegetarian, which has a p-value of
0.89305.

\subsection*{Fisher's LSD approach}\label{fishers-lsd-approach}
\addcontentsline{toc}{subsection}{Fisher's LSD approach}

\textbf{Idea:} Adjust the idea of a two-sample test, but use a larger
variance (namely the pooled variance of all groups).

\subsection*{Other contrasts}\label{other-contrasts}
\addcontentsline{toc}{subsection}{Other contrasts}

A contrast is a specific comparison between groups. So far we have only
considered pairwise contrasts (i.e., comparing two groups at a time).
But we can also design more complex contrasts. For example: are diets
that contain meat different from diets that do not contain meat?

\begin{verbatim}
# A tibble: 6 x 4
     bp diet          person_ID meat_or_no_meat
  <dbl> <fct>         <chr>     <chr>          
1   120 meat heavy    person_1  no meat        
2    89 vegan         person_2  no meat        
3    86 vegetarian    person_3  no meat        
4   116 meat heavy    person_4  no meat        
5   115 Mediterranean person_5  meat           
6   134 meat heavy    person_6  no meat        
\end{verbatim}

Here we defined a new explanatory variable that groups the meat heavy
and Mediterranean diet together into a single ``meat'' group and
vegetarian and vegan into a single ``no meat'' group. We then fit a
model with this explanatory variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_mnm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(bp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ meat\_or\_no\_meat, }\AttributeTok{data =}\NormalTok{ bp\_data\_diet)}
\end{Highlighting}
\end{Shaded}

(We should not look at model diagnostics here, before using the model.
But let us continue as if the assumptions are sufficiently met.)

We now do something a bit more complicated: we compare the variance
explained by the model with four diets to the model with two diets. This
is done by comparing the two models using an \(F\)-test. We are testing
the null hypothesis that the two models are equally good at explaining
the data, in which case the two diet model will explain as much variance
as the four diet model.

Let's look at the ANOVA table of the model comparison:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(fit, fit\_mnm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Model 1: bp ~ diet
Model 2: bp ~ meat_or_no_meat
  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    
1     46 3901.5                                  
2     48 9173.4 -2   -5271.9 31.078 2.886e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

We see the residual sum of squares of the model with meat or no meat is
over 9'000, while that of the four diet model is less than 4'000. That
is, the four diet model explains much more variance in the data than the
two diet model. The \(F\)-test is highly significant, so we reject the
null hypothesis that the two models are equally good at explaining the
data. And we conclude that its not just whether people eat meat or not,
but rather what kind of diet they eat that affects their blood pressure.

Ideally we do not make a lot of contrasts after we have collected and
looked at our data. Rather, we would specify the contrasts we are
interested in before we collect the data. This is called a priori
contrasts. But sometimes we do exploratory data analysis and then we can
make post hoc contrasts. In this case we should be careful to adjust for
multiple comparisons.

\subsection*{Choosing the reference
category}\label{choosing-the-reference-category}
\addcontentsline{toc}{subsection}{Choosing the reference category}

\textbf{Question}: Why was the ``heavy meat'' diet chosen as the
reference (intercept) category?

\textbf{Answer}: Because R orders the categories alphabetically and
takes the first level alphabetically as reference category.

Sometimes we may want to override this, for example if we have a
treatment that is experimentally the control, then it will usually be
useful to set this as the reference / intercept level.

In R we can set the reference level using the \texttt{relevel} function:

And now make the model and look at the estimated coefficients:

\begin{verbatim}

Call:
lm(formula = bp ~ diet, data = bp_data_diet)

Residuals:
     Min       1Q   Median       3Q      Max 
-17.9375  -5.9174  -0.4286   5.2969  22.3750 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)         95.857      3.481  27.538  < 2e-16 ***
dietmeat heavy      26.768      4.173   6.414 6.92e-08 ***
dietMediterranean   14.080      4.173   3.374  0.00151 ** 
dietvegetarian       3.143      4.453   0.706  0.48386    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 9.21 on 46 degrees of freedom
Multiple R-squared:  0.5748,    Adjusted R-squared:  0.5471 
F-statistic: 20.73 on 3 and 46 DF,  p-value: 1.214e-08
\end{verbatim}

Now we see the estimated coefficients for all diets except the vegan
diet. The intercept is the mean individuals with vegan diet.

\section*{Communicating the results of
ANOVA}\label{communicating-the-results-of-anova}
\addcontentsline{toc}{section}{Communicating the results of ANOVA}

\markright{Communicating the results of ANOVA}

When communicating the results of an ANOVA, we usually report the
\(F\)-statistic, the degrees of freedom of the numerator and
denominator, and the p-value. For example, we could say:

\begin{quote}
Blood pressure differed significantly between groups, with the mean of a
meat heavy diet being 123 mmHg, while the mean blood pressure of the
vegan group was 27 mmHg lower (One-way ANOVA, \(F(3, 46) = 20.7\),
\(p < 0.0001\).
\end{quote}

And we would make a nice graph, in this case showing each individual
observation since there are not too many to cause overplotting. We can
also add the estimated means of each group if we like:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(bp\_data\_diet, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ diet, }\AttributeTok{y =}\NormalTok{ bp)) }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{width =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{height =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ mean, }\AttributeTok{geom =} \StringTok{"point"}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{, }\AttributeTok{size =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Blood Pressure by Diet"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Diet"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Blood Pressure (mmHg)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-27-1.pdf}}

Some people like to see error bars as well, for example showing the 95\%
confidence intervals of the means:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(bp\_data\_diet, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ diet, }\AttributeTok{y =}\NormalTok{ bp)) }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{width =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{height =} \DecValTok{0}\NormalTok{, }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ mean, }\AttributeTok{geom =} \StringTok{"point"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{size =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun.data =}\NormalTok{ mean\_cl\_normal, }\AttributeTok{geom =} \StringTok{"errorbar"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Blood Pressure by Diet}\SpecialCharTok{\textbackslash{}n}\StringTok{Black points and error bars show mean Â± 95\% CI"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Diet"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Blood Pressure (mmHg)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{6.1-anova_files/figure-pdf/unnamed-chunk-28-1.pdf}}

There are many many plotting styles and preferences. The important thing
is to clearly communicate the results, and to not mislead the reader. I
find that plotting the individual data points is often a good idea,
especially when the sample size is not too large.

\section*{Summary of what you have
learned}\label{summary-of-what-you-have-learned}
\addcontentsline{toc}{section}{Summary of what you have learned}

\markright{Summary of what you have learned}

Please referring to the learning objectives document and the learning
objectives for this chapter.

\section*{Summing up}\label{summing-up}
\addcontentsline{toc}{section}{Summing up}

\markright{Summing up}

\begin{itemize}
\tightlist
\item
  ANOVA is just another linear model.
\item
  It is used when we have categorical explanatory variables.
\item
  We use \(F\)-tests to test the null hypothesis of no difference among
  the means of the groups (categories).
\item
  We can use contrasts and post-hoc tests to test specific hypotheses
  about the means of the groups.
\item
  Two-way ANOVA is used when we have two categorical explanatory
  variables and can be used to test for interactions between them.
\end{itemize}

\bookmarksetup{startatroot}

\chapter*{Multiple regression (L6)}\label{multiple-regression-l6}
\addcontentsline{toc}{chapter}{Multiple regression (L6)}

\markboth{Multiple regression (L6)}{Multiple regression (L6)}

\section*{Introduction}\label{introduction-3}
\addcontentsline{toc}{section}{Introduction}

\markright{Introduction}

In the previous chapters we covered simple linear regression and one-way
analysis of variance. In both we had one response variable and one
explanatory variable. In both cases we made a linear model to relate the
response variable to the explanatory variable. The two cases differed in
the type of explanatory variable. In the case of simple linear
regression, the explanatory variable was continuous. In the case of
one-way ANOVA, the explanatory variable was categorical.

We will now extend the linear model and analyses to cases with more than
one (i.e., multiple) explanatory variables. The explanatory variables
can be continuous or categorical, and can be a mixture of the two.

Some combinations of explanatory variables have special names:

\begin{itemize}
\tightlist
\item
  Multiple (more than one) continuous explanatory variables
  -\textgreater{} Multiple linear regression.
\item
  Two categorical explanatory variables -\textgreater{} Two-way ANOVA.
\item
  One continuous and one categorical explanatory variable
  -\textgreater{} Analysis of covariance (ANCOVA).
\end{itemize}

We will look at each of these, and start with multiple linear regression
which is usually shortened to just multiple regression.

\section*{Multiple regression}\label{multiple-regression}
\addcontentsline{toc}{section}{Multiple regression}

\markright{Multiple regression}

We previously looked at whether blood pressure is associated with age.
This is an important question, because blood pressure has many health
implications. However, blood pressure is not only associated with age,
but also with other factors, such as weight, height, and lifestyle. In
this chapter, we will look at how to investigate the association between
blood pressure and multiple explanatory variables.

When we have multiple explanatory variables, we are often interested in
questions such as:

\begin{itemize}
\tightlist
\item
  Question 1: As an ensemble (i.e., all together), are the explanatory
  variables ``useful''?
\item
  Question 2: Are each of the explanatory variables associated with the
  response?
\item
  Question 3: What proportion of variability is explained?
\item
  Question 4: Are some explanatory variables more important than others?
\end{itemize}

\subsection*{An example dataset}\label{an-example-dataset}
\addcontentsline{toc}{subsection}{An example dataset}

Blood pressure is again the response variable, with age and lifestyle as
two explanatory variables. Lifestyle is a continuous variable that is
the number of minutes of exercise per week.

Here is a look at the dataset:

\begin{verbatim}
# A tibble: 100 x 3
     age mins_exercise    bp
   <dbl>         <dbl> <dbl>
 1    49           115   115
 2    50            65    99
 3    74            61   116
 4    38           270    84
 5    52           168   111
 6    72            69   117
 7    52           263   106
 8    35            65   113
 9    33            91    85
10    21           119    96
# i 90 more rows
\end{verbatim}

Since there are three variables, we can make three different scatter
plots to visualise the relationships:

\textbf{1. Age vs blood pressure.} This is the graph of the response
variable (blood pressure) against one of the explanatory variables
(age). It looks like there is evidence of a positive relationship.

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-4-1.pdf}}

Here we see a positive relationship between age and blood pressure.
Blood pressure tends to increase with age.

\textbf{2. Minutes of exercise vs blood pressure.} This is a graph of
the response variable (blood pressure) against the other explanatory
variable (minutes of exercise). It looks like there is evidence of a
negative relationship.

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-5-1.pdf}}

Here we see a negative relationship between minutes of exercise and
blood pressure. Blood pressure tends to decrease with more minutes of
exercise.

\textbf{3. Age vs minutes of exercise.} This is a graph of the two
explanatory variables against each other. It looks like there is no
relationship.

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-6-1.pdf}}

And here we see no relationship between age and minutes of exercise. The
two explanatory variables appear to be independent.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

The lack of correlation between the two explanatory variables is very
important. If the two explanatory variables were correlated, we would
have a situation known as multicollinearity. Multicollinearity can
greatly complicate the interpretation of the results of a multiple
regression analysis. We will discuss multicollinearity later.

\end{tcolorbox}

\subsection*{The multiple linear regression
model}\label{the-multiple-linear-regression-model}
\addcontentsline{toc}{subsection}{The multiple linear regression model}

The multiple linear regression model is an extension of the simple
linear regression model. Recall the simple linear regression model is:

\[y_i = \beta_0 + \beta_1 x_i + \epsilon_i\]

where:

\begin{itemize}
\tightlist
\item
  \(y_i\) is the response variable
\item
  \(x_i\) is the explanatory variable
\item
  \(\beta_0\) is the intercept
\item
  \(\beta_1\) is the slope
\item
  \(\epsilon_i\) is the error term.
\end{itemize}

The multiple linear regression model with two explanatory variables is:

\[y_i = \beta_0 + \beta_1 x_i^{(1)} + \beta_2 x_i^{(2)} + \epsilon_i\]

where:

\begin{itemize}
\tightlist
\item
  \(x_i^{(1)}\) and \(x_i^{(2)}\) are the two explanatory variables
\item
  \(\beta_0\) is the intercept
\item
  \(\beta_1\) is the slope for the first explanatory variable
\item
  \(\beta_2\) is the slope for the second explanatory variable
\end{itemize}

Note that the intercept \(\beta_0\) is the value of the response
variable when all explanatory variables are zero. In this example, it
would be the blood pressure for someone that is 0 years old and does 0
minutes of exercise per week. This is not a particularly useful
scenario, but it is a necessary mathematical construct that helps us to
build the model.

We can extend the multiple regression model to have an arbitrary number
of explanatory variables:

\[y_i = \beta_0 + \beta_1 x_i^{(1)} + \beta_2 x_i^{(2)} + \ldots + \beta_p x_i^{(p)} + \epsilon_i\]

Where:

\(x_i^{(1)}, x_i^{(2)}, \ldots, x_i^{(p)}\) are the \(p\) explanatory
variables and all else is as before.

or with summation notation:

\[y_i = \beta_0 + \sum_{j=1}^p \beta_j x_i^{(j)} + \epsilon_i\]

Just like in simple linear regression, we can estimate the parameters
\(\beta_0, \beta_1, \ldots, \beta_p\) using the method of least squares.
The least squares method minimizes the sum of the squared residuals:

\[\sum_{i=1}^n \epsilon_i^2 = \sum_{i=1}^n (y_i - \hat{y}_i)^2\]

where \(\hat{y}_i\) is the predicted value of the response variable for
the \(i\)th observation:

\[\hat{y}_i = \hat{\beta}_0 + \sum_{j=1}^p \hat{\beta}_j x_i^{(j)}\]
where:

\(\hat{\beta}_0, \hat{\beta}_1, \ldots, \hat{\beta}_p\) are the
estimated parameters.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Think, Pair, Share (\#two-shape)}

Graphically, a linear regression with one explanatory variable is a
line. What is a geometric representation of linear regression with two
explanatory variables?

\end{tcolorbox}

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-7-1.pdf}}

Let's write the equation for the blood pressure data:

\[bp_i = \beta_0 + \beta_1 \cdot age_i + \beta_2 \cdot mins\_exercise_i + \epsilon_i\]

where:

\begin{itemize}
\tightlist
\item
  \(bp_i\) is the blood pressure for the \(i\)th observation
\item
  \(age_i\) is the age for the \(i\)th observation
\item
  \(mins\_exercise_i\) is the minutes of exercise for the \(i\)th
  observation
\item
  \(\beta_0\) is the intercept
\item
  \(\beta_1\) is the slope for age
\item
  \(\beta_2\) is the slope for minutes of exercise
\item
  \(\epsilon_i\) is the error term
\end{itemize}

and the error term is assumed to be normally distributed with mean 0 and
constant variance, just as was the case for simple linear regression:

\[\epsilon_i \sim N(0, \sigma^2)\]

\textbf{Seventh}, we know how to make predictions using the model, and
to make a prediction band.

\textbf{What we don't know} is how to answer the four questions already
mentioned above:

\begin{itemize}
\tightlist
\item
  Question 1: As an ensemble (i.e., all together), are the explanatory
  variables ``useful''?
\item
  Question 2: Are each of the explanatory variables associated with the
  response?
\item
  Question 3: What proportion of variability is explained?
\item
  Question 4: Are some explanatory variables more important than others?
\end{itemize}

Let's answer these questions using the blood pressure example.

\subsection*{Fitting the model}\label{fitting-the-model}
\addcontentsline{toc}{subsection}{Fitting the model}

We know how to estimate the parameters
\(\beta_0, \beta_1, \ldots, \beta_p\) using the method of least squares.

In R, we can fit a multiple linear regression model using the
\texttt{lm()} function in a very similar way to the simple linear
regression model. Here is the code for the blood pressure example. To
fit two explanatory variables, we simply add the second variable to the
formula using the \texttt{+} sign:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(bp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ mins\_exercise, }\AttributeTok{data =}\NormalTok{ bp\_data)}
\end{Highlighting}
\end{Shaded}

\subsection*{Checking the assumptions}\label{checking-the-assumptions}
\addcontentsline{toc}{subsection}{Checking the assumptions}

Great news --\textgreater{} the five assumptions of the multiple linear
regression model are the same as for the simple linear regression model:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Normality of residuals.
\item
  Homoscedasticity = constant variance of residuals.
\item
  Independence of residuals.
\item
  Linearity.
\item
  No outliers.
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Think, Pair, Share (\#assump-match)}

Review how we can check these assumptions in the simple linear
regression model:

Match the following to the assumptions above:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Graph of size of residuals vs.~fitted values.
\item
  QQ-plot.
\item
  Graph of residuals vs.~fitted values.
\item
  Graph of leverage vs.~standardized residuals.
\end{enumerate}

And what is missing?

\end{tcolorbox}

We can check the assumptions of the multiple linear regression model
using the same methods as for the simple linear regression model. Here
is the code for the blood pressure example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check the assumptions}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(m1, }\AttributeTok{which =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{), }\AttributeTok{add.smooth =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-9-1.pdf}}

We see that the assumptions are met for the blood pressure example:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Normality of residuals: The QQ-plot shows that the residuals are
  normally distributed.
\item
  Homoscedasticity: The scale-location plot shows that the residuals
  have constant variance.
\item
  Independence of residuals: No evidence of pattern or clustering. But
  also need to know about study design to properly assess independence.
\item
  Linearity: The residuals vs.~fitted values plot shows no clear pattern
  in the residuals.
\item
  No outliers: No points with high leverage or high residuals.
\end{enumerate}

\section*{Question 1: As an ensemble, are the explanatory variables
useful?}\label{question-1-as-an-ensemble-are-the-explanatory-variables-useful}
\addcontentsline{toc}{section}{Question 1: As an ensemble, are the
explanatory variables useful?}

\markright{Question 1: As an ensemble, are the explanatory variables
useful?}

Recall that when we learned about ANOVA we saw that a single categorical
explanatory variable with multiple levels can be represented as multiple
binary (0/1) explanatory variables. In that case, we used the \(F\)-test
to test the null hypothesis of no effect / relationship for all binary
variables together.

Likewise, when we have multiple continuous explanatory variables, we use
the \(F\)-test to test the null hypothesis that \textbf{together} the
explanatory variables have no association with the response variable.
That is, we use the \(F\)-test to test the null hypothesis that the
ensemble of explanatory variables is not associated with the response
variable.

This corresponds to the same null hypothesis as we used in one-way
ANOVA: The null hypothesis that the explained variance of the model is
no greater than would be expected by chance. Here, ``by chance'' means
that the slopes of the explanatory variables are zero:

\[H_0: \beta_1 = \beta_2 = \ldots = \beta_p = 0\]

And the alternative hypothesis (just as in one-way ANOVA) is that the
explained variance of the model is greater than would be expected by
chance. This would occur if the slopes of some or all of the explanatory
variables are not zero:

\[H_1: \beta_1 \neq 0 \text{ or } \beta_2 \neq 0 \text{ or } \ldots \text{ or } \beta_p \neq 0\]

Recall that the \(F\)-test compares the variance explained by the model
to the variance not explained by the model (i.e., the variance of the
residuals). If the variance explained by the model is significantly
greater than the variance not explained by the model, then we can
conclude that the explanatory variables are associated with the response
variable.

If we reject the null hypothesis, we can conclude that some combination
of the explanatory variables is associated with the response variable.
However, we cannot conclude which specific explanatory variables are
associated with the response variable. To determine which specific
explanatory variables are associated with the response variable, we need
to perform individual \(t\)-tests for each explanatory variable. We will
do this in the next section.

OK, back to the \(F\)-test.

We know a lot already from the ANOVA chapter. Let's review how we
calculate the \(F\)-statistic.

The \(F\)-statistic is calculated as the ratio of two mean squares:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The mean square of the model (\(MSE_{model}\)).
\item
  The mean square of the residuals (\(MSE_{residual}\)).
\end{enumerate}

Recall that a mean square is a sum of squares divided by the associated
degrees of freedom. The formulas for these are the same as for ANOVA.

So, to calculate these two mean squares, we need to calculate three sums
of squares:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The total sum of squares (\(SST\)).
\item
  The sum of squares of the model (\(SSM\)).
\item
  The sum of squares of the residuals (\(SSE\)).
\end{enumerate}

We also need to calculate the degrees of freedom associated with each
sum of squares.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The total degrees of freedom is \(n-1\), where \(n\) is the number of
  observations.
\item
  The model degrees of freedom is \(p\), where \(p\) is the number of
  explanatory variables. This is because for each explanatory variable
  we estimate one parameter (the slope), and each estimated parameter
  uses up one degree of freedom.
\item
  The residual degrees of freedom is \(n-1-p\).
\end{enumerate}

\subsection*{The F-statistic in R}\label{the-f-statistic-in-r}
\addcontentsline{toc}{subsection}{The F-statistic in R}

We could do all these calculations ourselves (and you might be asked to
in the exam), but also we can just ask R! For question 1 we need to know
the \(F\)-statistic for the multiple linear regression model. We can
easily get this from R using the \texttt{summary()} function, and by
looking in the right place in the output:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = bp ~ age + mins_exercise, data = bp_data)

Residuals:
     Min       1Q   Median       3Q      Max 
-26.9080  -6.2220   0.1734   6.5706  24.6617 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   89.17590    3.64054  24.495  < 2e-16 ***
age            0.51037    0.06023   8.473 2.62e-13 ***
mins_exercise -0.09004    0.01213  -7.424 4.41e-11 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 10.41 on 97 degrees of freedom
Multiple R-squared:  0.5473,    Adjusted R-squared:  0.5379 
F-statistic: 58.63 on 2 and 97 DF,  p-value: < 2.2e-16
\end{verbatim}

In the final line of output we see ``F-statistic: 58.63 on 2 and 97 DF,
p-value: \ensuremath{2.03\times 10^{-17}}''.

The model degrees of freedom is 2 (because we have two explanatory
variables), and the residual degrees of freedom is 97 (because we have
100 observations and 2 explanatory variables, so \(100 - 1 - 2 = 97\)).

So the \texttt{summary()} function gives us everything we need to answer
question 1. It even gives us the \(p\)-value for the \(F\)-test.

\textbf{How to report the result}. We could write somthing like this:
``The combination of age and minutes of exercise is significantly
associated with blood pressure (F(2, 97) = 58.63, p =
\ensuremath{2.03\times 10^{-17}}).'' Note that this is rather an
undesirable statement, because it focuses too much on the statistics and
not enough on the science. Indeed, perhaps we care more about the
association of each explanatory variable with blood pressure, which we
will look at next.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

If you want to review how to calculate a p-value from an F-statistic,
see the corresponding section of the one-way ANOVA chapter.

\end{tcolorbox}

\section*{Question 2: Which variables are associated with the
response?}\label{question-2-which-variables-are-associated-with-the-response}
\addcontentsline{toc}{section}{Question 2: Which variables are
associated with the response?}

\markright{Question 2: Which variables are associated with the
response?}

As we did for simple linear regression, we can perform a \(t\)-test for
one explanatory variable to determine if it is associated with the
response. And we can do this for each of the explanatory variables. As
before, the null hypothesis for each \(t\)-test is that the slope of the
explanatory variable is zero. The alternative hypothesis is that the
slope of the explanatory variable is not zero.

Here is the coefficients table, which includes the results of the
\(t\)-tests for each explanatory variable:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m1)}\SpecialCharTok{$}\NormalTok{coef}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                 Estimate Std. Error   t value     Pr(>|t|)
(Intercept)   89.17590334 3.64053711 24.495260 2.514032e-43
age            0.51037480 0.06023409  8.473188 2.623171e-13
mins_exercise -0.09003929 0.01212895 -7.423500 4.410580e-11
\end{verbatim}

And we can get the 95\% CI for each slope estimate \(\hat\beta_j\) as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confint}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   2.5 %      97.5 %
(Intercept)   81.9504449 96.40136174
age            0.3908268  0.62992281
mins_exercise -0.1141119 -0.06596668
\end{verbatim}

Reminder: The 95\% confidence interval is
\([\hat\beta - c \cdot \sigma^{(\beta)} ; \hat\beta + c \cdot \sigma^{(\beta)}]\),
where \(c\) is the 97.5\% quantile of the \(t\)-distribution with
\(n-p\) degrees of freedom).

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{However} Please insert a note into your brain that we are
dealing here with an ideal case of \textbf{uncorrelated explanatory
variables}. You'll learn later in the course about what happens when
explanatory variables are correlated. Hint: interpretation is difficult
and unstable!

\end{tcolorbox}

\section*{Question 3: What proportion of variability is
explained?}\label{question-3-what-proportion-of-variability-is-explained}
\addcontentsline{toc}{section}{Question 3: What proportion of
variability is explained?}

\markright{Question 3: What proportion of variability is explained?}

\subsection*{\texorpdfstring{Multiple
\(R^2\)}{Multiple R\^{}2}}\label{multiple-r2}
\addcontentsline{toc}{subsection}{Multiple \(R^2\)}

We can calculate the \(R^2\) value for the multiple linear regression
model just like we already did for a simple linear regression model. The
\(R^2\) value is the proportion of variability in the response variable
that is explained by the model. As before, the \(R^2\) value ranges from
0 to 1, where 0 indicates that the model does not explain any
variability in the response variable, and 1 indicates that the model
explains all the variability in the response variable.

For multiple linear regression, we often use the term ``multiple
\(R^2\)'' to distinguish it from the \(R^2\) value for simple linear
regression. The multiple \(R^2\) is the proportion of variability in the
response variable that is explained by the model, taking into account
all the explanatory variables in the model.

As before, for simple linear regression, the multiple \(R^2\) value is
calculated as the sum of squares explained by the model divided by the
total sum of squares:

\[R^2 = \frac{SSM}{SST}\]

where \(SSM\) is the sum of squares explained by the model and \(SST\)
is the total sum of squares, and \(SSM = SST - SSE\).

For the blood pressure data:

\begin{verbatim}
[1] 0.5472837
\end{verbatim}

\(R^2\) for multiple linear regression can also be calculated as the
squared correlation between \((y_1,\ldots,y_n)\) and
\((\hat{y}_1,\ldots,\hat{y}_n)\), where the \(\hat y\) are the fitted
values from the model. The fitted values are calculated as:

\[\hat{y}_i = \hat\beta_0 + \hat\beta_1 x^{(1)} + \ldots + \hat\beta_m x^{(m)}\]

In R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r\_squared }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(m1}\SpecialCharTok{$}\NormalTok{fitted.values, bp\_data}\SpecialCharTok{$}\NormalTok{bp)}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{r\_squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5472837
\end{verbatim}

Or:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sss }\OtherTok{\textless{}{-}} \FunctionTok{anova}\NormalTok{(m1)}
\NormalTok{SSM }\OtherTok{\textless{}{-}}\NormalTok{ sss}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Sum Sq}\StringTok{\textasciigrave{}}\NormalTok{[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ sss}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Sum Sq}\StringTok{\textasciigrave{}}\NormalTok{[}\DecValTok{2}\NormalTok{]}
\NormalTok{SST }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(sss}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Sum Sq}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{R\_squared }\OtherTok{\textless{}{-}}\NormalTok{ SSM }\SpecialCharTok{/}\NormalTok{ SST}
\NormalTok{R\_squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5472837
\end{verbatim}

\subsection*{\texorpdfstring{Adjusted
\(R^2\)}{Adjusted R\^{}2}}\label{adjusted-r2}
\addcontentsline{toc}{subsection}{Adjusted \(R^2\)}

However, we have a little problem to address. The \(R^2\) value
increases as we add more explanatory variables to the model, even if the
additional variables are not associated with the response. This is
because the \(R^2\) value is calculated as the proportion of variability
in the response variable that is explained by the model. As we add more
explanatory variables to the model, the model will always explain more
variability in the response variable, even if the additional variables
are not associated with the response. Some of the variance will be
explained by chance.

Here is an example of this problem. First, here's the explanatory power
of the model with only age and minutes of exercise as the explanatory
variables:

\begin{verbatim}
[1] 0.5472837
\end{verbatim}

Now, we can add a new explanatory variable to the blood pressure model
that is not associated with the response:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bp\_data}\SpecialCharTok{$}\NormalTok{random\_variable }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(bp\_data))}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(bp }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ mins\_exercise }\SpecialCharTok{+}\NormalTok{ random\_variable, }\AttributeTok{data =}\NormalTok{ bp\_data)}
\FunctionTok{summary}\NormalTok{(m2)}\SpecialCharTok{$}\NormalTok{r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5576748
\end{verbatim}

The \(R^2\) value for the model with the random variable is higher than
the \(R^2\) value for the model without the random variable. This is
because the model with the random variable explains more variability in
the response variable, even though the random variable is not associated
with the response.

To address this problem, we can use the adjusted \(R^2\) value. The
adjusted \(R^2\) value is calculated as:

\[R^2_{\text{adj}} = 1 - \frac{SSE / (n - p - 1)}{SST / (n - 1)}\]

where * \(SSE\) is the sum of squared errors * \(SST\) is the total sum
of squares * \(n\) is the number of observations * \(p\) is the number
of explanatory variables in the model.

Or put another way:

\[R^2_{adj} = 1-(1-R^2 )\frac{n-1}{n-p-1}\] In this form, we can see
that as \(p\) increases (as we add explanatory variables) the term
\((n-1)/(n-p-1)\) increases, and the adjusted \(R^2\) value will
decrease if the additional variables are not associated with the
response.

Take home: when we want to compare the explanatory power of models that
differ in the number of explanatory variables, we should use the
adjusted \(R^2\) value.

\section*{Question 4: Are some explanatory variables more important than
others?}\label{question-4-are-some-explanatory-variables-more-important-than-others}
\addcontentsline{toc}{section}{Question 4: Are some explanatory
variables more important than others?}

\markright{Question 4: Are some explanatory variables more important
than others?}

\textbf{Third}, we know how to test the significance of the parameters
using the \(t\)-test.

\textbf{Fourth}, we know how to calculate the confidence intervals for
the parameters, and to make a confidence band.

How important are the explanatory variables and how important are they
relative to each other?

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\textbf{Think, Pair, Share (\#variable-importance)}

How might we assess how important is each of the explanatory variables,
and how important they are relative to each other?

\end{tcolorbox}

The importance of an explanatory variable can be assessed by looking at
the size of the coefficient for that variable. The larger the
coefficient, the more important the variable is in explaining the
response variable.

It is, however, important to remember that the size of the coefficient
depends on the scale of the explanatory variable. If the explanatory
variables are on different scales, then the coefficients will be on
different scales and cannot be directly compared.

In our example, the age variable is measured in years, so the
coefficient is in units mmHg (pressure) per year. The mins\_exercise
variable is measured in minutes, so the coefficient is in units mmHg per
minute. The coefficients are on different scales and cannot be directly
compared. Furthermore, the value of the coefficients would change if we
measured age in months or minutes of exercise in hours.

There are other perspectives we can take when we're assessing
importance. For example, we cannot change our age, but we can change the
number of minutes of exercise. So, the practical importance of the two
variables is quite different in that sense also.

To compare the importance of the explanatory variables that are measured
on different scales, we can standardize the variables before fitting the
model. This means that we subtract the mean of the variable and divide
by the standard deviation. This puts all the variables on the same
scale, so the coefficients can be directly compared. The coefficients
are then in units of the response variable per standard deviation of the
explanatory variable.

However, the coefficients are then not in the original units of the
explanatory variables, so it is not always easy to interpret the
coefficients. So while we can compare the coefficients, they have lost a
bit of their original meaning and are not so easy to interpret.

One way to relate the coefficients in this case is to realise that to
compensate for the blood pressure increase associated with one year of
age, one would need to exercise for a certain number of minutes more.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-tip-color!10!white, leftrule=.75mm, colframe=quarto-callout-tip-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

\emph{Think, Pair, Share (\#exercise-age)}

How many minutes of exercise per week would we need to add to our
fitness schedule to compensate for the blood pressure increase
associated with one year of age?

\end{tcolorbox}

\section*{Question 5: how do we make
predictions?}\label{question-5-how-do-we-make-predictions}
\addcontentsline{toc}{section}{Question 5: how do we make predictions?}

\markright{Question 5: how do we make predictions?}

We already made predictions from a simple linear regression model?

Recall that the equation for multiple linear regression is:

\[y_i = \beta_0 + \beta_1 x_i^{(1)} + \beta_2 x_i^{(2)} + \ldots + \beta_p x_i^{(p)} + \epsilon_i\]

Therefore to get a predicted value of \(y_i\), we can use the estimated
parameters (\(\hat\beta_0, \hat\beta_1, \ldots, \hat\beta_p\)) and the
values of the explanatory variables
(\(x_i^{(1)}, x_i^{(2)}, \ldots, x_i^{(p)}\)):

\[\hat{y}_i = \hat\beta_0 + \hat\beta_1 x_i^{(1)} + \hat\beta_2 x_i^{(2)} + \ldots + \hat\beta_p x_i^{(p)}\]

In R, we can use the \texttt{predict()} function to make predictions
from a multiple linear regression model. Here is an example of how to
make predictions for the values of the explanatory variables in the
original dataset:

Where \texttt{m1} is the multiple linear regression model fitted
earlier. The \texttt{predict} function automatically uses the original
data because we did not provide any new data.

We can also make predictions for new values of the explanatory variables
by providing a new data frame to the \texttt{predict()} function. Here
is an example of how to make predictions for new values of age and
minutes of exercise:

First we need to make some new values of age and minutes of exercise:

Then we can use the \texttt{predict()} function to make predictions for
these new values:

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-important-color!10!white, leftrule=.75mm, colframe=quarto-callout-important-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

The new data frame must have the all the explanatory variables used in
the model, and the variable names must match exactly those used in the
model.

\end{tcolorbox}

We can take this to the next level and make what is called a
``conditional effects plot'' or ``effect plot''. This is a plot that
shows the predicted values of the response variable for different values
of one explanatory variable, while holding the other explanatory
variables constant. Here is an example of how to make a conditional
effects plot for age, while holding minutes of exercise constant at 100:

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-24-1.pdf}}

And lets take this to the next level again and make a conditional
effects plot for three different levels of \texttt{mins\_exercise}:

A new function! And it's one of Owen's favourites:
\texttt{expand.grid()}. This function creates a data frame from all
combinations of the supplied vectors or factors. Here, we are creating a
data frame with all combinations of age (from 20 to 80) and minutes of
exercise (0, 150, and 300).

We then give the new data frame to the \texttt{predict()} function to
get the predicted values for each combination of age and minutes of
exercise:

(Note that we changed)

And make a graph:

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-27-1.pdf}}

\section*{Collinearity}\label{collinearity}
\addcontentsline{toc}{section}{Collinearity}

\markright{Collinearity}

In the blood pressure example data used previously in this chapter there
is no evidence of correlation between the two explanatory variables.
However, in practice, it is common for explanatory variables to be
correlated with each other. This is known as collinearity. It can be
quite problematic for us!

\textbf{Think-pair-share (\#collinearity1)} Imagine if there was perfect
correlation between age and minutes of exercise. This would mean that a
graph of age vs minutes of exercise would show a perfect line. What
would be the implications for the multiple linear regression model? For
example, what would be the \(R^2\) value for a model with one
explanatory variable compared to a model with both explanatory
variables?

Collinearity, specifically \emph{harmful} collinearity, is extremely
common in real dataset that result from observational studies. This is
because in observational studies there are often numerous explanatory
variables, and they are often correlated with each other. This is a
situation that is ripe for collinearity problems. (Collinearity can also
happen in data resulting from designed manipulative experiments, but is
hopefully relatively rare there because a well-designed experiment will
try to avoid collinearity by ensuring that the explanatory variables are
independent.)

So what is collinearity, and why is it a problem?

\textbf{\emph{Put simply, collinearity is when one explanatory variable
is predictable from a linear combination of others.}}

This can happen due to strong correlation among pairs of explanatory
variables, or due to more complex relationships involving three or more
explanatory variables.

For example, if we have three explanatory variables, \(x_1, x_2,\) and
\(x_3\), and if \(x_3\) can be predicted from a linear combination of
\(x_1\) and \(x_2\), then we have collinearity. For example, if:

\[x_3 = 2 \cdot x_1 + 3 \cdot x_2 + \text{small random noise}\]

In this case, variable \(x_3\) is a linear combination of \(x_1\) and
\(x_2\), plus some small random noise. This means that if we know the
values of \(x_1\) and \(x_2\), we can predict the value of \(x_3\) quite
accurately. Also, in this case we might not have strong correlation
between any pair of the explanatory variables, but there is still
collinearity because \(x_3\) is predictable from \(x_1\) and \(x_2\). So
lack of correlation between pairs of explanatory variables does not
guarantee that there is no collinearity.

\textbf{\emph{It is a problem because it makes the slope estimates
unstable and therefore difficult to interpret.}}

Let us see this instability in practice. First let's look at the really
extreme example of perfect collinearity. Here's a new version of the
blood pressure data in which the minutes of exercise variable is
perfectly predicted from age:

Here is the line of code that makes the perfect correlation between age
and minutes of exercise:

Now we generate the blood pressure variable as before:

Now we fit a multiple linear regression model with only age:

\begin{verbatim}

Call:
lm(formula = bp ~ age, data = bp_data_perfect)

Residuals:
    Min      1Q  Median      3Q     Max 
-33.546  -9.147  -0.327   8.938  33.213 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 100.43331    4.54751  22.085  < 2e-16 ***
age           0.47541    0.08549   5.561 2.33e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 14.54 on 98 degrees of freedom
Multiple R-squared:  0.2399,    Adjusted R-squared:  0.2321 
F-statistic: 30.92 on 1 and 98 DF,  p-value: 2.325e-07
\end{verbatim}

The estimated slope (coefficient) is 0.48, which is close to the true
value of 0.5. The 95\% confidence interval is 0.31 to 0.65, which
includes the true value of 0.5. All good then.

Now we fit the multiple linear regression model with both age and
minutes of exercise included:

\begin{verbatim}

Call:
lm(formula = bp ~ mins_exercise + age, data = bp_data_perfect)

Residuals:
    Min      1Q  Median      3Q     Max 
-33.546  -9.147  -0.327   8.938  33.213 

Coefficients: (1 not defined because of singularities)
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)   147.97398    4.48276  33.010  < 2e-16 ***
mins_exercise  -0.47541    0.08549  -5.561 2.33e-07 ***
age                  NA         NA      NA       NA    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 14.54 on 98 degrees of freedom
Multiple R-squared:  0.2399,    Adjusted R-squared:  0.2321 
F-statistic: 30.92 on 1 and 98 DF,  p-value: 2.325e-07
\end{verbatim}

This output is a bit strange. The estimate for age is now \texttt{NA}.
This is because the model cannot distinguish between the effects of age
and minutes of exercise, since they are perfectly correlated. The model
is unable to estimate the coefficient for age of exercise, so it returns
\texttt{NA}.

This is an example of instability of coefficients due to collinearity.
The coefficient for age is completely unstable, as it changes from a
number to \texttt{NA} depending on whether minutes of exercise is
included in the model or not.

Actually, you can see that the estimate for \texttt{mins\_exercise} are
the same (except the sign of the coefficient) as the estimate for age in
the previous model. This is because minutes of exercise is perfectly
correlated with age, so the model is essentially using minutes of
exercise as a proxy for age. With perfect collinearity, the model cannot
distinguish between the effects of the two variables\ldots{} they are
effectively identical.

You can also see that the \(R^2\) value doesn't change when the second
variable is added. That is, the model with only age included is
identical to the model with both age and minutes of exercise included.
This is because minutes of exercise is perfectly correlated age, so
including minutes of exercise in the model does not add any new
information.

That is a pretty extreme example of perfect collinearity. In practice,
collinearity is often not perfect, but still strong enough to cause
problems.

Let's look at the less extreme example of collinearity we had earlier,
with three explanatory variables, \(x_1, x_2,\) and \(x_3\), and where
\(x_3\) can be predicted from a linear combination of \(x_1\) and
\(x_2\) plus some random noise:

\begin{verbatim}
            x1          x2        x3          y
x1  1.00000000 -0.04953215 0.1877534  0.6079515
x2 -0.04953215  1.00000000 0.5194100 -0.1488812
x3  0.18775342  0.51940999 1.0000000  0.6434430
y   0.60795153 -0.14888117 0.6434430  1.0000000
\end{verbatim}

We see that there is not strong correlation between any pair of the
explanatory variables, but there is still collinearity because \(x_3\)
is predictable from \(x_1\) and \(x_2\).

Let's look for evidence of instability of the coefficients. First, we
fit the multiple linear regression model with all three explanatory
variables included:

\begin{verbatim}
              Estimate Std. Error   t value     Pr(>|t|)
(Intercept)  4.9806739 0.10734366  46.39933 1.490805e-67
x1           1.4675042 0.11972274  12.25752 2.384482e-21
x2          -1.9193496 0.12990373 -14.77517 1.832330e-26
x3           0.4885226 0.02244616  21.76419 6.723265e-39
\end{verbatim}

Do these change much if we fit the model with only \(x_1\) and \(x_2\)
included?

\begin{verbatim}
              Estimate Std. Error   t value     Pr(>|t|)
(Intercept)  5.3105865  0.2575325 20.621034 3.113931e-37
x1           2.1192629  0.2809162  7.544111 2.464756e-11
x2          -0.3956201  0.2651792 -1.491897 1.389714e-01
\end{verbatim}

Yes, they do change quite a bit. The coefficients for \(x_1\) and
\(x_2\) are quite different when \(x_3\) is included in the model
compared to when it is not included. This is because \(x_3\) is
predictable from \(x_1\) and \(x_2\), so including \(x_3\) in the model
changes the interpretation of the coefficients for \(x_1\) and \(x_2\).

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, coltitle=black, opacitybacktitle=0.6, left=2mm, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, toprule=.15mm, breakable, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, titlerule=0mm, colback=white, bottomrule=.15mm, arc=.35mm, toptitle=1mm]

In a not so extreme case such as this one, the coefficients will not be
completely unstable (i.e., they will not change from a number to NA) but
they can still change quite a bit depending on which other collinear
variables are included in the model.

\end{tcolorbox}

The bottom line is that collinearity between explanatory variables
complicates the interpretation of the model coefficients. If there is
collinearity/correlation between the explanatory variables, then the
model coefficients can be unstable and difficult to interpret.

Let's have one more look at this instability that is caused by
collinearity. And make this demonstration a bit more general. We'll
simulate data with two explanatory variables that are correlated with
each other to varying degrees. We'll then fit multiple linear regression
models with both explanatory variables included, and see how the
stability of the coefficients changes as we change the correlation
between the explanatory variables.

\begin{verbatim}
Warning in geom_point(color = "blue", alpha = 0.3, height = 0): Ignoring
unknown parameters: `height`
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-36-1.pdf}}

In the left panel we see the slope estimates for \(x_1\) from the
multiple linear regression model with both \(x_1\) and \(x_2\) included,
for different levels of correlation between \(x_1\) and \(x_2\). When
there is no correlation between \(x_1\) and \(x_2\) (i.e., no
collinearity), the slope estimates are quite stable and close to the
true value of 1.

As the correlation between \(x_1\) and \(x_2\) increases, the slope
estimates become more variable (= less stable). At correlation of 0.9,
the slope estimates are quite variable and can be very far from the true
value of 1.

The right panel shows the variance of the slope estimates as a function
of the correlation between \(x_1\) and \(x_2\). Variance here is a
measure of the amount of vertical spread in the left panel.

We see that the variance of the slope estimates increases as the
correlation between \(x_1\) and \(x_2\) increases. This shows that
greater collinearity between explanatory variables leads to greater
instability (variance) of the slope estimates.

This increase in variance caused by collinearity is known as the
\textbf{variance inflation effect}. The variance inflation effect makes
it difficult to interpret the coefficients of the model, because the
coefficients can be quite unstable and can change a lot depending on
which other collinear variables are included in the model.

\subsection*{\texorpdfstring{Collinearity and interpretation of
\(R^2\)}{Collinearity and interpretation of R\^{}2}}\label{collinearity-and-interpretation-of-r2}
\addcontentsline{toc}{subsection}{Collinearity and interpretation of
\(R^2\)}

Collinearity also affects the interpretation of the \(R^2\) values.
Collinearity will cause the collinear explanatory variables to share
some of the explained variance. The \(R^2\) value of the multiple
regression will then be less than the sum of the \(R^2\) values of the
individual regressions of the response variable on each of the
explanatory variables separately.

\(R^2\) of the age only model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m2\_age)}\SpecialCharTok{$}\NormalTok{r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2900831
\end{verbatim}

\(R^2\) of the mins\_exercise only model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m2\_mins\_exercise)}\SpecialCharTok{$}\NormalTok{r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.212204
\end{verbatim}

\(R^2\) of the model with both age and mins\_exercise:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m2\_both)}\SpecialCharTok{$}\NormalTok{r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5472837
\end{verbatim}

In this case the two explanatory variables are strongly correlated and
so share a lot of the explained variance. The \(R^2\) value of the model
with both explanatory variables is much less than the sum of the \(R^2\)
values of the models with each explanatory variable separately. In fact,
either of the models with only one explanatory variable is nearly as
good as the model with both explanatory variables. We don't gain much
from including another explanatory variable in the model when we already
include one explanatory variable that is strongly correlated with the
other.

\subsection*{Do I have a problem (with
collinearity)?}\label{do-i-have-a-problem-with-collinearity}
\addcontentsline{toc}{subsection}{Do I have a problem (with
collinearity)?}

There are several ways to measuring collinearity between explanatory
variables and to assess if it is a problematic. One way is to look at
the correlation matrix of the explanatory variables. If there are strong
correlations between any pair of explanatory variables, then there is
likely to be collinearity.

But recall that collinearity can also occur without strong pairwise
correlations. So another way to detect collinearity is to calculate the
Variance Inflation Factor (VIF). This is so named because it measures
how much the variance of the estimated regression coefficients is
increased due to collinearity. (Recall that we saw the variance
inflation effect in the simulation above.)

Recall the definition of collinearity: it is when an explanatory
variable is predictable from a linear combination of others. To
calculate the VIF for a specific explanatory variable, we fit a linear
regression model with that explanatory variable as the response
variable, and all the other explanatory variables as the explanatory
variables. We then calculate the \(R^2\) value for this model. The VIF
is then calculated as:

\[VIF_j = \frac{1}{1 - R^2_j}\]

where \(R^2_j\) is the \(R^2\) value from the model with explanatory
variable \(j\) as the response variable, and all other explanatory
variables as the explanatory variables.

In the case where the explanatory variable \(j\) is not predictable from
the other explanatory variables at all, then \(R^2_j = 0\), and the VIF
is 1. This indicates that there is no collinearity.

In the case where the explanatory variable \(j\) is perfectly
predictable from the other explanatory variables, then \(R^2_j = 1\),
and the VIF is infinite. This indicates that there is perfect
collinearity.

To get the VIF for a multiple linear regression model with multiple
explanatory variables, we calculate the VIF for each explanatory
variable separately.

The VIF measures how much the variance of the estimated regression
coefficients is increased due to collinearity.

In R, we can calculate the VIF using the \texttt{vif()} function from
the \texttt{car} package. Here is the code to calculate the VIF for the
blood pressure model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading required package: carData
\end{verbatim}

\begin{verbatim}

Attaching package: 'car'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:dplyr':

    recode
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:purrr':

    some
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          age mins_exercise 
     1.006948      1.006948 
\end{verbatim}

We see that the VIF values for both explanatory variables are close to
1, indicating that there is no collinearity between the explanatory
variables.

For the previous example with collinearity among three explanatory
variables, we can calculate the VIF as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(m\_collinear\_123)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      x1       x2       x3 
1.069365 1.412832 1.460863 
\end{verbatim}

We see that the VIF values for all three explanatory variables are
greater than 1, indicating that there is collinearity between the
explanatory variables. The VIF for \(x_3\) is highest, indicating that
\(x_3\) is predictable from \(x_1\) and \(x_2\). But none of the VIF
values are extremely high, indicating that the collinearity is not
severe.

A VIF value greater than 5 or 10 is often used as a rule of thumb to
indicate that there is collinearity between the explanatory variables.

Let's make an example of three explanatory variables with more severe
collinearity:

\begin{verbatim}
       x1        x2        x3 
 4.277416 10.644760 13.360572 
\end{verbatim}

We see that the VIF values of \(x_2\) and \(x_3\) are greater than 10,
indicating that there is strong collinearity between the explanatory
variables. The coefficients for \(x_2\) and \(x_3\) will be quite
unstable and difficult to interpret.

\subsection*{What to do about
collinearity?}\label{what-to-do-about-collinearity}
\addcontentsline{toc}{subsection}{What to do about collinearity?}

Imagine we see high VIFs, we can conclud that there is collinearity
between explanatory variables, and that the coefficients for those
variables are likely to be unstable and difficult to interpret. What can
we do???

The answer is we should \emph{think}!

\begin{itemize}
\tightlist
\item
  Are predictors measuring the same concept?
\item
  Is this collinearity expected from the study design?
\item
  Do I care about interpretation, or am I only interested in prediction?
\end{itemize}

And then consider some possible remedies:

\begin{itemize}
\tightlist
\item
  Combine predictors (index, PCA, biologically meaningful composite).
\item
  Remove one of a set of redundant explanatory variables.
\item
  Use regularization if prediction is the goal.
\end{itemize}

We'll look at some of these later in the course.

\section*{Review}\label{review}
\addcontentsline{toc}{section}{Review}

\markright{Review}

Simple regression:

\begin{itemize}
\tightlist
\item
  How well does the model describe the data: Correlation and \(R^2\)
\item
  Are the parameter estimates compatible with some specific value
  (\(t\)-test)?
\item
  What range of parameters values are compatible with the data
  (confidence intervals)?
\item
  What regression lines are compatible with the data (confidence band)?
\item
  What are plausible values of other data (prediction band)?
\end{itemize}

Multiple regression:

\begin{itemize}
\tightlist
\item
  Multiple linear regression \(x_1\), \(x_2\), \ldots, \(x_m\)
\item
  Checking assumptions.
\item
  \(R^2\) in multiple linear regression
\item
  \(t\)-tests, \(F\)-tests and \(p\)-values
\end{itemize}

\section*{Extras}\label{extras-2}
\addcontentsline{toc}{section}{Extras}

\markright{Extras}

\subsection*{3D plot of multiple linear
regression}\label{d-plot-of-multiple-linear-regression}
\addcontentsline{toc}{subsection}{3D plot of multiple linear regression}

3D plots can help us to visualise multiple linear regression models with
two explanatory variables. They are also kind of cool. They can also be
difficult to interpret. So use with caution!

Here is the code to make a 3D plot of the blood pressure data. The
y-axis is blood pressure, the x-axis is age, and the z-axis is minutes
of exercise. Here is a 3d plot that we can interactive with and rotate:

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-44-1.pdf}}

\subsection*{Publication ready table of
results}\label{publication-ready-table-of-results}
\addcontentsline{toc}{subsection}{Publication ready table of results}

Sometimes we need to put a table of coefficients and confidence
intervals into a report or publication. One option is to make a table in
Word, and to manually enter the coefficients and confidence intervals.
This is tedious and error prone. A much better option is to use R to
make the table for us. One way to do this is to use the \texttt{broom}
package to tidy up the model output into a data frame, and then use the
\texttt{knitr} package to make a table from the data frame.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(broom)}
\FunctionTok{library}\NormalTok{(knitr)}
\NormalTok{tidy\_m1 }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(m1, }\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{kable}\NormalTok{(tidy\_m1, }\AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{caption =} \StringTok{"Multiple linear regression results}
\StringTok{for blood pressure data"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2000}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1286}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1143}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1286}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}@{}}
\caption{Multiple linear regression results for blood pressure
data}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
estimate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
std.error
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
statistic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p.value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
conf.low
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
conf.high
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
estimate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
std.error
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
statistic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p.value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
conf.low
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
conf.high
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
(Intercept) & 89.176 & 3.641 & 24.495 & 0 & 81.950 & 96.401 \\
age & 0.510 & 0.060 & 8.473 & 0 & 0.391 & 0.630 \\
mins\_exercise & -0.090 & 0.012 & -7.424 & 0 & -0.114 & -0.066 \\
\end{longtable}

Another approach is to use \texttt{tbl\_regression} function within the
\texttt{gtsummary} package to get a publication ready table of the
coefficients and confidence intervals:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gtsummary)}
\FunctionTok{tbl\_regression}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{table}
\fontsize{12.0pt}{14.4pt}\selectfont
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}lccc}
\toprule
\textbf{Characteristic} & \textbf{Beta} & \textbf{95\% CI}\textsuperscript{\textit{1}} & \textbf{p-value} \\ 
\midrule\addlinespace[2.5pt]
age & 0.51 & 0.39, 0.63 & <0.001 \\ 
mins\_exercise & -0.09 & -0.11, -0.07 & <0.001 \\ 
\bottomrule
\end{tabular*}
\begin{minipage}{\linewidth}
\textsuperscript{\textit{1}}CI = Confidence Interval\\
\end{minipage}
\end{table}

To use either approach most efficiently you will, however, need to write
your report using R Markdown or Quarto so that the table is
automatically created in your report document.

\subsection*{A figure showing the coefficients and confidence
intervals}\label{a-figure-showing-the-coefficients-and-confidence-intervals}
\addcontentsline{toc}{subsection}{A figure showing the coefficients and
confidence intervals}

As well as or rather than a table of coefficients, we could make a
figure showing the coefficients and confidence intervals for each
explanatory variable. This can be a nice way to visualise the results of
the multiple linear regression model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_m1 }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(m1, }\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{tidy\_m1 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{!=} \StringTok{"(Intercept)"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ term, }\AttributeTok{y =}\NormalTok{ estimate)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ conf.low, }\AttributeTok{ymax =}\NormalTok{ conf.high), }\AttributeTok{width =}
                \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Explanatory variable"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Coefficient estimate"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Multiple linear regression coefficients}\SpecialCharTok{\textbackslash{}n}\StringTok{and confidence intervals"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{7.1-multiple-explanatory-variables-part1_files/figure-pdf/unnamed-chunk-47-1.pdf}}


\backmatter


\end{document}
