{"title":"Categorical explanatory variables (L5)","markdown":{"headingText":"Categorical explanatory variables (L5)","headingAttr":{"id":"","classes":["unnumbered"],"keyvalue":[]},"containsRefs":false,"markdown":"```{r}\nsuppressMessages(library(tidyverse))\nsuppressMessages(library(gtsummary))\nsuppressMessages(library(broom))\nsuppressMessages(library(knitr))\nsuppressMessages(library(kableExtra))\n```\n\n\n\n\n\nThis chapter contains the content of the fifth lecture of the course BIO144 Data Analysis in Biology at the University of Zurich.\n\n## Introduction\n\nWe so far only considered continuous explanatory variables. Today we will look at the following topics:\n\n* Binary explanatory variables.\n* Categorical explanatory variables.\n\n\n\n### The good news\n\nThe good news is that the mathematical model of a linear regression does not change when we include binary or categorical explanatory variables. The model is still:\n\n$$y_i = \\beta_0 + \\beta_1 x^{(1)}_i + \\beta_2 x^{(2)}_i + \\ldots + \\epsilon_i$$\n\nThis means that things like the $R^2$, $F$-test, $t$-test, confidence intervals, etc. are still applicable. We also carry out model diagnostics mostly in the same way. So a lot of what you already learned is useful here. I suppose this is a good thing, since you don't have to learn it again. But it also means that you have to have learned and understood it by now. If you haven't, please reach out for assistance.\n\n### The bad news\n\nThere isn't any.\n\n## Binary explanatory variables\n\nImagine the question \"do people who smoke have higher blood pressure?\" Though we could quantify the amount of smoking, we could also just ask if someone smokes or not. This is a binary variable. We can put that information into a variable $x$ where values $x_i$ can take on the values 0 or 1, where 0 denotes non-smoker and 1 denotes smoker. The linear model is then:\n\n$$y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$$\nHuh? This is exactly the same model as when the explanatory variable $x$ is continuous. The only difference is that $x_i$ can only be a zero or a one. The interpretation of the $\\beta_1$ is also the same: it is the change in the response variable $y$ when $x$ changes by one unit. In this case, the change is from non-smoker to smoker.\n\n::: {.callout-tip}\n## Think, Pair, Share (#bp-nonsmoker)\n\nWhat is the predicted value of $y$ for a non-smoker? And for a smoker?\n:::\n\n\nThe $\\beta_1$ can be thought of as the effect on blood pressure of smoking. If $\\beta_1$ is positive, smoking increases blood pressure. If $\\beta_1$ is negative, smoking decreases blood pressure.\n\nFor the question of whether smoking influences blood pressure we can formulate a null and an alternative hypothesis.\n\n* Null hypothesis: $\\beta_1 = 0$. That is, smoking has no effect on blood pressure.\n* Alternative hypothesis: $\\beta_1 \\neq 0$. That is, smoking has an effect on blood pressure.\n\n\n::: {.callout-tip}\n## Think, Pair, Share (#null-test)\n\nWhat statistical test can we use to test the null hypothesis here?\n:::\n\n\nLet's take a graphical view of the case of a binary response variable.\n\n```{r}\nn <- 50\nsmoke_01 <- sample(c(0,1), n, replace = TRUE)\nbp <- 80 + 15*smoke_01 + rnorm(n, 0, 2)\nbp_data_smoking <- data.frame(smoke_01, bp)\n```\n\n```{r}\nggplot(bp_data_smoking, aes(x = smoke_01, y = bp)) +\n  geom_point() +\n  labs(x = \"Smoking (0=no, 1=yes)\", y = \"Blood pressure\")\n```\n\n\n::: {.callout-tip}\n## Think, Pair, Share (#draw-coefficients)\n\nDraw on the graph a representation of the model $\\beta_0$, $\\beta_1$, and $\\beta_0 + \\beta_1$.\n:::\n\n\nHere is a graph showing the mean of the two groups (non-smoker and smoker) and a vertical line for the difference between the two means:\n\n```{r}\ngroup_means <- bp_data_smoking %>%\n  group_by(smoke_01) %>%\n  summarise(mean_bp = mean(bp), .groups = \"drop\")\nggplot(bp_data_smoking, aes(x = smoke_01, y = bp)) +\n  geom_point() +\n  geom_point(data = group_means, aes(x = smoke_01, y = mean_bp), color = \"red\", size = 5) +\n  geom_hline(yintercept = group_means$mean_bp[1], color = \"red\", linetype = \"dotted\") +\n  geom_hline(yintercept = group_means$mean_bp[2], color = \"red\", linetype = \"dotted\") +\n  geom_segment(aes(x = 0.5, y = group_means$mean_bp[1],\n                   xend = 0.5, yend = group_means$mean_bp[2]),\n               color = \"blue\", linewidth = 1,\n               arrow = arrow(length = unit(0.5,\"cm\"), ends = \"both\")) +\n  labs(x = \"Smoking (0=no, 1=yes)\", y = \"Blood pressure\") +\n  annotate(\"text\", x = 0.5, y = mean(group_means$mean_bp), label = \"beta_1\", hjust = -0.1) +\n  annotate(\"text\", x = 0.04, y = group_means$mean_bp[1]+0.5, label = \"beta_0\", hjust = -0.1) +\n  annotate(\"text\", x = 0.96, y = group_means$mean_bp[2]+0.5, label = \"beta_0 + beta_1\", hjust = 1) +\n  ggtitle(\"Effect of smoking on blood pressure\")\n```\n\n\n### Example: Smoking and blood pressure\n\nLet's do a real example. We have data on blood pressure and smoking status. We want to know if smoking has an effect on blood pressure.\n\nTo fit the linear model in R, we use the `lm` function as before. The only difference is that the explanatory variable is binary. But we do not need to tell this to R. It can handle things just fine. So, the code to fit the model is:\n\n```{r}\n#| echo = TRUE\nmod_smoking <- lm(bp ~ smoke_01, data = bp_data_smoking)\n```\n\nOf course, we next look at the model diagnostic plots to see if the model assumptions are met.\n\n```{r}\npar(mfrow = c(2,2))\nsuppressMessages(plot(mod_smoking, add.smooth = FALSE))\n```\n\nThe QQ-plot shows that the residuals are close enough to the normal distribution.\n\nThe other plots are a little different from before, because we have only two fitted, one for non-smokers and one for smokers. But we can still see that the residuals show no clear difference between the two groups. Also there is no leverage plot, due to all leverages being equal (all data points are equal distance from $\\hat{x}$)\n\nHere is how it could have looked if smoking also increased the variability in the blood pressure among individuals:\n\n```{r}\nbp <- 80 + 15*smoke_01 + rnorm(n, 0, 5 + 5*smoke_01)\nbp_data_smoking_het <- data.frame(smoke_01, bp)\nggplot(bp_data_smoking_het, aes(x = smoke_01, y = bp)) +\n  geom_point() +\n  labs(x = \"Smoking (0=no, 1=yes)\", y = \"Blood pressure\")\n```\n\nIt is clear that not only does smoking increase the mean blood pressure, but it also increases the inter-individuals (between individual) variability in blood pressure.\n\n```{r}\nmod_smoking_het <- lm(bp ~ smoke_01, data = bp_data_smoking_het)\npar(mfrow = c(2,2))\nsuppressMessages(plot(mod_smoking_het, add.smooth = FALSE))\n```\n\nWe can see in the residuals vs. fitted plot that the residuals of the non-smokers are less spread out than the residuals of the smokers. This is a sign of heteroscedasticity (difference in variance among groups).\n\n### Does smoking have an effect on blood pressure?\n\nWe address this question by testing the null hypothesis of no effect of smoking on blood pressure? This null hypothesis corresponds to $\\beta_1 = 0$. This is the same as testing if the slope of the line is different from zero, for which we use a $t$-test.\n\nHere is the table of estimates and the $t$-test:\n\n```{r}\ntbl_regression(mod_smoking)\n```\n\nOr for more information:\n\n```{r}\nsummary(mod_smoking)$coefficients\n```\n\nThere is very clear evidence that smoking increases blood pressure. The $p$-value is very small.\n\n### Reporting our findings\n\nAn appropriate graph would be a scatter plot of blood pressure against smoking status, just like we made above. You may see graphs of such data that are bar graphs with error bars. This is not a good way to present the data, because it hides the individual data points and their distribution. It is better to show the individual data points. If there are very many data points, however, a box and whisker plot may be more informative.\n\n```{r}\nggplot(data = bp_data_smoking, mapping = aes(x = as.factor(smoke_01), y = bp)) +\n  geom_boxplot()\n```\n\n\nAn appropriate sentence to write about our results would be. \"We found that smoking increases blood pressure by 15 units (95% CI: 14 to 17 units, $t = 25.8$, $p < 0.001$, $df = 48$).\" This sentence gives the effect size, the confidence interval, and the $t$-test results. **It is a sentence about the the effect of smoking.**\n\nNot so good would be to write: \"There was a statistically significant effect of smoking on blood pressure ($t = 25.8$, $p < 0.001$, $df = 48$).\" -- This is not informative; it does not even give the direction of the effect. **It is a sentence about statistical significance.**.\n\n**Generally speaking, put the focus on the effect/relationship, not on the statistical significance.**\n\n\n### Words instead of 0/1\n\nIn the smoking explanatory variable we denoted a non-smoker with a 0 and a smoker with a 1. Could we instead have denoted a non-smoker with the word \"non-smoker\" and a smoker with the word \"smoker\"? Lets see how the `lm` function feels about that.\n\n```{r}\nbp_data_smoking_words <- bp_data_smoking\nbp_data_smoking_words$status <- factor(ifelse(bp_data_smoking$smoke_01 == 0, \"non-smoker\", \"smoker\"))\nbp_data_smoking_words <- bp_data_smoking_words %>%\n  select(bp, status)\nhead(bp_data_smoking_words)\n```\n\nThe data now has the variable that describes smoker status as a word. Here's a graph of that data:\n\n```{r}\nggplot(bp_data_smoking_words, aes(x = status, y = bp)) +\n  geom_point() +\n  labs(x = \"Smoking status\", y = \"Blood pressure\")\n```\n\nVery nice. Now we can fit the model:\n\n```{r}\nmod_smoking_words <- lm(bp ~ status, data = bp_data_smoking_words)\nsummary(mod_smoking_words)$coefficients\n```\n\nThe numbers in this table are exactly the same as before, when we used the 0/1 coding. The `lm` function is pretty smart. It recodes the two levels (non-smoker and smoker) in the status variable to be a binary variable. The `summary` function then gives the estimates for the two levels.\n\n```{r eval = FALSE}\ntbl_regression(mod_smoking_words)\n```\n\nWe can also get the $R^2$ value, and it has the same meaning and is calculated in the same way.\n\n```{r}\nsummary(mod_smoking_words)$r.squared\n```\n\nSo, a linear model with a binary explanatory variable very similiar to a linear model with a continuous explanatory variable. A difference is that the estimates are not slopes, but differences in means between the two groups.\n\n::: {.callout-note}\nA linear model with a binary explanatory variable is the same as a two-sample $t$-test:\n\n```{r}\nt.test(bp ~ status, data = bp_data_smoking_words, var.equal = TRUE)\n```\n\nThe value of $t$-statistic is the same as exactly the value of the $t$-statistic in the linear output. It is exactly the same test.\n:::\n\n\n::: {.callout-note}\nYou may hear the term \"binary regression\" or \"logistic regression\" in the future. This is a different type of regression model that is used when the response variable is binary. The model we are talking about here is called \"linear regression with binary explanatory variables\".\n:::\n\n\n::: {.callout-note}\nIn all that went above, we assumed that observations were independent. I.e., we assumed there were 50 truly independent observation. This is a very strong assumption. In reality, we might have made more than one measure of blood pressure from one individual. This is called \"clustering\" or \"repeated measures\". A consequence would be that we not then have 50 truly independent observation, we would have fewer than 50, and so we would have fewer than 48 degrees of freedom for error. We will talk about this again later in the course.\n:::\n\n## Categorical explanatory variables\n\nImage we have a new question: \"Is a person's blood pressure related to their diet?\" We have data on the diet of 50 people and we have coded their diets as: \"meat heavy\", \"Mediterranean\", \"vegetarian\", and \"vegan\".\n\nHere is an example dataset:\n\n```{r}\nset.seed(1)\nbp_data_diet <- tibble(diet = sample(c(\"meat heavy\", \"Mediterranean\",\n                                       \"vegetarian\", \"vegan\"),\n                                     50, replace = TRUE)) |> \n  mutate(bp = ceiling(rnorm(50, mean = ifelse(diet == \"meat heavy\", 120,\n                                       ifelse(diet == \"Mediterranean\", 110,\n                                              ifelse(diet == \"vegetarian\", 100, 90))),\n                   sd = 10)),\n         person_ID = paste0(\"person_\", 1:50))\nhead(bp_data_diet)\n```\n\nAnd here's a graph of the dataset:\n\n```{r}\nggplot(bp_data_diet, aes(x = diet, y = bp)) +\n  geom_point() +\n  labs(x = \"Diet\", y = \"Blood pressure\")\n```\n\nWe can see quite a lot from this, for example that the \"meat heavy\" diet is associated with higher blood pressure.\n\nBut how can a linear model be used with such an explanatory variable?\n\n### Dummy variables\n\nThe trick is to convert the categorical variable into a set of binary variables. For a categorical variable with $k$ levels, we create $k - 1$ binary variables $x_i^{(j)}$.\n\nWe already did this with the smoking status variable. It contained two levels, \"non-smoker\" and \"smoker\". We created a binary variable $x_i^{(1)}$ that was 1 if the $i$-th person was a smoker and 0 if they were a non-smoker. That is, the categorical variable *smoking status* had $k = 2$ levels which were recoded into $k - 1 = 1$ binary variables.\n\nFor the diet variable, we have $k = 4$ levels. So we should create $k - 1 = 3$ binary variables. We create one less than the number of levels because the last level is the \"baseline\" level. The baseline level is the level that the other levels are compared to. In this case, the baseline level is \"meat heavy\". The other levels are compared to \"meat heavy\".\n\nAnother way to think about why we need one less binary variable than the number of levels is that when meat_heavy = 0 & Mediterranean = 0 & vegetarian = 0, we there is no other possibility than the person has a vegan diet. We infer the vegan diet from a process of elimination of the other possibilities. This is why we only need three binary variables, and more generally only need $k - 1$ binary variables for a categorical variable with $k$ levels.\n\nHere is the dataset with four binary variables:\n\n```{r}\nbp_data_diet <- bp_data_diet %>%\n  mutate(meat_heavy = ifelse(diet == \"meat heavy\", 1, 0),\n         Mediterranean = ifelse(diet == \"Mediterranean\", 1, 0),\n         vegetarian = ifelse(diet == \"vegetarian\", 1, 0),\n         vegan = ifelse(diet == \"vegan\", 1, 0))\nhead(bp_data_diet)\n```\n\nAnd here it is with three:\n\n```{r}\nselect(bp_data_diet, -meat_heavy) |> head()\n```\n\nThe point is that the second table with one less binary variable has exactly the same information as the first table with four binary variables. It has the same information because we know that there are only four possible diets in the dataset.\n\nNow we can use the following linear model, which has three binary explanatory variables:\n\n$$y_i = \\beta_0 + \\beta_1 x_i^{(1)} + \\beta_2 x_i^{(2)} + \\beta_3 x_i^{(3)} + \\epsilon_i$$\n\nwhere $x_i^{(1)}$ is the binary variable for the Mediterranean diet, $x_i^{(2)}$ is the binary variable for the vegetarian diet, and $x_i^{(3)}$ is the binary variable for the vegan diet.\n\n\n::: {.callout-tip}\n## Think, Pair, Share (#beta0-meaning)\n\nQuestion: What is the interpretation of $\\beta_0$ in this model?\n:::\n\n\nIt is the expected value of the response variable when all the explanatory variables are zero. I.e., it is the intercept. In this case, it is the expected blood pressure of a person on a meat heavy diet because the meat heavy diet is the baseline diet.\n\nMathematically, $\\hat{y} = \\beta_0$ when $x_i^{(1)} = x_i^{(2)} = x_i^{(3)} = 0$. This is the case when the person is on a meat heavy diet, because $x_i^{(1)} = 0$ means not on a Mediterranean diet, $x_i^{(2)} = 0$ means not on a vegetarian diet, and $x_i^{(3)} = 0$ means not on a vegan diet.\n\n::: {.callout-tip}\n## Think, Pair, Share (#beta1-meaning)\n\nWhat is the interpretation of $\\beta_1$ in this model?\n:::\n\nRecall the meaning of the $\\beta_j$ coefficients in the model of smoking effects on blood pressure. It was the expected difference in blood pressure between a smoker and a non-smoker. In this model, $\\beta_1$ is the expected difference in blood pressure between a person on a Mediterranean diet and a person on a meat heavy diet.\n\n**Question:** What is the interpretation of $\\beta_2$ in this model?\n\n**Answer:** $\\beta_2$ is the expected difference in blood pressure between a person on a vegetarian diet and a person on a meat heavy diet.\n\n**Question:** What is the interpretation of $\\beta_3$ in this model?\n\n**Answer:** $\\beta_3$ is the expected difference in blood pressure between a person on a vegan diet and a person on a meat heavy diet.\n\nSo, each of the three coefficients $\\beta_1$, $\\beta_2$, and $\\beta_3$ is the expected difference in blood pressure between a person on a particular diet and a person on the meat heavy diet. Meat heavy is the reference / intercept diet.\n\n### In a visualisation\n\nHere is a visualisation of the model:\n\n```{r}\nbp_model_diet <- lm(bp ~ diet, data = bp_data_diet)\ngroup_means <- bp_data_diet %>%\n  group_by(diet, .groups = \"drop\") %>%\n  summarise(mean_bp = mean(bp))\nggplot(bp_data_diet, aes(x = diet, y = bp)) +\n  geom_point() +\n  geom_hline(yintercept = coef(bp_model_diet)[1], color = \"red\") +\n  geom_point(data = group_means, aes(y = mean_bp), color = \"blue\", size = 3) +\n  geom_segment(data = group_means[-2,], aes(x = diet, xend = diet,\n                                       y = coef(bp_model_diet)[1], yend = mean_bp),\n               color = \"blue\",\n               arrow = arrow(length = unit(0.5,\"cm\"), ends = \"both\")) +\n  labs(title = \"Blood pressure by diet\",\n       x = \"Diet\",\n       y = \"Blood pressure\") +\n  annotate(\"text\", x = 0, y = group_means$mean_bp[2]+1.5,\n            label = \"beta_0\", hjust = -0.5) +\n  annotate(\"text\", x = 2, y = mean(group_means$mean_bp[c(2, 1)]),\n            label = \"beta_1\", hjust = -0.1) +\n  annotate(\"text\", x = 3, y = mean(group_means$mean_bp[c(2, 3)]),\n            label = \"beta_2\", hjust = -0.1) +\n  annotate(\"text\", x = 4, y = mean(group_means$mean_bp[c(2, 4)]),\n            label = \"beta_3\", hjust = -0.1) \n\n\n```\n\n### Degrees of freedom of a categorical variable\n\nWhen we fit a single categorical variable to the data we are fitting a model with $k$ levels. However, the degrees of freedom of a categorical variable with $k$ levels is $k-1$. This is because one degree of freedom corresponds to the intercept, and the remaining $k-1$ degrees of freedom correspond to the $k-1$ coefficients of the $k-1$ dummy variables.\n\nSo, generally speaking, the degrees of freedom used up a categorical variable with $k$ levels is $k-1$.\n\n### Doing it in R\n\nIn R, we can fit a linear model with a categorical variable using the `lm()` function. And we don't need to make the dummy binary variables. That is all very conveniently done in the inner workings of the `lm()` function. Here we go:\n\n```{r}\n#| echo = TRUE\nbp_model_diet <- lm(bp ~ diet, data = bp_data_diet)\n```\n\nNo news is good news!\n\nCheck the diagnostic plots to assess if the model assumptions are met.\n\n```{r}\npar(mfrow = c(2, 2))\nplot(bp_model_diet, add.smooth = FALSE)\n```\n\nNo patterns in the residuals, QQ-plot data close to the line, and the residuals are homoscedastic. No evidence of outliers. The model assumptions are met.\n\n\n\nLet's look at the estimates of the coefficients and their $t$-statistics and $p$-values.\n\n```{r}\nsummary(bp_model_diet)$coefficients\n```\n\n\n\n::: {.callout-tip}\n## Think, Pair, Share (#beta-conclusions)\n\nWhat can we conclude from the values of the three $\\beta$ coefficients?\n:::\n\nThe three non-intercept coefficients are the $\\beta_1$, $\\beta_2$, and $\\beta_3$ coefficients. The value of each is negative, which means that the blood pressure is lower on the Mediterranean, vegetarian, and vegan diets compared to the meat heavy diet.\n\nThe $t$-statistics and $p$-values are also given. The $p$-values are all less than 0.05, so we can reject the null hypothesis that the coefficients are zero. This means that the blood pressure is significantly lower on the Mediterranean, vegetarian, and vegan diets compared to the meat heavy diet.\n\nJust for fun, let's fit the model using the three binary dummy variables:\n\n```{r}\n#| echo = TRUE\nbp_model_diet_bin <- lm(bp ~ Mediterranean + vegetarian + vegan, data = bp_data_diet)\nsummary(bp_model_diet_bin)$coefficients\n```\n\nExactly the same :)\n\nAnd for even more fun, lets see what happens if we fit a model with four binary variables, one for each diet.\n\n```{r}\n#| echo = TRUE\nbp_data_diet_bin <- bp_data_diet %>%\n  select(bp, meat_heavy, Mediterranean, vegetarian, vegan)\nbp_model_diet_bin_all <- lm(bp ~ - Mediterranean + vegetarian + vegan + meat_heavy,\n                            data = bp_data_diet_bin)\nsummary(bp_model_diet_bin_all)$coefficients\n```\n\nThe `lm` function has dropped the `meat_heavy` variable because it is perfectly collinear with the other three variables. This is because the sum of the four binary variables is always 1. This is called the dummy variable trap. The `lm` function is smart enough to drop one of the variables to avoid the trap.\n\n### Is diet important for blood pressure?\n\nWhen we want to answer the question \"is diet important for blood pressure\" we likely want to understand if there are *any* differences between diets. This is very similar to when we asked in multiple regression if *any* of the slopes are different from zero. Recall that then we used an $F$-test. We can do the same here.\n\nThe null hypothesis is that all the coefficients are zero, which means that the diet has no effect on blood pressure. The alternative hypothesis is that at least one of the coefficients is different from zero, which means that at least one diet has an effect on blood pressure.\n\nAnother way to express the null hypothesis is that diet does not explain a significant amount of the variance in blood pressure. The alternative hypothesis is that diet explains a significant amount of the variance in blood pressure.\n\nVariance explained by diet is quantified by the sum of squares associated with the diet variable. This is the model sum of squares, SSM.\n\nAs before, the $F$-statistic is the ratio the mean square of the model to the mean square of the residuals:\n\n$$F = \\frac{MSE_{model}}{MSE_{residual}} = \\frac{SSM/(k-1)}{SSE/(n -1 - (k -1))}$$\n\nwhere $k$ is the number of levels of the categorical variable and $n$ is the number of observations.\n\n::: {.callout-note}\n$(n - 1)$ is the total number of degrees of freedom in the model. $(k - 1)$ is the number of degrees of freedom used up by the categorical variable. $(n - 1 - (k - 1))$ is the number of degrees of freedom left over for the residuals. This simplifies to $n - k$.\n:::\n\n\nThe $F$-statistic is compared to the $F$-distribution with $k-1$ and $(n -1 - (k -1)) = n-k$) degrees of freedom.\n\nLet's do the $F$-test for the diet variable:\n\n```{r}\nanova(bp_model_diet)\n```\n\nThe $p$-value is less than 0.05, so we can reject the null hypothesis that diet has no effect on blood pressure.\n\n::: {.callout-tip}\n## Think, Pair, Share (#table-rsquared)\n\nCalculate the $R^2$ for the model from the ANOVA table.\n:::\n\n\n::: {.callout-tip}\n\nLet's use the lovely `gtsummary` package to summarize the model.\n\n```{r}\n# Get the ANOVA table\nanova_table <- anova(bp_model_diet)\n\n# Convert the ANOVA table to a tidy data frame\nanova_df <- broom::tidy(anova_table)\n\n# Rename columns for clarity\nanova_df <- anova_df %>%\n  rename(\n    \"Term\" = term,\n    \"Degrees of Freedom\" = df,\n    \"Sum of Squares\" = sumsq,\n    \"Mean Square\" = meansq,\n    \"F Statistic\" = statistic,\n    \"P Value\" = p.value\n  )\n\n# Create a nicely formatted ANOVA table using kableExtra\nanova_df %>%\n  kable(\n    format = \"html\", \n    digits = 3, \n    caption = \"ANOVA Table: Linear Model Analysis\",\n    col.names = c(\"Term\", \"DF\", \"Sum of Squares\", \"Mean Square\", \"F Statistic\", \"P Value\")\n  ) %>%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE\n  ) %>%\n  column_spec(6, bold = TRUE, color = \"black\") %>%  # Highlight the p-value column\n  row_spec(0, bold = TRUE, color = \"white\", background = \"gray\")  # Style header row\n\n```\n:::\n\n\n\n## Additional reading\n\nIf you'd like to read another perspective please feel free to take a look at Chapters 3.2u-x, 3.3, 4.1-4.5 in *Lineare Regression*.\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":5,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"5-categorical-explanatory-variables.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}